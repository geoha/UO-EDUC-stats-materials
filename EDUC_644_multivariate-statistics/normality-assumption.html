<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>19 Normality Assumption | Week 09: Confirmatory Factor Analysis</title>
  <meta name="description" content="Course materials for multivariate statistics" />
  <meta name="generator" content="bookdown 0.44 and GitBook 2.6.7" />

  <meta property="og:title" content="19 Normality Assumption | Week 09: Confirmatory Factor Analysis" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Course materials for multivariate statistics" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="19 Normality Assumption | Week 09: Confirmatory Factor Analysis" />
  
  <meta name="twitter:description" content="Course materials for multivariate statistics" />
  

<meta name="author" content="EDUC 644" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="descriptive-statistics.html"/>
<link rel="next" href="fitting-the-manova-model.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/tabwid-1.1.3/tabwid.css" rel="stylesheet" />
<script src="libs/tabwid-1.1.3/tabwid.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 1em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Multivariate Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="scalars.html"><a href="scalars.html"><i class="fa fa-check"></i><b>1</b> Scalars</a></li>
<li class="chapter" data-level="2" data-path="vectors.html"><a href="vectors.html"><i class="fa fa-check"></i><b>2</b> Vectors</a></li>
<li class="chapter" data-level="3" data-path="matrices.html"><a href="matrices.html"><i class="fa fa-check"></i><b>3</b> Matrices</a>
<ul>
<li class="chapter" data-level="3.1" data-path="matrices.html"><a href="matrices.html#data-files-as-matrices"><i class="fa fa-check"></i><b>3.1</b> Data Files as Matrices</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="symmetrical-matrices.html"><a href="symmetrical-matrices.html"><i class="fa fa-check"></i><b>4</b> Symmetrical Matrices</a>
<ul>
<li class="chapter" data-level="4.1" data-path="symmetrical-matrices.html"><a href="symmetrical-matrices.html#variance-covariance-matrices"><i class="fa fa-check"></i><b>4.1</b> Variance-covariance Matrices</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="symmetrical-matrices.html"><a href="symmetrical-matrices.html#greek-letters"><i class="fa fa-check"></i><b>4.1.1</b> Greek letters</a></li>
<li class="chapter" data-level="4.1.2" data-path="symmetrical-matrices.html"><a href="symmetrical-matrices.html#example-variance-covariance-matrix"><i class="fa fa-check"></i><b>4.1.2</b> Example variance-covariance matrix</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="symmetrical-matrices.html"><a href="symmetrical-matrices.html#the-diagonal-and-trace"><i class="fa fa-check"></i><b>4.2</b> The diagonal and trace</a></li>
<li class="chapter" data-level="4.3" data-path="symmetrical-matrices.html"><a href="symmetrical-matrices.html#an-identity-matrix"><i class="fa fa-check"></i><b>4.3</b> An identity matrix</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="transposed-vectors-and-matrices.html"><a href="transposed-vectors-and-matrices.html"><i class="fa fa-check"></i><b>5</b> Transposed Vectors and Matrices</a></li>
<li class="chapter" data-level="6" data-path="matrix-addition-and-subtraction.html"><a href="matrix-addition-and-subtraction.html"><i class="fa fa-check"></i><b>6</b> Matrix Addition and Subtraction</a></li>
<li class="chapter" data-level="7" data-path="operations-on-matrices-with-a-scalar.html"><a href="operations-on-matrices-with-a-scalar.html"><i class="fa fa-check"></i><b>7</b> Operations on Matrices with a Scalar</a>
<ul>
<li class="chapter" data-level="7.1" data-path="operations-on-matrices-with-a-scalar.html"><a href="operations-on-matrices-with-a-scalar.html#sum-of-square-and-cross-product-sscp-matrices"><i class="fa fa-check"></i><b>7.1</b> Sum-of-square-and-cross-product (SSCP) matrices</a></li>
<li class="chapter" data-level="7.2" data-path="operations-on-matrices-with-a-scalar.html"><a href="operations-on-matrices-with-a-scalar.html#operations-on-elements-of-a-matrix-example-with-a-correlation-matrix"><i class="fa fa-check"></i><b>7.2</b> Operations on elements of a matrix: Example with a correlation matrix</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="matrix-multiplication.html"><a href="matrix-multiplication.html"><i class="fa fa-check"></i><b>8</b> Matrix Multiplication</a>
<ul>
<li class="chapter" data-level="8.1" data-path="matrix-multiplication.html"><a href="matrix-multiplication.html#another-example-of-matrix-multiplication-to-get-the-sscp"><i class="fa fa-check"></i><b>8.1</b> Another example of matrix multiplication, to get the SSCP</a></li>
<li class="chapter" data-level="8.2" data-path="matrix-multiplication.html"><a href="matrix-multiplication.html#the-ordering-is-important"><i class="fa fa-check"></i><b>8.2</b> The ordering is important</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="inverse-of-a-matrix.html"><a href="inverse-of-a-matrix.html"><i class="fa fa-check"></i><b>9</b> Inverse of a Matrix</a></li>
<li class="chapter" data-level="10" data-path="matrix-determinants-as-generalized-variance.html"><a href="matrix-determinants-as-generalized-variance.html"><i class="fa fa-check"></i><b>10</b> Matrix determinants, as generalized variance</a></li>
<li class="chapter" data-level="11" data-path="eigenvectors-and-eigenvalues.html"><a href="eigenvectors-and-eigenvalues.html"><i class="fa fa-check"></i><b>11</b> Eigenvectors and Eigenvalues</a></li>
<li class="chapter" data-level="12" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>12</b> Summary</a></li>
<li class="chapter" data-level="13" data-path="optional-spss-and-r-code-to-manipulate-matrices.html"><a href="optional-spss-and-r-code-to-manipulate-matrices.html"><i class="fa fa-check"></i><b>13</b> Optional: SPSS and R Code to Manipulate Matrices</a></li>
<li class="chapter" data-level="14" data-path="hotellings-t2.html"><a href="hotellings-t2.html"><i class="fa fa-check"></i><b>14</b> Hotelling’s <span class="math inline">\(T^2\)</span></a>
<ul>
<li class="chapter" data-level="14.1" data-path="hotellings-t2.html"><a href="hotellings-t2.html#within-group-covariance-matrices"><i class="fa fa-check"></i><b>14.1</b> Within-group covariance matrices</a></li>
<li class="chapter" data-level="14.2" data-path="hotellings-t2.html"><a href="hotellings-t2.html#sscp-matrices"><i class="fa fa-check"></i><b>14.2</b> SSCP matrices</a></li>
<li class="chapter" data-level="14.3" data-path="hotellings-t2.html"><a href="hotellings-t2.html#conducting-the-test-using-functions"><i class="fa fa-check"></i><b>14.3</b> Conducting the Test using Functions</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="data-from-week-1.html"><a href="data-from-week-1.html"><i class="fa fa-check"></i><b>15</b> Data from Week 1</a></li>
<li class="chapter" data-level="16" data-path="orthogonal-contrasts.html"><a href="orthogonal-contrasts.html"><i class="fa fa-check"></i><b>16</b> Orthogonal contrasts</a>
<ul>
<li class="chapter" data-level="16.1" data-path="orthogonal-contrasts.html"><a href="orthogonal-contrasts.html#conditions-for-orthogonal-contrasts"><i class="fa fa-check"></i><b>16.1</b> Conditions for orthogonal contrasts</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="orthogonal-contrasts.html"><a href="orthogonal-contrasts.html#an-analogy-for-these-conditions"><i class="fa fa-check"></i><b>16.1.1</b> An analogy for these conditions</a></li>
<li class="chapter" data-level="16.1.2" data-path="orthogonal-contrasts.html"><a href="orthogonal-contrasts.html#accounting-for-type-i-error-in-non-orthogonal-contrasts."><i class="fa fa-check"></i><b>16.1.2</b> Accounting for Type I error in non-orthogonal contrasts.</a></li>
<li class="chapter" data-level="16.1.3" data-path="orthogonal-contrasts.html"><a href="orthogonal-contrasts.html#bonferronithe-more-conservative-pizza-sauce"><i class="fa fa-check"></i><b>16.1.3</b> Bonferroni—the more conservative pizza sauce</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="orthogonal-contrasts.html"><a href="orthogonal-contrasts.html#post-hoc-tests"><i class="fa fa-check"></i><b>16.2</b> Post-hoc tests</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>17</b> Data</a></li>
<li class="chapter" data-level="18" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html"><i class="fa fa-check"></i><b>18</b> Descriptive statistics</a>
<ul>
<li class="chapter" data-level="18.1" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html#by-group-descriptive-statistics"><i class="fa fa-check"></i><b>18.1</b> By-group descriptive statistics</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="normality-assumption.html"><a href="normality-assumption.html"><i class="fa fa-check"></i><b>19</b> Normality Assumption</a>
<ul>
<li class="chapter" data-level="19.1" data-path="normality-assumption.html"><a href="normality-assumption.html#univariate-normality"><i class="fa fa-check"></i><b>19.1</b> Univariate Normality</a>
<ul>
<li class="chapter" data-level="19.1.1" data-path="normality-assumption.html"><a href="normality-assumption.html#identifying-univariate-outliers-within-groups"><i class="fa fa-check"></i><b>19.1.1</b> Identifying univariate outliers within groups</a></li>
<li class="chapter" data-level="19.1.2" data-path="normality-assumption.html"><a href="normality-assumption.html#kurtosis-and-skew"><i class="fa fa-check"></i><b>19.1.2</b> Kurtosis and skew</a></li>
<li class="chapter" data-level="19.1.3" data-path="normality-assumption.html"><a href="normality-assumption.html#examining-univariate-normality-using-density-plots"><i class="fa fa-check"></i><b>19.1.3</b> Examining univariate normality using density plots</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="normality-assumption.html"><a href="normality-assumption.html#examining-univariate-normality-using-quantile-quantile-plots"><i class="fa fa-check"></i><b>19.2</b> Examining univariate normality using quantile-quantile plots</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="normality-assumption.html"><a href="normality-assumption.html#univariate-q-q-plots-from-other-packages"><i class="fa fa-check"></i><b>19.2.1</b> Univariate Q-Q plots from other packages</a></li>
<li class="chapter" data-level="19.2.2" data-path="normality-assumption.html"><a href="normality-assumption.html#statistical-tests-of-univariate-normality"><i class="fa fa-check"></i><b>19.2.2</b> Statistical tests of univariate normality</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="normality-assumption.html"><a href="normality-assumption.html#a-caution-about-statistical-tests-of-statistical-assumptions"><i class="fa fa-check"></i><b>19.3</b> A caution about statistical tests of statistical assumptions</a></li>
<li class="chapter" data-level="19.4" data-path="normality-assumption.html"><a href="normality-assumption.html#mahalanobis-distance-and-multivariate-outliers"><i class="fa fa-check"></i><b>19.4</b> Mahalanobis Distance and Multivariate Outliers</a>
<ul>
<li class="chapter" data-level="19.4.1" data-path="normality-assumption.html"><a href="normality-assumption.html#outliers"><i class="fa fa-check"></i><b>19.4.1</b> Outliers</a></li>
<li class="chapter" data-level="19.4.2" data-path="normality-assumption.html"><a href="normality-assumption.html#mahalanobis-distance-using-residuals"><i class="fa fa-check"></i><b>19.4.2</b> Mahalanobis Distance using Residuals</a></li>
<li class="chapter" data-level="19.4.3" data-path="normality-assumption.html"><a href="normality-assumption.html#multivariate-residual-q-q-plot-by-group"><i class="fa fa-check"></i><b>19.4.3</b> Multivariate residual Q-Q plot by group</a></li>
</ul></li>
<li class="chapter" data-level="19.5" data-path="normality-assumption.html"><a href="normality-assumption.html#statistical-tests-of-multivariate-normality"><i class="fa fa-check"></i><b>19.5</b> Statistical Tests of Multivariate Normality</a></li>
<li class="chapter" data-level="19.6" data-path="normality-assumption.html"><a href="normality-assumption.html#homogeneity-of-covariance"><i class="fa fa-check"></i><b>19.6</b> Homogeneity of Covariance</a></li>
<li class="chapter" data-level="19.7" data-path="normality-assumption.html"><a href="normality-assumption.html#conclusions-about-our-statistical-assumptions"><i class="fa fa-check"></i><b>19.7</b> Conclusions about our statistical assumptions</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="fitting-the-manova-model.html"><a href="fitting-the-manova-model.html"><i class="fa fa-check"></i><b>20</b> Fitting the MANOVA Model</a>
<ul>
<li class="chapter" data-level="20.0.1" data-path="fitting-the-manova-model.html"><a href="fitting-the-manova-model.html#interpretation"><i class="fa fa-check"></i><b>20.0.1</b> Interpretation</a></li>
<li class="chapter" data-level="20.1" data-path="fitting-the-manova-model.html"><a href="fitting-the-manova-model.html#follow-up-analysis-with-univariate-f-tests"><i class="fa fa-check"></i><b>20.1</b> Follow-up analysis with univariate <em>F</em>-tests</a></li>
<li class="chapter" data-level="20.2" data-path="fitting-the-manova-model.html"><a href="fitting-the-manova-model.html#effect-size"><i class="fa fa-check"></i><b>20.2</b> Effect size</a></li>
<li class="chapter" data-level="20.3" data-path="fitting-the-manova-model.html"><a href="fitting-the-manova-model.html#comparing-the-model-without-outlier"><i class="fa fa-check"></i><b>20.3</b> Comparing the Model Without Outlier</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="robust-one-way-manova.html"><a href="robust-one-way-manova.html"><i class="fa fa-check"></i><b>21</b> Robust One-way MANOVA</a></li>
<li class="chapter" data-level="22" data-path="summary-1.html"><a href="summary-1.html"><i class="fa fa-check"></i><b>22</b> Summary</a></li>
<li class="chapter" data-level="23" data-path="following-tabachnick-and-fidells-notes.html"><a href="following-tabachnick-and-fidells-notes.html"><i class="fa fa-check"></i><b>23</b> Following Tabachnick and Fidell’s notes</a>
<ul>
<li class="chapter" data-level="23.1" data-path="following-tabachnick-and-fidells-notes.html"><a href="following-tabachnick-and-fidells-notes.html#another-way-to-get-the-sscp_w"><i class="fa fa-check"></i><b>23.1</b> Another way to get the <span class="math inline">\(SSCP_W\)</span>:</a></li>
<li class="chapter" data-level="23.2" data-path="following-tabachnick-and-fidells-notes.html"><a href="following-tabachnick-and-fidells-notes.html#mathbfsscp_between-for-each-factor"><i class="fa fa-check"></i><b>23.2</b> <span class="math inline">\(\mathbf{SSCP_{Between}}\)</span> for each factor</a></li>
<li class="chapter" data-level="23.3" data-path="following-tabachnick-and-fidells-notes.html"><a href="following-tabachnick-and-fidells-notes.html#mathbfsscp_between-for-the-interaction"><i class="fa fa-check"></i><b>23.3</b> <span class="math inline">\(\mathbf{SSCP_{Between}}\)</span> for the interaction</a></li>
<li class="chapter" data-level="23.4" data-path="following-tabachnick-and-fidells-notes.html"><a href="following-tabachnick-and-fidells-notes.html#these-by-hand-calculations-will-be-available-in-manova."><i class="fa fa-check"></i><b>23.4</b> These by-hand calculations will be available in <code>manova()</code>.</a></li>
<li class="chapter" data-level="23.5" data-path="following-tabachnick-and-fidells-notes.html"><a href="following-tabachnick-and-fidells-notes.html#calculating-the-generalized-variance"><i class="fa fa-check"></i><b>23.5</b> Calculating the generalized variance</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="calculating-wilks-lambda.html"><a href="calculating-wilks-lambda.html"><i class="fa fa-check"></i><b>24</b> Calculating Wilks’ Lambda</a>
<ul>
<li class="chapter" data-level="24.1" data-path="calculating-wilks-lambda.html"><a href="calculating-wilks-lambda.html#fit-the-factorial-manova"><i class="fa fa-check"></i><b>24.1</b> Fit the factorial MANOVA</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="mancova.html"><a href="mancova.html"><i class="fa fa-check"></i><b>25</b> MANCOVA</a>
<ul>
<li class="chapter" data-level="25.1" data-path="mancova.html"><a href="mancova.html#mancova-example"><i class="fa fa-check"></i><b>25.1</b> MANCOVA example</a></li>
<li class="chapter" data-level="25.2" data-path="mancova.html"><a href="mancova.html#lets-think-about-ordering-and-type-i-sums-of-squares"><i class="fa fa-check"></i><b>25.2</b> Let’s think about ordering and Type I sums of squares</a>
<ul>
<li class="chapter" data-level="25.2.1" data-path="mancova.html"><a href="mancova.html#adjusted-means"><i class="fa fa-check"></i><b>25.2.1</b> Adjusted means</a></li>
</ul></li>
<li class="chapter" data-level="25.3" data-path="mancova.html"><a href="mancova.html#fitting-the-discriminant-function-analysis-model"><i class="fa fa-check"></i><b>25.3</b> Fitting the discriminant function analysis model</a></li>
<li class="chapter" data-level="25.4" data-path="mancova.html"><a href="mancova.html#dimension-reduction-analysis"><i class="fa fa-check"></i><b>25.4</b> Dimension reduction analysis</a>
<ul>
<li class="chapter" data-level="25.4.1" data-path="mancova.html"><a href="mancova.html#effect-sizes"><i class="fa fa-check"></i><b>25.4.1</b> Effect sizes</a></li>
</ul></li>
<li class="chapter" data-level="25.5" data-path="mancova.html"><a href="mancova.html#structure-and-standardized-discriminant-function-coefficients"><i class="fa fa-check"></i><b>25.5</b> Structure and standardized discriminant function coefficients</a></li>
<li class="chapter" data-level="25.6" data-path="mancova.html"><a href="mancova.html#discriminant-function-scores"><i class="fa fa-check"></i><b>25.6</b> Discriminant function scores</a></li>
<li class="chapter" data-level="25.7" data-path="mancova.html"><a href="mancova.html#group-means-centroids-of-the-discriminant-function-scores"><i class="fa fa-check"></i><b>25.7</b> Group means (centroids) of the discriminant-function scores</a></li>
<li class="chapter" data-level="25.8" data-path="mancova.html"><a href="mancova.html#bivariate-scatterplot"><i class="fa fa-check"></i><b>25.8</b> Bivariate scatterplot</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="write-up.html"><a href="write-up.html"><i class="fa fa-check"></i><b>26</b> Write-up</a></li>
<li class="chapter" data-level="27" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html"><i class="fa fa-check"></i><b>27</b> Example 1, to see some properties of PCA</a>
<ul>
<li class="chapter" data-level="27.1" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#pca-with-covariance-vs.-correlation"><i class="fa fa-check"></i><b>27.1</b> PCA with Covariance vs. Correlation</a></li>
<li class="chapter" data-level="27.2" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#unscaled-eigenvectors"><i class="fa fa-check"></i><b>27.2</b> Unscaled eigenvectors</a></li>
<li class="chapter" data-level="27.3" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#looking-at-the-properties-of-eigenvectors-and-eigenvalues"><i class="fa fa-check"></i><b>27.3</b> Looking at the properties of eigenvectors and eigenvalues</a>
<ul>
<li class="chapter" data-level="27.3.1" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#eigenvalues-add-up-to-total-observed-variance"><i class="fa fa-check"></i><b>27.3.1</b> Eigenvalues add up to total observed variance</a></li>
<li class="chapter" data-level="27.3.2" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#each-components-proportion-of-variance"><i class="fa fa-check"></i><b>27.3.2</b> Each component’s proportion of variance</a></li>
<li class="chapter" data-level="27.3.3" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#rescaling-the-eigenvectors"><i class="fa fa-check"></i><b>27.3.3</b> Rescaling the eigenvectors</a></li>
<li class="chapter" data-level="27.3.4" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#reproducing-the-covariance-or-correlation-matrix"><i class="fa fa-check"></i><b>27.3.4</b> Reproducing the covariance (or correlation) matrix</a></li>
<li class="chapter" data-level="27.3.5" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#summary-of-the-vectors-and-matrices"><i class="fa fa-check"></i><b>27.3.5</b> Summary of the vectors and matrices</a></li>
</ul></li>
<li class="chapter" data-level="27.4" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#using-the-psych-package"><i class="fa fa-check"></i><b>27.4</b> Using the psych package</a></li>
<li class="chapter" data-level="27.5" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#determining-how-many-components-to-retain"><i class="fa fa-check"></i><b>27.5</b> Determining how many components to retain</a>
<ul>
<li class="chapter" data-level="27.5.1" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#kaisers-rule"><i class="fa fa-check"></i><b>27.5.1</b> 1. Kaiser’s rule</a></li>
<li class="chapter" data-level="27.5.2" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#scree-plot"><i class="fa fa-check"></i><b>27.5.2</b> 2. Scree plot</a></li>
<li class="chapter" data-level="27.5.3" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#parallel-analysis"><i class="fa fa-check"></i><b>27.5.3</b> 3. Parallel analysis</a></li>
</ul></li>
<li class="chapter" data-level="27.6" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#reduced-pca-model"><i class="fa fa-check"></i><b>27.6</b> Reduced PCA model</a></li>
<li class="chapter" data-level="27.7" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#interpretation-1"><i class="fa fa-check"></i><b>27.7</b> Interpretation</a>
<ul>
<li class="chapter" data-level="27.7.1" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#plot"><i class="fa fa-check"></i><b>27.7.1</b> Plot</a></li>
</ul></li>
<li class="chapter" data-level="27.8" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#interpretation-of-the-rotated-solution"><i class="fa fa-check"></i><b>27.8</b> Interpretation of the rotated solution</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="example-two.html"><a href="example-two.html"><i class="fa fa-check"></i><b>28</b> Example Two</a>
<ul>
<li class="chapter" data-level="28.1" data-path="example-two.html"><a href="example-two.html#pca-on-unstandardized-scores"><i class="fa fa-check"></i><b>28.1</b> PCA on Unstandardized Scores</a>
<ul>
<li class="chapter" data-level="28.1.1" data-path="example-two.html"><a href="example-two.html#hand-calculating-component-scores-from-this-pca"><i class="fa fa-check"></i><b>28.1.1</b> Hand calculating component scores from this PCA</a></li>
</ul></li>
<li class="chapter" data-level="28.2" data-path="example-two.html"><a href="example-two.html#pca-on-the-standardized-scores"><i class="fa fa-check"></i><b>28.2</b> PCA on the Standardized Scores</a>
<ul>
<li class="chapter" data-level="28.2.1" data-path="example-two.html"><a href="example-two.html#calculating-component-scores"><i class="fa fa-check"></i><b>28.2.1</b> Calculating component scores</a></li>
<li class="chapter" data-level="28.2.2" data-path="example-two.html"><a href="example-two.html#using-the-rescaled-eigenvectors-to-interpret-the-components"><i class="fa fa-check"></i><b>28.2.2</b> Using the rescaled eigenvectors to interpret the components</a></li>
</ul></li>
<li class="chapter" data-level="28.3" data-path="example-two.html"><a href="example-two.html#let-the-psych-package-do-the-work"><i class="fa fa-check"></i><b>28.3</b> Let the Psych Package Do the Work</a>
<ul>
<li class="chapter" data-level="28.3.1" data-path="example-two.html"><a href="example-two.html#view-the-component-scores"><i class="fa fa-check"></i><b>28.3.1</b> View the component scores</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="29" data-path="heptathlon-example.html"><a href="heptathlon-example.html"><i class="fa fa-check"></i><b>29</b> Heptathlon example</a>
<ul>
<li class="chapter" data-level="29.1" data-path="heptathlon-example.html"><a href="heptathlon-example.html#data-and-data-cleaning"><i class="fa fa-check"></i><b>29.1</b> Data and data cleaning</a></li>
<li class="chapter" data-level="29.2" data-path="heptathlon-example.html"><a href="heptathlon-example.html#examine-assumption-of-linearity"><i class="fa fa-check"></i><b>29.2</b> Examine assumption of linearity</a></li>
<li class="chapter" data-level="29.3" data-path="heptathlon-example.html"><a href="heptathlon-example.html#multivariate-normality-and-outliers"><i class="fa fa-check"></i><b>29.3</b> Multivariate normality and outliers</a></li>
<li class="chapter" data-level="29.4" data-path="heptathlon-example.html"><a href="heptathlon-example.html#re-examine-linearity-and-normality"><i class="fa fa-check"></i><b>29.4</b> Re-examine linearity and normality</a></li>
<li class="chapter" data-level="29.5" data-path="heptathlon-example.html"><a href="heptathlon-example.html#fit-the-initial-pca"><i class="fa fa-check"></i><b>29.5</b> Fit the initial PCA</a></li>
<li class="chapter" data-level="29.6" data-path="heptathlon-example.html"><a href="heptathlon-example.html#determine-the-number-of-components-to-retain"><i class="fa fa-check"></i><b>29.6</b> Determine the number of components to retain</a></li>
<li class="chapter" data-level="29.7" data-path="heptathlon-example.html"><a href="heptathlon-example.html#refit-the-pca-model-using-rotation-if-that-is-acceptable-in-your-field"><i class="fa fa-check"></i><b>29.7</b> Refit the PCA model, using rotation if that is acceptable in your field</a></li>
<li class="chapter" data-level="29.8" data-path="heptathlon-example.html"><a href="heptathlon-example.html#interpret-the-components"><i class="fa fa-check"></i><b>29.8</b> Interpret the components</a></li>
<li class="chapter" data-level="29.9" data-path="heptathlon-example.html"><a href="heptathlon-example.html#saving-the-scores"><i class="fa fa-check"></i><b>29.9</b> Saving the scores</a></li>
</ul></li>
<li class="chapter" data-level="30" data-path="other-example-from-later-in-the-chapter-not-assigned.html"><a href="other-example-from-later-in-the-chapter-not-assigned.html"><i class="fa fa-check"></i><b>30</b> Other example from later in the chapter (not assigned)</a>
<ul>
<li class="chapter" data-level="30.1" data-path="other-example-from-later-in-the-chapter-not-assigned.html"><a href="other-example-from-later-in-the-chapter-not-assigned.html#usairpollution-data"><i class="fa fa-check"></i><b>30.1</b> USairpollution Data</a></li>
</ul></li>
<li class="chapter" data-level="31" data-path="another-resource.html"><a href="another-resource.html"><i class="fa fa-check"></i><b>31</b> Another resource</a></li>
<li class="chapter" data-level="32" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>32</b> References</a></li>
<li class="chapter" data-level="33" data-path="introductory-comments.html"><a href="introductory-comments.html"><i class="fa fa-check"></i><b>33</b> Introductory comments</a>
<ul>
<li class="chapter" data-level="33.1" data-path="introductory-comments.html"><a href="introductory-comments.html#packages"><i class="fa fa-check"></i><b>33.1</b> Packages</a></li>
<li class="chapter" data-level="33.2" data-path="introductory-comments.html"><a href="introductory-comments.html#efa-ne-pca"><i class="fa fa-check"></i><b>33.2</b> EFA <span class="math inline">\(\ne\)</span> PCA</a></li>
</ul></li>
<li class="chapter" data-level="34" data-path="preparatory-steps.html"><a href="preparatory-steps.html"><i class="fa fa-check"></i><b>34</b> Preparatory steps</a>
<ul>
<li class="chapter" data-level="34.1" data-path="preparatory-steps.html"><a href="preparatory-steps.html#examining-the-data"><i class="fa fa-check"></i><b>34.1</b> Examining the data</a>
<ul>
<li class="chapter" data-level="34.1.1" data-path="preparatory-steps.html"><a href="preparatory-steps.html#descriptive-statistics-1"><i class="fa fa-check"></i><b>34.1.1</b> Descriptive statistics</a></li>
</ul></li>
<li class="chapter" data-level="34.2" data-path="preparatory-steps.html"><a href="preparatory-steps.html#addressing-assumptions"><i class="fa fa-check"></i><b>34.2</b> Addressing assumptions</a>
<ul>
<li class="chapter" data-level="34.2.1" data-path="preparatory-steps.html"><a href="preparatory-steps.html#linearity"><i class="fa fa-check"></i><b>34.2.1</b> Linearity</a></li>
<li class="chapter" data-level="34.2.2" data-path="preparatory-steps.html"><a href="preparatory-steps.html#outliers-and-multivariate-normality"><i class="fa fa-check"></i><b>34.2.2</b> Outliers and multivariate normality</a></li>
<li class="chapter" data-level="34.2.3" data-path="preparatory-steps.html"><a href="preparatory-steps.html#absence-of-perfect-multicollinearity"><i class="fa fa-check"></i><b>34.2.3</b> Absence of perfect multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="34.3" data-path="preparatory-steps.html"><a href="preparatory-steps.html#determining-factorability"><i class="fa fa-check"></i><b>34.3</b> Determining factorability</a></li>
<li class="chapter" data-level="34.4" data-path="preparatory-steps.html"><a href="preparatory-steps.html#determining-how-many-factors-to-retain"><i class="fa fa-check"></i><b>34.4</b> Determining how many factors to retain</a>
<ul>
<li class="chapter" data-level="34.4.1" data-path="preparatory-steps.html"><a href="preparatory-steps.html#parallel-analysis-1"><i class="fa fa-check"></i><b>34.4.1</b> Parallel analysis</a></li>
</ul></li>
<li class="chapter" data-level="34.5" data-path="preparatory-steps.html"><a href="preparatory-steps.html#factor-analysis-with-a-data-matrix-raw-data"><i class="fa fa-check"></i><b>34.5</b> Factor analysis with a data matrix (raw data)</a>
<ul>
<li class="chapter" data-level="34.5.1" data-path="preparatory-steps.html"><a href="preparatory-steps.html#determine-how-much-of-the-variance-is-explained-by-the-n-factors"><i class="fa fa-check"></i><b>34.5.1</b> Determine how much of the variance is explained by the <em>n</em> factors</a></li>
<li class="chapter" data-level="34.5.2" data-path="preparatory-steps.html"><a href="preparatory-steps.html#fit-the-efa-with-rotation-for-interpretation"><i class="fa fa-check"></i><b>34.5.2</b> Fit the EFA with rotation, for interpretation</a></li>
<li class="chapter" data-level="34.5.3" data-path="preparatory-steps.html"><a href="preparatory-steps.html#reduced-correlation-matrix"><i class="fa fa-check"></i><b>34.5.3</b> Reduced correlation matrix</a></li>
<li class="chapter" data-level="34.5.4" data-path="preparatory-steps.html"><a href="preparatory-steps.html#examining-pattern-coefficients-the-factor-loadings"><i class="fa fa-check"></i><b>34.5.4</b> Examining pattern coefficients (the factor loadings)</a></li>
</ul></li>
<li class="chapter" data-level="34.6" data-path="preparatory-steps.html"><a href="preparatory-steps.html#factor-analysis-with-correlation-data"><i class="fa fa-check"></i><b>34.6</b> Factor analysis with correlation data</a>
<ul>
<li class="chapter" data-level="34.6.1" data-path="preparatory-steps.html"><a href="preparatory-steps.html#setting-up-the-data"><i class="fa fa-check"></i><b>34.6.1</b> Setting up the data</a></li>
<li class="chapter" data-level="34.6.2" data-path="preparatory-steps.html"><a href="preparatory-steps.html#preparatory-steps-1"><i class="fa fa-check"></i><b>34.6.2</b> Preparatory steps</a></li>
<li class="chapter" data-level="34.6.3" data-path="preparatory-steps.html"><a href="preparatory-steps.html#performing-the-factor-analysis"><i class="fa fa-check"></i><b>34.6.3</b> Performing the factor analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="35" data-path="references-1.html"><a href="references-1.html"><i class="fa fa-check"></i><b>35</b> References</a></li>
<li class="chapter" data-level="36" data-path="factor-analysis-with-correlation-data-1.html"><a href="factor-analysis-with-correlation-data-1.html"><i class="fa fa-check"></i><b>36</b> Factor analysis with correlation data</a>
<ul>
<li class="chapter" data-level="36.1" data-path="factor-analysis-with-correlation-data-1.html"><a href="factor-analysis-with-correlation-data-1.html#setting-up-the-data-1"><i class="fa fa-check"></i><b>36.1</b> Setting up the data</a>
<ul>
<li class="chapter" data-level="36.1.1" data-path="factor-analysis-with-correlation-data-1.html"><a href="factor-analysis-with-correlation-data-1.html#some-extra-stuff-importing-half-the-correlation-matrix"><i class="fa fa-check"></i><b>36.1.1</b> Some extra stuff: Importing half the correlation matrix</a></li>
</ul></li>
<li class="chapter" data-level="36.2" data-path="factor-analysis-with-correlation-data-1.html"><a href="factor-analysis-with-correlation-data-1.html#preparatory-steps-2"><i class="fa fa-check"></i><b>36.2</b> Preparatory steps</a>
<ul>
<li class="chapter" data-level="36.2.1" data-path="factor-analysis-with-correlation-data-1.html"><a href="factor-analysis-with-correlation-data-1.html#factorability"><i class="fa fa-check"></i><b>36.2.1</b> Factorability</a></li>
<li class="chapter" data-level="36.2.2" data-path="factor-analysis-with-correlation-data-1.html"><a href="factor-analysis-with-correlation-data-1.html#number-of-factors"><i class="fa fa-check"></i><b>36.2.2</b> Number of factors</a></li>
</ul></li>
<li class="chapter" data-level="36.3" data-path="factor-analysis-with-correlation-data-1.html"><a href="factor-analysis-with-correlation-data-1.html#performing-the-factor-analysis-1"><i class="fa fa-check"></i><b>36.3</b> Performing the factor analysis</a></li>
</ul></li>
<li class="chapter" data-level="37" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html"><i class="fa fa-check"></i><b>37</b> EFA with categorical data</a>
<ul>
<li class="chapter" data-level="37.1" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html#describing-categorical-data"><i class="fa fa-check"></i><b>37.1</b> Describing categorical data</a>
<ul>
<li class="chapter" data-level="37.1.1" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html#plotting-categorical-data"><i class="fa fa-check"></i><b>37.1.1</b> Plotting categorical data</a></li>
<li class="chapter" data-level="37.1.2" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html#specifying-the-variable-type-as-ordinal"><i class="fa fa-check"></i><b>37.1.2</b> Specifying the variable type as ordinal</a></li>
<li class="chapter" data-level="37.1.3" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html#getting-the-correlation-matrix"><i class="fa fa-check"></i><b>37.1.3</b> Getting the correlation matrix</a></li>
<li class="chapter" data-level="37.1.4" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html#appraising-the-factorability-and-determining-the-number-of-factors-to-retain"><i class="fa fa-check"></i><b>37.1.4</b> Appraising the factorability and determining the number of factors to retain</a></li>
<li class="chapter" data-level="37.1.5" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html#factor-analysis-on-the-polychoric-matrix"><i class="fa fa-check"></i><b>37.1.5</b> Factor analysis on the polychoric matrix</a></li>
<li class="chapter" data-level="37.1.6" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html#the-polycor-package-if-needed"><i class="fa fa-check"></i><b>37.1.6</b> The polycor package, if needed</a></li>
</ul></li>
<li class="chapter" data-level="37.2" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html#factor-scores"><i class="fa fa-check"></i><b>37.2</b> Factor scores</a>
<ul>
<li class="chapter" data-level="37.2.1" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html#which-factor-scores-to-use"><i class="fa fa-check"></i><b>37.2.1</b> Which factor scores to use?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="38" data-path="practice.html"><a href="practice.html"><i class="fa fa-check"></i><b>38</b> Practice</a>
<ul>
<li class="chapter" data-level="38.1" data-path="practice.html"><a href="practice.html#summary-2"><i class="fa fa-check"></i><b>38.1</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="39" data-path="references-2.html"><a href="references-2.html"><i class="fa fa-check"></i><b>39</b> References</a></li>
<li class="chapter" data-level="40" data-path="preparatory-steps-3.html"><a href="preparatory-steps-3.html"><i class="fa fa-check"></i><b>40</b> Preparatory steps</a>
<ul>
<li class="chapter" data-level="40.1" data-path="preparatory-steps-3.html"><a href="preparatory-steps-3.html#describing-the-data"><i class="fa fa-check"></i><b>40.1</b> Describing the data</a>
<ul>
<li class="chapter" data-level="40.1.1" data-path="preparatory-steps-3.html"><a href="preparatory-steps-3.html#an-article-reported-r-and-the-sds-so-how-can-i-get-s"><i class="fa fa-check"></i><b>40.1.1</b> An article reported R and the SDs, so how can I get S?</a></li>
<li class="chapter" data-level="40.1.2" data-path="preparatory-steps-3.html"><a href="preparatory-steps-3.html#describing-from-a-categorical-perspective"><i class="fa fa-check"></i><b>40.1.2</b> Describing from a categorical perspective</a></li>
<li class="chapter" data-level="40.1.3" data-path="preparatory-steps-3.html"><a href="preparatory-steps-3.html#addressing-assumptions-1"><i class="fa fa-check"></i><b>40.1.3</b> Addressing assumptions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="41" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html"><i class="fa fa-check"></i><b>41</b> Fitting a CFA model</a>
<ul>
<li class="chapter" data-level="41.1" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#making-sure-the-model-was-correctly-estimated"><i class="fa fa-check"></i><b>41.1</b> Making sure the model was correctly estimated</a></li>
<li class="chapter" data-level="41.2" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#evaluating-the-model-fit"><i class="fa fa-check"></i><b>41.2</b> Evaluating the model fit</a></li>
<li class="chapter" data-level="41.3" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#interpretting-the-parameter-estimates"><i class="fa fa-check"></i><b>41.3</b> Interpretting the parameter estimates</a></li>
<li class="chapter" data-level="41.4" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#further-inspecting-our-model"><i class="fa fa-check"></i><b>41.4</b> Further inspecting our model</a>
<ul>
<li class="chapter" data-level="41.4.1" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#looking-at-the-models-covariance-matrices"><i class="fa fa-check"></i><b>41.4.1</b> Looking at the model’s covariance matrices</a></li>
</ul></li>
<li class="chapter" data-level="41.5" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#further-inspecting-our-models-parameters"><i class="fa fa-check"></i><b>41.5</b> Further inspecting our model’s parameters</a>
<ul>
<li class="chapter" data-level="41.5.1" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#seeing-which-parameters-were-estimated"><i class="fa fa-check"></i><b>41.5.1</b> Seeing which parameters were estimated</a></li>
<li class="chapter" data-level="41.5.2" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#optional-saving-parameter-estimates-to-a-data-frame"><i class="fa fa-check"></i><b>41.5.2</b> Optional: Saving parameter estimates to a data frame</a></li>
<li class="chapter" data-level="41.5.3" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#generating-path-diagrams"><i class="fa fa-check"></i><b>41.5.3</b> Generating path diagrams</a></li>
<li class="chapter" data-level="41.5.4" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#examining-modification-indices"><i class="fa fa-check"></i><b>41.5.4</b> Examining modification indices</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="42" data-path="using-alternative-model-specifications.html"><a href="using-alternative-model-specifications.html"><i class="fa fa-check"></i><b>42</b> Using alternative model specifications</a>
<ul>
<li class="chapter" data-level="42.1" data-path="using-alternative-model-specifications.html"><a href="using-alternative-model-specifications.html#rescaling-the-factors-to-be-standardized"><i class="fa fa-check"></i><b>42.1</b> Rescaling the factors to be standardized</a></li>
<li class="chapter" data-level="42.2" data-path="using-alternative-model-specifications.html"><a href="using-alternative-model-specifications.html#specifying-a-competing-nested-model"><i class="fa fa-check"></i><b>42.2</b> Specifying a competing, nested, model</a></li>
<li class="chapter" data-level="42.3" data-path="using-alternative-model-specifications.html"><a href="using-alternative-model-specifications.html#conducting-model-comparisons"><i class="fa fa-check"></i><b>42.3</b> Conducting model comparisons</a></li>
</ul></li>
<li class="chapter" data-level="43" data-path="estimating-factor-scores.html"><a href="estimating-factor-scores.html"><i class="fa fa-check"></i><b>43</b> Estimating factor scores</a></li>
<li class="chapter" data-level="44" data-path="cfa-with-categorical-data.html"><a href="cfa-with-categorical-data.html"><i class="fa fa-check"></i><b>44</b> CFA with categorical data</a>
<ul>
<li class="chapter" data-level="44.1" data-path="cfa-with-categorical-data.html"><a href="cfa-with-categorical-data.html#using-data-from-an-r-package"><i class="fa fa-check"></i><b>44.1</b> Using data from an R package</a></li>
<li class="chapter" data-level="44.2" data-path="cfa-with-categorical-data.html"><a href="cfa-with-categorical-data.html#preparing-the-data"><i class="fa fa-check"></i><b>44.2</b> Preparing the data</a></li>
<li class="chapter" data-level="44.3" data-path="cfa-with-categorical-data.html"><a href="cfa-with-categorical-data.html#describing-the-data-1"><i class="fa fa-check"></i><b>44.3</b> Describing the data</a></li>
<li class="chapter" data-level="44.4" data-path="cfa-with-categorical-data.html"><a href="cfa-with-categorical-data.html#fitting-the-cfa-model"><i class="fa fa-check"></i><b>44.4</b> Fitting the CFA model</a></li>
</ul></li>
<li class="chapter" data-level="45" data-path="way-tldr-summary.html"><a href="way-tldr-summary.html"><i class="fa fa-check"></i><b>45</b> Way TL;DR Summary</a></li>
<li class="chapter" data-level="46" data-path="references-3.html"><a href="references-3.html"><i class="fa fa-check"></i><b>46</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Week 09: Confirmatory Factor Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="normality-assumption" class="section level1 hasAnchor" number="19">
<h1><span class="header-section-number">19</span> Normality Assumption<a href="normality-assumption.html#normality-assumption" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="univariate-normality" class="section level2 hasAnchor" number="19.1">
<h2><span class="header-section-number">19.1</span> Univariate Normality<a href="normality-assumption.html#univariate-normality" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Univariate normality is a necessary but insufficient for multivariate normality. We can explore normality of each dependent variable in each group.<a href="#fn18" class="footnote-ref" id="fnref18"><sup>18</sup></a> First, we could look for univariate outliers, per the example in the reading. After that, let’s examine the kurtosis and skew estimates and plots.</p>
<p>At this point, we’re following Pituch and Stevens’ (and Tabachnick &amp; Fidell’s) approach to analyze assumptions of the <strong>observed dependent-variable data</strong>. The code and interpretations can also be used with the <strong>residual scores</strong> corresponding with each dependent variable, which is addressed later on in this code. I’d actually recommend simply skipping to doing these steps with the residual data, but I’ll follow Pituch and Stevens’ approach first. The primary reason scholars suggest using the observed data is to avoid temptation of looking at the model results, such as with <code>summary(my.fitted.model)</code>, which in R we can avoid by simply not asking for the results even though we have fit the model.</p>
<div id="identifying-univariate-outliers-within-groups" class="section level3 hasAnchor" number="19.1.1">
<h3><span class="header-section-number">19.1.1</span> Identifying univariate outliers within groups<a href="normality-assumption.html#identifying-univariate-outliers-within-groups" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Pituch and Stevens suggested examining <em>z</em>-scores of each variable within each group to identify any plausible outliers. They suggested a <em>z</em>-score greater than 2.5 in magnitude would merit scrutiny, which is approximately equal to a two-tailed test at alpha = .01. This advice is different from that of Tabachnick and Fidell (2013), who suggest a criterion of 3.29, corresponding with an alpha = .001, but also qualify this by saying that we might change this threshold depending on the sample size, as a large sample will more likely yield outliers.<a href="#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a></p>
<p>To get standardized scores, we can use the <code>scale()</code> function for each variable separately.<a href="#fn20" class="footnote-ref" id="fnref20"><sup>20</sup></a> In the code below, we use the dplyr package to calculate the <em>z</em>-scores and create a dummy variable that indicates which are outliers based on the criterion Pituch and Stevens suggested.</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="normality-assumption.html#cb83-1" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb83-2"><a href="normality-assumption.html#cb83-2" tabindex="-1"></a>datz <span class="ot">&lt;-</span> dat <span class="sc">%&gt;%</span> </span>
<span id="cb83-3"><a href="normality-assumption.html#cb83-3" tabindex="-1"></a>  <span class="fu">group_by</span>(gp) <span class="sc">%&gt;%</span> </span>
<span id="cb83-4"><a href="normality-assumption.html#cb83-4" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">y1.z =</span> <span class="fu">scale</span>(y1),</span>
<span id="cb83-5"><a href="normality-assumption.html#cb83-5" tabindex="-1"></a>         <span class="at">y2.z =</span> <span class="fu">scale</span>(y2),</span>
<span id="cb83-6"><a href="normality-assumption.html#cb83-6" tabindex="-1"></a>         <span class="at">y3.z =</span> <span class="fu">scale</span>(y3),</span>
<span id="cb83-7"><a href="normality-assumption.html#cb83-7" tabindex="-1"></a>         <span class="at">outlier_uni =</span> <span class="fu">if_else</span>(<span class="fu">abs</span>(y1.z) <span class="sc">&gt;</span> <span class="fl">2.5</span> <span class="sc">|</span></span>
<span id="cb83-8"><a href="normality-assumption.html#cb83-8" tabindex="-1"></a>                               <span class="fu">abs</span>(y2.z) <span class="sc">&gt;</span> <span class="fl">2.5</span> <span class="sc">|</span></span>
<span id="cb83-9"><a href="normality-assumption.html#cb83-9" tabindex="-1"></a>                               <span class="fu">abs</span>(y3.z) <span class="sc">&gt;</span> <span class="fl">2.5</span>, <span class="dv">1</span>, <span class="dv">0</span>))</span>
<span id="cb83-10"><a href="normality-assumption.html#cb83-10" tabindex="-1"></a>datz <span class="sc">%&gt;%</span> <span class="fu">filter</span>(outlier_uni <span class="sc">==</span> <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## # A tibble: 3 × 9
## # Groups:   gp [2]
##      id gp       y1    y2    y3 y1.z[,1] y2.z[,1] y3.z[,1] outlier_uni
##   &lt;int&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;
## 1     9 1      29.1  15.1  3.28     3.52    1.67    -1.69            1
## 2    21 1      26.2  17.4 16.9      2.91    2.23     1.95            1
## 3    52 2      15.9  12.9 19.1      2.77    0.421    0.135           1</code></pre>
<p>We see three cases we could flag as outliers, all on <code>y1</code>. Two of these cases (Cases 9 &amp; 21) are in Group 1; one (Case 52) was in Group 2. These <em>z</em>-scores are not terribly excessive—only Case 9 exceeds the criterion of 3.29. We could examine these data to see if there was a data-entry error. Let’s assume it was not and carry on by seeing if these same cases show up in our examination of multivariate normality.</p>
</div>
<div id="kurtosis-and-skew" class="section level3 hasAnchor" number="19.1.2">
<h3><span class="header-section-number">19.1.2</span> Kurtosis and skew<a href="normality-assumption.html#kurtosis-and-skew" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We used the psych package above when we used the <code>describeBy()</code> function. We could simply interpret those and use the absolute value of 2 as the criterion. Looking at that, we see that on <code>y1</code>, Group 1 has a kurtosis exceeding the magnitude of 2.00. It is positive, indicating leptokurtosis (too much pointiness), which becomes less problematic with samples greater than 100 or so; a platykurtic skew, which has thick tails, underestimates the sample’s variance until about a sample size of 200 (Tabachnick &amp; Fidell, 2013, p. 80, cite Waternaux, 1976). Based on the univariate kurtosis and skew estimates of <code>y2</code> and <code>y3</code>, we do not see evidence that these two variables differ from normality within each group.</p>
<p>We could also use confidence intervals to determine if the kurtosis and skew are outside of an expected range that might constitute normality. The DescTools package can provide these confidence intervals; they suggest using the bootstrap estimator, <code>bca</code> for the confidence intervals. Here’s an example of skew with the first dependent variable only:</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="normality-assumption.html#cb85-1" tabindex="-1"></a><span class="fu">library</span>(DescTools)</span>
<span id="cb85-2"><a href="normality-assumption.html#cb85-2" tabindex="-1"></a><span class="fu">tapply</span>(dat<span class="sc">$</span>y1,</span>
<span id="cb85-3"><a href="normality-assumption.html#cb85-3" tabindex="-1"></a>       dat<span class="sc">$</span>gp,</span>
<span id="cb85-4"><a href="normality-assumption.html#cb85-4" tabindex="-1"></a>       DescTools<span class="sc">::</span>Kurt, </span>
<span id="cb85-5"><a href="normality-assumption.html#cb85-5" tabindex="-1"></a>       <span class="at">method =</span> <span class="dv">3</span> , <span class="co"># Use method 2 if you want the same result as SPSS </span></span>
<span id="cb85-6"><a href="normality-assumption.html#cb85-6" tabindex="-1"></a>       <span class="at">conf.level =</span> .<span class="dv">95</span>,</span>
<span id="cb85-7"><a href="normality-assumption.html#cb85-7" tabindex="-1"></a>       <span class="at">ci.type =</span> <span class="st">&quot;bca&quot;</span>)</span></code></pre></div>
<pre><code>## $`1`
##       kurt     lwr.ci     upr.ci 
##  3.6784860 -0.1136231  9.9966050 
## 
## $`2`
##       kurt     lwr.ci     upr.ci 
##  0.5480051 -0.9553924  4.9379932</code></pre>
<p>The 3.68 kurtosis for Group 1 on this variable is within their confidence interval, suggesting it might not be enough to flag non-normality.</p>
</div>
<div id="examining-univariate-normality-using-density-plots" class="section level3 hasAnchor" number="19.1.3">
<h3><span class="header-section-number">19.1.3</span> Examining univariate normality using density plots<a href="normality-assumption.html#examining-univariate-normality-using-density-plots" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can examine plots of each variable, by group. First, let’s examine density plots of each variable, within each group, and compare that to the theoretical normal distribution. For this, the easiest way seems to be with the ggpubr package, which has the <code>ggdensity()</code> function instead of the <code>ggplot()</code> function we usually use.<a href="#fn21" class="footnote-ref" id="fnref21"><sup>21</sup></a></p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="normality-assumption.html#cb87-1" tabindex="-1"></a><span class="fu">library</span>(ggpubr)</span>
<span id="cb87-2"><a href="normality-assumption.html#cb87-2" tabindex="-1"></a>dat <span class="sc">%&gt;%</span> </span>
<span id="cb87-3"><a href="normality-assumption.html#cb87-3" tabindex="-1"></a>  <span class="fu">filter</span>(gp <span class="sc">==</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span>       <span class="co"># subset to Group 1, using dplyr.</span></span>
<span id="cb87-4"><a href="normality-assumption.html#cb87-4" tabindex="-1"></a><span class="fu">ggdensity</span>(<span class="at">x =</span> <span class="st">&quot;y1&quot;</span>,         <span class="co"># specify which variable.</span></span>
<span id="cb87-5"><a href="normality-assumption.html#cb87-5" tabindex="-1"></a>          <span class="at">fill =</span> <span class="st">&quot;gray50&quot;</span>,  <span class="co"># observed density is colored gray.</span></span>
<span id="cb87-6"><a href="normality-assumption.html#cb87-6" tabindex="-1"></a>          <span class="at">color =</span> <span class="st">&quot;white&quot;</span>,  <span class="co"># remove line from observed density plot</span></span>
<span id="cb87-7"><a href="normality-assumption.html#cb87-7" tabindex="-1"></a>          <span class="at">title =</span> <span class="st">&quot;Gasoline trucks&quot;</span>) <span class="sc">+</span> </span>
<span id="cb87-8"><a href="normality-assumption.html#cb87-8" tabindex="-1"></a>  <span class="co"># I know `gp == 1` matches gasoline trucks, so I use `title = `.</span></span>
<span id="cb87-9"><a href="normality-assumption.html#cb87-9" tabindex="-1"></a>  <span class="co"># And, here&#39;s the theoretical normal density line, layered on top:</span></span>
<span id="cb87-10"><a href="normality-assumption.html#cb87-10" tabindex="-1"></a>  <span class="fu">stat_overlay_normal_density</span>(<span class="at">color =</span> <span class="st">&quot;darkred&quot;</span>)</span></code></pre></div>
<p><img src="multivariate_stats_files/figure-html/unnamed-chunk-65-1.png" width="672" /></p>
<p>We can see that compared to a theoretical normal distribution, the distribution of <code>y1</code> with the Gasoline-truck group is leptokurtic (too peaked) and positively skewed. This is consistent with the skew and kurtosis reported in the <code>describeBy()</code> function earlier, 1.71 and 3.68 respectively. The two outliers seem to be responsible for this bump on the right side.</p>
<p>We can do this for every group and every variable. Here’s the diesel group with <code>y1</code>.</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="normality-assumption.html#cb88-1" tabindex="-1"></a>dat <span class="sc">%&gt;%</span> </span>
<span id="cb88-2"><a href="normality-assumption.html#cb88-2" tabindex="-1"></a>  <span class="fu">filter</span>(gp <span class="sc">==</span> <span class="dv">2</span>) <span class="sc">%&gt;%</span>       </span>
<span id="cb88-3"><a href="normality-assumption.html#cb88-3" tabindex="-1"></a><span class="fu">ggdensity</span>(<span class="at">x =</span> <span class="st">&quot;y1&quot;</span>,         </span>
<span id="cb88-4"><a href="normality-assumption.html#cb88-4" tabindex="-1"></a>          <span class="at">fill =</span> <span class="st">&quot;gray50&quot;</span>,  </span>
<span id="cb88-5"><a href="normality-assumption.html#cb88-5" tabindex="-1"></a>          <span class="at">color =</span> <span class="st">&quot;white&quot;</span>,  </span>
<span id="cb88-6"><a href="normality-assumption.html#cb88-6" tabindex="-1"></a>          <span class="at">title =</span> <span class="st">&quot;Diesel trucks&quot;</span>,</span>
<span id="cb88-7"><a href="normality-assumption.html#cb88-7" tabindex="-1"></a>          <span class="at">xlab =</span> <span class="st">&quot;Fuel costs&quot;</span>) <span class="sc">+</span> </span>
<span id="cb88-8"><a href="normality-assumption.html#cb88-8" tabindex="-1"></a>  <span class="fu">stat_overlay_normal_density</span>(<span class="at">color =</span> <span class="st">&quot;darkred&quot;</span>)</span></code></pre></div>
<p><img src="multivariate_stats_files/figure-html/unnamed-chunk-66-1.png" width="672" />
The second group’s scores on this variable seem to come from a population with a normal distribution.<a href="#fn22" class="footnote-ref" id="fnref22"><sup>22</sup></a> We see a little bump on the right hand side, probably caused by that outlier we found with the <em>z</em>-scores.</p>
<p>We can also display both groups in a plot as separate panels (or facets). Here, we’re adding the <code>facet.by =</code> argument from this function (which is specific to this function, in looking at <code>?ggdensity</code>), with the group variable in our data, <code>gp</code>, plot the two groups next to each other in their respective panel of the plot. Then, we’re making the label of the panel more informative with <code>panel.labs = list(gp = c("Gasoline", "Diesel"))</code>, where the <code>gp</code> here is, again, the name of the group variable in our data set.</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="normality-assumption.html#cb89-1" tabindex="-1"></a>dat <span class="sc">%&gt;%</span> </span>
<span id="cb89-2"><a href="normality-assumption.html#cb89-2" tabindex="-1"></a><span class="fu">ggdensity</span>(<span class="at">x =</span> <span class="st">&quot;y1&quot;</span>,</span>
<span id="cb89-3"><a href="normality-assumption.html#cb89-3" tabindex="-1"></a>          <span class="at">fill =</span> <span class="st">&quot;gray50&quot;</span>,</span>
<span id="cb89-4"><a href="normality-assumption.html#cb89-4" tabindex="-1"></a>          <span class="at">color =</span> <span class="st">&quot;white&quot;</span>,  </span>
<span id="cb89-5"><a href="normality-assumption.html#cb89-5" tabindex="-1"></a>          <span class="at">xlab =</span> <span class="st">&quot;Fuel costs&quot;</span>,</span>
<span id="cb89-6"><a href="normality-assumption.html#cb89-6" tabindex="-1"></a>          <span class="at">facet.by =</span> <span class="st">&quot;gp&quot;</span>, </span>
<span id="cb89-7"><a href="normality-assumption.html#cb89-7" tabindex="-1"></a>          <span class="at">panel.labs =</span> <span class="fu">list</span>(<span class="at">gp =</span> <span class="fu">c</span>(<span class="st">&quot;Gasoline&quot;</span>, <span class="st">&quot;Diesel&quot;</span>)) ) <span class="sc">+</span> </span>
<span id="cb89-8"><a href="normality-assumption.html#cb89-8" tabindex="-1"></a>  <span class="fu">stat_overlay_normal_density</span>(<span class="at">color =</span> <span class="st">&quot;darkred&quot;</span>)</span></code></pre></div>
<p><img src="multivariate_stats_files/figure-html/unnamed-chunk-67-1.png" width="672" /></p>
<p>The one problem with this layout is that the y-axis is on the same scale for both variables, which seems to stretch the y-axis scale so it appears as though the second group is excessively leptokurtic. However, by comparing this to the superimposed normal curve, we see it is not too peaked.</p>
<p>Let’s look at the other two variables:</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="normality-assumption.html#cb90-1" tabindex="-1"></a>dat <span class="sc">%&gt;%</span> </span>
<span id="cb90-2"><a href="normality-assumption.html#cb90-2" tabindex="-1"></a><span class="fu">ggdensity</span>(<span class="at">x =</span> <span class="st">&quot;y2&quot;</span>,</span>
<span id="cb90-3"><a href="normality-assumption.html#cb90-3" tabindex="-1"></a>          <span class="at">fill =</span> <span class="st">&quot;gray50&quot;</span>,</span>
<span id="cb90-4"><a href="normality-assumption.html#cb90-4" tabindex="-1"></a>          <span class="at">color =</span> <span class="st">&quot;white&quot;</span>,  </span>
<span id="cb90-5"><a href="normality-assumption.html#cb90-5" tabindex="-1"></a>          <span class="at">xlab =</span> <span class="st">&quot;Repair costs&quot;</span>,</span>
<span id="cb90-6"><a href="normality-assumption.html#cb90-6" tabindex="-1"></a>          <span class="at">facet.by =</span> <span class="st">&quot;gp&quot;</span>, </span>
<span id="cb90-7"><a href="normality-assumption.html#cb90-7" tabindex="-1"></a>          <span class="at">panel.labs =</span> <span class="fu">list</span>(<span class="at">gp =</span> <span class="fu">c</span>(<span class="st">&quot;Gasoline&quot;</span>, <span class="st">&quot;Diesel&quot;</span>)) ) <span class="sc">+</span> </span>
<span id="cb90-8"><a href="normality-assumption.html#cb90-8" tabindex="-1"></a>  <span class="fu">stat_overlay_normal_density</span>(<span class="at">color =</span> <span class="st">&quot;darkred&quot;</span>)</span></code></pre></div>
<p><img src="multivariate_stats_files/figure-html/unnamed-chunk-68-1.png" width="672" /></p>
<p>Although the observed density plots look truncated, with some fat tails, we do see support for the conclusion that the sample data are drawn from a population of normally distributed data.</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="normality-assumption.html#cb91-1" tabindex="-1"></a>dat <span class="sc">%&gt;%</span> </span>
<span id="cb91-2"><a href="normality-assumption.html#cb91-2" tabindex="-1"></a><span class="fu">ggdensity</span>(<span class="at">x =</span> <span class="st">&quot;y3&quot;</span>,</span>
<span id="cb91-3"><a href="normality-assumption.html#cb91-3" tabindex="-1"></a>          <span class="at">fill =</span> <span class="st">&quot;gray50&quot;</span>,</span>
<span id="cb91-4"><a href="normality-assumption.html#cb91-4" tabindex="-1"></a>          <span class="at">color =</span> <span class="st">&quot;white&quot;</span>,  </span>
<span id="cb91-5"><a href="normality-assumption.html#cb91-5" tabindex="-1"></a>          <span class="at">xlab =</span> <span class="st">&quot;Capital costs&quot;</span>,</span>
<span id="cb91-6"><a href="normality-assumption.html#cb91-6" tabindex="-1"></a>          <span class="at">facet.by =</span> <span class="st">&quot;gp&quot;</span>, </span>
<span id="cb91-7"><a href="normality-assumption.html#cb91-7" tabindex="-1"></a>          <span class="at">panel.labs =</span> <span class="fu">list</span>(<span class="at">gp =</span> <span class="fu">c</span>(<span class="st">&quot;Gasoline&quot;</span>, <span class="st">&quot;Diesel&quot;</span>)) ) <span class="sc">+</span> </span>
<span id="cb91-8"><a href="normality-assumption.html#cb91-8" tabindex="-1"></a>  <span class="fu">stat_overlay_normal_density</span>(<span class="at">color =</span> <span class="st">&quot;darkred&quot;</span>)</span></code></pre></div>
<p><img src="multivariate_stats_files/figure-html/unnamed-chunk-69-1.png" width="672" /></p>
<p>These plots also suggest the sample data seem to come from a population of normally distributed data.</p>
</div>
</div>
<div id="examining-univariate-normality-using-quantile-quantile-plots" class="section level2 hasAnchor" number="19.2">
<h2><span class="header-section-number">19.2</span> Examining univariate normality using quantile-quantile plots<a href="normality-assumption.html#examining-univariate-normality-using-quantile-quantile-plots" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Quantile-quantile plots are probably the most useful for examining normality. They’re a little less work than the density plots, too. If you want a refresher on what quantiles are and how Q-Q plots are generated, Josh Starmer has a couple of videos: one on quantiles, <a href="https://www.youtube.com/watch?v=IFKQLDmRK0Y">linked to here</a>, and one on Q-Q plots, <a href="https://www.youtube.com/watch?v=okjYjClSjOg">linked to here</a>.</p>
<p>Here’s a plot of the first group with the first variable:</p>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="normality-assumption.html#cb92-1" tabindex="-1"></a>dat <span class="sc">%&gt;%</span> </span>
<span id="cb92-2"><a href="normality-assumption.html#cb92-2" tabindex="-1"></a>  <span class="fu">filter</span>(gp <span class="sc">==</span> <span class="st">&quot;1&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb92-3"><a href="normality-assumption.html#cb92-3" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">sample =</span> y1)) <span class="sc">+</span></span>
<span id="cb92-4"><a href="normality-assumption.html#cb92-4" tabindex="-1"></a>  <span class="fu">stat_qq</span>() <span class="sc">+</span></span>
<span id="cb92-5"><a href="normality-assumption.html#cb92-5" tabindex="-1"></a>  <span class="fu">stat_qq_line</span>() <span class="sc">+</span></span>
<span id="cb92-6"><a href="normality-assumption.html#cb92-6" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="st">&quot;Norm quantiles&quot;</span>) <span class="sc">+</span></span>
<span id="cb92-7"><a href="normality-assumption.html#cb92-7" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="st">&quot;Sample quantiles&quot;</span>) <span class="sc">+</span> </span>
<span id="cb92-8"><a href="normality-assumption.html#cb92-8" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Gasoline trucks&quot;</span>)</span></code></pre></div>
<p><img src="multivariate_stats_files/figure-html/unnamed-chunk-70-1.png" width="672" /></p>
<p>We see the effect of those two outliers on the plot in Group 1 (gasoline trucks). Their scores are much higher than we would expect if the data were from a normal distribution. Without them, it would look normal.</p>
<p>Here’s the second group:</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="normality-assumption.html#cb93-1" tabindex="-1"></a>dat <span class="sc">%&gt;%</span> </span>
<span id="cb93-2"><a href="normality-assumption.html#cb93-2" tabindex="-1"></a>  <span class="fu">filter</span>(gp <span class="sc">==</span> <span class="st">&quot;2&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb93-3"><a href="normality-assumption.html#cb93-3" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">sample =</span> y1)) <span class="sc">+</span></span>
<span id="cb93-4"><a href="normality-assumption.html#cb93-4" tabindex="-1"></a>  <span class="fu">stat_qq</span>() <span class="sc">+</span></span>
<span id="cb93-5"><a href="normality-assumption.html#cb93-5" tabindex="-1"></a>  <span class="fu">stat_qq_line</span>() <span class="sc">+</span></span>
<span id="cb93-6"><a href="normality-assumption.html#cb93-6" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="st">&quot;Norm quantiles&quot;</span>) <span class="sc">+</span></span>
<span id="cb93-7"><a href="normality-assumption.html#cb93-7" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="st">&quot;Sample quantiles&quot;</span>) <span class="sc">+</span> </span>
<span id="cb93-8"><a href="normality-assumption.html#cb93-8" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Diesel trucks&quot;</span>)</span></code></pre></div>
<p><img src="multivariate_stats_files/figure-html/unnamed-chunk-71-1.png" width="672" /></p>
<p>In Group 2, <code>y1</code> looks normal enough, with most of the scores very close to the line, though there is one observation with a score that is unexpectedly high.</p>
<p>We could use ggplot for the other four plots. Let’s look at a function from the car package that also provides some error bands:</p>
<div id="univariate-q-q-plots-from-other-packages" class="section level3 hasAnchor" number="19.2.1">
<h3><span class="header-section-number">19.2.1</span> Univariate Q-Q plots from other packages<a href="normality-assumption.html#univariate-q-q-plots-from-other-packages" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The car package’s <code>qqPlot()</code> is convenient in that it includes an error band for interpreting points that are off the line, and it labels outliers. This approach requires the input be a matrix or vector (not a data frame, as ggplot requires). For this, we need to change our group variable to be numeric and create a matrix with group and our dependent variables:</p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="normality-assumption.html#cb94-1" tabindex="-1"></a>ym <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">gp =</span> <span class="fu">as.numeric</span>(dat<span class="sc">$</span>gp), dat[, <span class="dv">3</span><span class="sc">:</span><span class="dv">5</span>])</span>
<span id="cb94-2"><a href="normality-assumption.html#cb94-2" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb94-3"><a href="normality-assumption.html#cb94-3" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">qqPlot</span>(ym[,<span class="dv">2</span>], <span class="at">ylab =</span> <span class="st">&quot;Y1&quot;</span>, <span class="at">groups =</span> ym[,<span class="dv">1</span>])</span></code></pre></div>
<p><img src="multivariate_stats_files/figure-html/unnamed-chunk-72-1.png" width="672" /></p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="normality-assumption.html#cb95-1" tabindex="-1"></a><span class="co"># For the other two variables:</span></span>
<span id="cb95-2"><a href="normality-assumption.html#cb95-2" tabindex="-1"></a><span class="co"># car::qqPlot(ym[,3], ylab = &quot;Y2&quot;, groups = ym[,1])</span></span>
<span id="cb95-3"><a href="normality-assumption.html#cb95-3" tabindex="-1"></a><span class="co"># car::qqPlot(ym[,4], ylab = &quot;Y3&quot;, groups = ym[,1])</span></span></code></pre></div>
<p>This also labels the row number of the observations that might be flagged as outliers. We see results that are consistent with the above plots. This was only with the first dependent variable; we’d use the same code with the other two.</p>
<p>Another package we could use is ggpubr, with the <code>ggqqplot()</code> function. We used this package with our density plots. This is convenient because we don’t have to change the data into matrix format:</p>
<p>Here’s are all the plots with this package:</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="normality-assumption.html#cb96-1" tabindex="-1"></a><span class="fu">library</span>(ggpubr)</span>
<span id="cb96-2"><a href="normality-assumption.html#cb96-2" tabindex="-1"></a>dat <span class="sc">%&gt;%</span> </span>
<span id="cb96-3"><a href="normality-assumption.html#cb96-3" tabindex="-1"></a>  <span class="fu">filter</span>(gp <span class="sc">==</span> <span class="st">&quot;1&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb96-4"><a href="normality-assumption.html#cb96-4" tabindex="-1"></a>  <span class="fu">ggqqplot</span>(<span class="at">x =</span> <span class="st">&quot;y1&quot;</span>,</span>
<span id="cb96-5"><a href="normality-assumption.html#cb96-5" tabindex="-1"></a>           <span class="at">title =</span> <span class="st">&quot;Gasoline trucks&#39; fuel costs&quot;</span>) </span></code></pre></div>
<p><img src="multivariate_stats_files/figure-html/unnamed-chunk-73-1.png" width="672" /></p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb97-1"><a href="normality-assumption.html#cb97-1" tabindex="-1"></a>dat <span class="sc">%&gt;%</span> </span>
<span id="cb97-2"><a href="normality-assumption.html#cb97-2" tabindex="-1"></a>  <span class="fu">filter</span>(gp <span class="sc">==</span> <span class="st">&quot;2&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb97-3"><a href="normality-assumption.html#cb97-3" tabindex="-1"></a>  <span class="fu">ggqqplot</span>(<span class="at">x =</span> <span class="st">&quot;y1&quot;</span>,</span>
<span id="cb97-4"><a href="normality-assumption.html#cb97-4" tabindex="-1"></a>           <span class="at">title =</span> <span class="st">&quot;Diesel trucks&#39; fuel costs&quot;</span>) </span></code></pre></div>
<p><img src="multivariate_stats_files/figure-html/unnamed-chunk-73-2.png" width="672" /></p>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="normality-assumption.html#cb98-1" tabindex="-1"></a>dat <span class="sc">%&gt;%</span> </span>
<span id="cb98-2"><a href="normality-assumption.html#cb98-2" tabindex="-1"></a>  <span class="fu">filter</span>(gp <span class="sc">==</span> <span class="st">&quot;1&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb98-3"><a href="normality-assumption.html#cb98-3" tabindex="-1"></a>  <span class="fu">ggqqplot</span>(<span class="at">x =</span> <span class="st">&quot;y2&quot;</span>,</span>
<span id="cb98-4"><a href="normality-assumption.html#cb98-4" tabindex="-1"></a>           <span class="at">title =</span> <span class="st">&quot;Gasoline trucks&#39; repair costs&quot;</span>) </span></code></pre></div>
<p><img src="multivariate_stats_files/figure-html/unnamed-chunk-73-3.png" width="672" /></p>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb99-1"><a href="normality-assumption.html#cb99-1" tabindex="-1"></a>dat <span class="sc">%&gt;%</span> </span>
<span id="cb99-2"><a href="normality-assumption.html#cb99-2" tabindex="-1"></a>  <span class="fu">filter</span>(gp <span class="sc">==</span> <span class="st">&quot;2&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb99-3"><a href="normality-assumption.html#cb99-3" tabindex="-1"></a>  <span class="fu">ggqqplot</span>(<span class="at">x =</span> <span class="st">&quot;y2&quot;</span>,</span>
<span id="cb99-4"><a href="normality-assumption.html#cb99-4" tabindex="-1"></a>           <span class="at">title =</span> <span class="st">&quot;Diesel trucks&#39; repair costs&quot;</span>) </span></code></pre></div>
<p><img src="multivariate_stats_files/figure-html/unnamed-chunk-73-4.png" width="672" /></p>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="normality-assumption.html#cb100-1" tabindex="-1"></a>dat <span class="sc">%&gt;%</span> </span>
<span id="cb100-2"><a href="normality-assumption.html#cb100-2" tabindex="-1"></a>  <span class="fu">filter</span>(gp <span class="sc">==</span> <span class="st">&quot;1&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb100-3"><a href="normality-assumption.html#cb100-3" tabindex="-1"></a>  <span class="fu">ggqqplot</span>(<span class="at">x =</span> <span class="st">&quot;y3&quot;</span>,</span>
<span id="cb100-4"><a href="normality-assumption.html#cb100-4" tabindex="-1"></a>           <span class="at">title =</span> <span class="st">&quot;Gasoline trucks&#39; capital costs&quot;</span>) </span></code></pre></div>
<p><img src="multivariate_stats_files/figure-html/unnamed-chunk-73-5.png" width="672" /></p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="normality-assumption.html#cb101-1" tabindex="-1"></a>dat <span class="sc">%&gt;%</span> </span>
<span id="cb101-2"><a href="normality-assumption.html#cb101-2" tabindex="-1"></a>  <span class="fu">filter</span>(gp <span class="sc">==</span> <span class="st">&quot;2&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb101-3"><a href="normality-assumption.html#cb101-3" tabindex="-1"></a>  <span class="fu">ggqqplot</span>(<span class="at">x =</span> <span class="st">&quot;y3&quot;</span>,</span>
<span id="cb101-4"><a href="normality-assumption.html#cb101-4" tabindex="-1"></a>           <span class="at">title =</span> <span class="st">&quot;Diesel trucks&#39; capital costs&quot;</span>) </span></code></pre></div>
<p><img src="multivariate_stats_files/figure-html/unnamed-chunk-73-6.png" width="672" /></p>
<p>This one does <em>not</em> label the outliers, which is why I like the car package’s version better.</p>
<p>If I were in a hurry and I needed to assess univariate normality, I’d simply look at the Q-Q plots from the car package. If I wanted to publish something pretty, I’d use ggplot or ggpubr’s ggqqplot, and I’d display the density plots with the normal distribution layered over them for comparison.</p>
</div>
<div id="statistical-tests-of-univariate-normality" class="section level3 hasAnchor" number="19.2.2">
<h3><span class="header-section-number">19.2.2</span> Statistical tests of univariate normality<a href="normality-assumption.html#statistical-tests-of-univariate-normality" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>There are also statistical tests of normality. The Shapiro–Wilk test seems to be well regarded. To demonstrate, let’s examine <code>y1</code> with Group 1:</p>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="normality-assumption.html#cb102-1" tabindex="-1"></a>g1 <span class="ot">&lt;-</span> <span class="fu">subset</span>(dat, gp <span class="sc">==</span> <span class="dv">1</span>, <span class="at">select =</span> <span class="fu">c</span>(<span class="st">&quot;y1&quot;</span>, <span class="st">&quot;y2&quot;</span>, <span class="st">&quot;y3&quot;</span>))</span>
<span id="cb102-2"><a href="normality-assumption.html#cb102-2" tabindex="-1"></a><span class="fu">shapiro.test</span>(g1<span class="sc">$</span>y1)</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  g1$y1
## W = 0.83672, p-value = 9.555e-05</code></pre>
<p>The <em>p</em>-value below our critical alpha of .05 indicates that for Group 1, we can reject the null hypothesis that <code>y1</code> is from a normal distribution. We don’t like this result.</p>
<p>Let’s look at Group 2 on this same variable:</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="normality-assumption.html#cb104-1" tabindex="-1"></a><span class="fu">shapiro.test</span>(g1<span class="sc">$</span>y2)</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  g1$y2
## W = 0.96282, p-value = 0.2623</code></pre>
<p>The same test with Group 2 did not reject the null hypothesis, which indicates we do not have evidence to suggest <code>y1</code> differs from normality. We would do this test by-group for the other two variables and hope we got non-significance.<a href="#fn23" class="footnote-ref" id="fnref23"><sup>23</sup></a></p>
</div>
</div>
<div id="a-caution-about-statistical-tests-of-statistical-assumptions" class="section level2 hasAnchor" number="19.3">
<h2><span class="header-section-number">19.3</span> A caution about statistical tests of statistical assumptions<a href="normality-assumption.html#a-caution-about-statistical-tests-of-statistical-assumptions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As with most (or all) statistical tests of statistical assumptions, we are arguing for the null hypothesis, which is kind of antithetical to null-hypothesis statistical testing but that’s how it seems to be done.</p>
<p>With small sample sizes, statistical tests like Shapiro-Wilk show non-significance even when the data are not normal. With large sample sizes, they’re too sensitive to deviations from normality. With this, statistical tests of normality should not be the primary source of evidence for evaluating this assumption.</p>
</div>
<div id="mahalanobis-distance-and-multivariate-outliers" class="section level2 hasAnchor" number="19.4">
<h2><span class="header-section-number">19.4</span> Mahalanobis Distance and Multivariate Outliers<a href="normality-assumption.html#mahalanobis-distance-and-multivariate-outliers" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We can calculate each observation’s Mahalanobis distance. I think of this as the observation’s degree of weirdness compared to the rest of the data. This is a function of leverage, which was addressed in multiple regression.</p>
<!-- $$\text{Mahalanobis distance} = (N - 1)(h_{ii} - 1/N)$$ -->
<!-- where $h_{ii}$ (or "RHAT") is the leverage.  -->
<p>Mahalanobis distances are in squared units, so we use a chi-square distribution instead of a normal distribution with quantiles in our Q-Q plots. The <code>mahalanobis()</code> function from Base R has three arguments: the matrix of multivariate variables, the means of those those variables (in <code>center=</code>), and the covariance matrix of those variables.<a href="#fn24" class="footnote-ref" id="fnref24"><sup>24</sup></a> We’ll create a matrix of our dependent variables for the first argument and use the <code>colMeans()</code> and <code>cov()</code> functions to get the latter two.</p>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="normality-assumption.html#cb106-1" tabindex="-1"></a>dvs <span class="ot">&lt;-</span> <span class="fu">cbind</span>(dat[,<span class="fu">c</span>(<span class="st">&quot;y1&quot;</span>,<span class="st">&quot;y2&quot;</span>,<span class="st">&quot;y3&quot;</span>)])</span>
<span id="cb106-2"><a href="normality-assumption.html#cb106-2" tabindex="-1"></a>distances <span class="ot">&lt;-</span> <span class="fu">mahalanobis</span>(dvs, </span>
<span id="cb106-3"><a href="normality-assumption.html#cb106-3" tabindex="-1"></a>                         <span class="at">center =</span> <span class="fu">colMeans</span>(dvs), </span>
<span id="cb106-4"><a href="normality-assumption.html#cb106-4" tabindex="-1"></a>                         <span class="at">cov =</span> <span class="fu">cov</span>(dvs))</span></code></pre></div>
<p>Each observation has a multivariate distance, so let’s save it to the data frame:</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="normality-assumption.html#cb107-1" tabindex="-1"></a>dat<span class="sc">$</span>distancesraw <span class="ot">&lt;-</span> distances</span></code></pre></div>
<p>We might notice that for some observations, they have really high Mahalanobis distance values. We could sort them from high to low to see if there is a quick descent before it then levels out:</p>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="normality-assumption.html#cb108-1" tabindex="-1"></a><span class="fu">sort</span>(dat<span class="sc">$</span>distancesraw, <span class="at">decreasing =</span> <span class="cn">TRUE</span>)[<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>] <span class="co"># first 20 observations</span></span></code></pre></div>
<pre><code>##  [1] 20.369430 13.881471 12.473991 11.967188  9.750828  5.731465  5.132105  4.292636  3.937175
## [10]  3.885500  3.418971  3.413827  2.976672  2.950409  2.940999  2.823275  2.647751  2.496250
## [19]  2.491660  2.472095</code></pre>
<div id="outliers" class="section level3 hasAnchor" number="19.4.1">
<h3><span class="header-section-number">19.4.1</span> Outliers<a href="normality-assumption.html#outliers" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>There is a standard way to see if they are outliers. We calculate the <em>p</em>-value of that Mahalanobis distance, from a chi-square distribution with <span class="math inline">\(p-1\)</span> degrees of freedom (where <em>p</em> = number of dependent variables), and use <span class="math inline">\(p &lt; .001\)</span> as a criterion for identifying an outlier.</p>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="normality-assumption.html#cb110-1" tabindex="-1"></a>dat<span class="sc">$</span>p <span class="ot">&lt;-</span> <span class="fu">pchisq</span>(distances, </span>
<span id="cb110-2"><a href="normality-assumption.html#cb110-2" tabindex="-1"></a>                <span class="at">df =</span> (<span class="fu">ncol</span>(dvs)<span class="sc">-</span><span class="dv">1</span>), <span class="co"># df is number of variables - 1</span></span>
<span id="cb110-3"><a href="normality-assumption.html#cb110-3" tabindex="-1"></a>                <span class="at">lower.tail=</span><span class="cn">FALSE</span>)</span></code></pre></div>
<p>Let’s flag any cases with a <em>p</em>-value lower than our alpha = .001 criterion. In this code, we’re using <code>ifelse()</code> to dummy code any cases with criterion as <code>1</code> and <code>0</code> otherwise. Then, we’re requesting rows of the data that have a value of <code>1</code> on this new variable.</p>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="normality-assumption.html#cb111-1" tabindex="-1"></a>dat<span class="sc">$</span>outlier <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(dat<span class="sc">$</span>p <span class="sc">&lt;</span> .<span class="dv">001</span>, </span>
<span id="cb111-2"><a href="normality-assumption.html#cb111-2" tabindex="-1"></a>                      <span class="dv">1</span>, <span class="co"># the case gets a 1 if p &lt; .001</span></span>
<span id="cb111-3"><a href="normality-assumption.html#cb111-3" tabindex="-1"></a>                      <span class="dv">0</span>) <span class="co"># otherwise, the value on this new variable is 0</span></span>
<span id="cb111-4"><a href="normality-assumption.html#cb111-4" tabindex="-1"></a><span class="co"># We can see two outliers here:</span></span>
<span id="cb111-5"><a href="normality-assumption.html#cb111-5" tabindex="-1"></a>dat[dat<span class="sc">$</span>outlier <span class="sc">==</span> <span class="dv">1</span>, ]</span></code></pre></div>
<pre><code>##    id gp    y1    y2    y3 distancesraw            p outlier
## 9   9  1 29.11 15.09  3.28     20.36943 3.774282e-05       1
## 21 21  1 26.16 17.44 16.89     13.88147 9.675577e-04       1</code></pre>
<p>Not surprisingly, these are the two pains in the neck in our univariate analysis. Out liars, out!</p>
<p>The Mahalanobis distances are in squared units. The car package has a function we can use for this to generate a kind of Q-Q plot. Instead of a normal distribution of quantiles on the X axis, we can specify a chi-squared distribution. Everitt and Hothorn (2011) use similar procedures to obtain the same type of plot.</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="normality-assumption.html#cb113-1" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb113-2"><a href="normality-assumption.html#cb113-2" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">qqPlot</span>(distances, </span>
<span id="cb113-3"><a href="normality-assumption.html#cb113-3" tabindex="-1"></a>            <span class="at">distribution =</span> <span class="st">&quot;chisq&quot;</span>, <span class="at">df =</span> <span class="fu">mean</span>(distances), </span>
<span id="cb113-4"><a href="normality-assumption.html#cb113-4" tabindex="-1"></a>            <span class="at">lwd =</span> <span class="dv">1</span>, </span>
<span id="cb113-5"><a href="normality-assumption.html#cb113-5" tabindex="-1"></a>            <span class="at">grid =</span> <span class="cn">FALSE</span>, </span>
<span id="cb113-6"><a href="normality-assumption.html#cb113-6" tabindex="-1"></a>            <span class="at">main =</span> <span class="st">&quot;Multi-normal Q-Q Plot on Raw Data&quot;</span>, </span>
<span id="cb113-7"><a href="normality-assumption.html#cb113-7" tabindex="-1"></a>            <span class="at">xlab =</span> <span class="fu">expression</span>(chi<span class="sc">^</span><span class="dv">2</span> <span class="sc">*</span> <span class="st">&quot; quantiles&quot;</span>), </span>
<span id="cb113-8"><a href="normality-assumption.html#cb113-8" tabindex="-1"></a>            <span class="at">ylab =</span> <span class="fu">expression</span>(<span class="st">&quot;Mahalanobis distances &quot;</span><span class="sc">^</span><span class="dv">2</span>))</span></code></pre></div>
<p><img src="multivariate_stats_files/figure-html/unnamed-chunk-81-1.png" width="672" /></p>
<pre><code>## [1]  9 21</code></pre>
</div>
<div id="mahalanobis-distance-using-residuals" class="section level3 hasAnchor" number="19.4.2">
<h3><span class="header-section-number">19.4.2</span> Mahalanobis Distance using Residuals<a href="normality-assumption.html#mahalanobis-distance-using-residuals" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Many scholars point out that the normality assumption is really about the residuals of the model. Let’s fit our MANOVA model <strong>without examining the results</strong> and save the residuals to the data frame, then conduct this same approach we did above with Mahalanobis distance:</p>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="normality-assumption.html#cb115-1" tabindex="-1"></a>dvs     <span class="ot">&lt;-</span> <span class="fu">cbind</span>(dat<span class="sc">$</span>y1, dat<span class="sc">$</span>y2, dat<span class="sc">$</span>y3)</span>
<span id="cb115-2"><a href="normality-assumption.html#cb115-2" tabindex="-1"></a>man.mod <span class="ot">&lt;-</span> <span class="fu">manova</span>(dvs <span class="sc">~</span> gp, <span class="at">data =</span> dat)</span>
<span id="cb115-3"><a href="normality-assumption.html#cb115-3" tabindex="-1"></a>dat[, <span class="fu">c</span>(<span class="st">&quot;res1&quot;</span>, <span class="st">&quot;res2&quot;</span>, <span class="st">&quot;res3&quot;</span>)] <span class="ot">&lt;-</span> man.mod<span class="sc">$</span>residuals</span>
<span id="cb115-4"><a href="normality-assumption.html#cb115-4" tabindex="-1"></a>resids <span class="ot">&lt;-</span> <span class="fu">cbind</span>(dat[,<span class="fu">c</span>(<span class="st">&quot;res1&quot;</span>, <span class="st">&quot;res2&quot;</span>, <span class="st">&quot;res3&quot;</span>)])</span>
<span id="cb115-5"><a href="normality-assumption.html#cb115-5" tabindex="-1"></a>distances <span class="ot">&lt;-</span> <span class="fu">mahalanobis</span>(resids, </span>
<span id="cb115-6"><a href="normality-assumption.html#cb115-6" tabindex="-1"></a>                         <span class="at">center =</span> <span class="fu">colMeans</span>(resids), </span>
<span id="cb115-7"><a href="normality-assumption.html#cb115-7" tabindex="-1"></a>                         <span class="at">cov =</span> <span class="fu">cov</span>(resids))</span>
<span id="cb115-8"><a href="normality-assumption.html#cb115-8" tabindex="-1"></a>dat<span class="sc">$</span>distances <span class="ot">&lt;-</span> distances</span>
<span id="cb115-9"><a href="normality-assumption.html#cb115-9" tabindex="-1"></a>dat<span class="sc">$</span>p <span class="ot">&lt;-</span> <span class="fu">pchisq</span>(distances, </span>
<span id="cb115-10"><a href="normality-assumption.html#cb115-10" tabindex="-1"></a>                <span class="at">df =</span> (<span class="fu">ncol</span>(resids)<span class="sc">-</span><span class="dv">1</span>), <span class="co"># df is number of variables - 1</span></span>
<span id="cb115-11"><a href="normality-assumption.html#cb115-11" tabindex="-1"></a>                <span class="at">lower.tail=</span><span class="cn">FALSE</span>)</span>
<span id="cb115-12"><a href="normality-assumption.html#cb115-12" tabindex="-1"></a></span>
<span id="cb115-13"><a href="normality-assumption.html#cb115-13" tabindex="-1"></a>dat<span class="sc">$</span>outlier <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(dat<span class="sc">$</span>p <span class="sc">&lt;</span> .<span class="dv">001</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb115-14"><a href="normality-assumption.html#cb115-14" tabindex="-1"></a>dat[dat<span class="sc">$</span>outlier <span class="sc">==</span> <span class="dv">1</span>, ]</span></code></pre></div>
<pre><code>##   id gp    y1    y2   y3 distancesraw            p outlier     res1   res2      res3 distances
## 9  9  1 29.11 15.09 3.28     20.36943 1.989997e-05       1 16.89139 6.9775 -6.310278  21.64958</code></pre>
<p>Now, we see that Case 9 is the only outlier. Let’s look at the multivariate analogue to the univariate Q-Q plot, now with residuals:</p>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="normality-assumption.html#cb117-1" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb117-2"><a href="normality-assumption.html#cb117-2" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">qqPlot</span>(distances, </span>
<span id="cb117-3"><a href="normality-assumption.html#cb117-3" tabindex="-1"></a>            <span class="at">distribution =</span> <span class="st">&quot;chisq&quot;</span>, <span class="at">df =</span> <span class="fu">mean</span>(distances), </span>
<span id="cb117-4"><a href="normality-assumption.html#cb117-4" tabindex="-1"></a>            <span class="at">lwd =</span> <span class="dv">1</span>, </span>
<span id="cb117-5"><a href="normality-assumption.html#cb117-5" tabindex="-1"></a>            <span class="at">grid =</span> <span class="cn">FALSE</span>, </span>
<span id="cb117-6"><a href="normality-assumption.html#cb117-6" tabindex="-1"></a>            <span class="at">main =</span> <span class="st">&quot;Multi-normal Q-Q Plot on Residuals&quot;</span>, </span>
<span id="cb117-7"><a href="normality-assumption.html#cb117-7" tabindex="-1"></a>            <span class="at">xlab =</span> <span class="fu">expression</span>(chi<span class="sc">^</span><span class="dv">2</span> <span class="sc">*</span> <span class="st">&quot; quantiles&quot;</span>), </span>
<span id="cb117-8"><a href="normality-assumption.html#cb117-8" tabindex="-1"></a>            <span class="at">ylab =</span> <span class="fu">expression</span>(<span class="st">&quot;Mahalanobis distances &quot;</span><span class="sc">^</span><span class="dv">2</span>))</span></code></pre></div>
<p><img src="multivariate_stats_files/figure-html/unnamed-chunk-83-1.png" width="672" /></p>
<pre><code>## [1]  9 21</code></pre>
<p>We see a very similar shape to what we saw with the raw data. It looks like we will not be able to claim we have met the assumption of normality. However, we should really be examining multidimensional normality <strong>within each group</strong>, not the entire data set. Let’s do that:</p>
<!-- #### Using ggplot -->
<!-- We could do something similar with GGplot. This is as far as I got: -->
<!-- ```{r} -->
<!-- library(ggplot2) -->
<!-- qq_all <- dat %>%   -->
<!--   ggplot(aes(sample = distances)) + -->
<!--   # the distribution is not in quantiles but in chi-square distribution -->
<!--   # the df of the chisq dist is the mean(distances): -->
<!--   geom_qq(distribution = qchisq, dparams = mean(distances) ) + -->
<!--   stat_qq_line(distribution = qchisq, dparams = mean(distances) ) + -->
<!--   scale_x_continuous(name = expression(chi^2 * " quantiles") ) +  -->
<!--   scale_y_continuous(name = expression("Mahalanobis distances "^2))  -->
<!-- qq_all -->
<!-- ``` -->
</div>
<div id="multivariate-residual-q-q-plot-by-group" class="section level3 hasAnchor" number="19.4.3">
<h3><span class="header-section-number">19.4.3</span> Multivariate residual Q-Q plot by group<a href="normality-assumption.html#multivariate-residual-q-q-plot-by-group" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>With the residuals, we can use the <code>groups =</code> argument to specify the group. This requires that the matrix have a column that is the group variable.</p>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="normality-assumption.html#cb119-1" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb119-2"><a href="normality-assumption.html#cb119-2" tabindex="-1"></a>distances_gp <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">gp =</span> <span class="fu">as.numeric</span>(dat<span class="sc">$</span>gp), distances)</span>
<span id="cb119-3"><a href="normality-assumption.html#cb119-3" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">qqPlot</span>(distances_gp[, <span class="sc">-</span><span class="dv">1</span>], </span>
<span id="cb119-4"><a href="normality-assumption.html#cb119-4" tabindex="-1"></a>            <span class="at">distribution =</span> <span class="st">&quot;chisq&quot;</span>, <span class="at">df =</span> <span class="fu">mean</span>(distances_gp[, <span class="sc">-</span><span class="dv">1</span>]), </span>
<span id="cb119-5"><a href="normality-assumption.html#cb119-5" tabindex="-1"></a>            <span class="at">groups =</span> distances_gp[,<span class="st">&quot;gp&quot;</span>],</span>
<span id="cb119-6"><a href="normality-assumption.html#cb119-6" tabindex="-1"></a>            <span class="at">lwd =</span> <span class="dv">1</span>, </span>
<span id="cb119-7"><a href="normality-assumption.html#cb119-7" tabindex="-1"></a>            <span class="at">grid =</span> <span class="cn">FALSE</span>, </span>
<span id="cb119-8"><a href="normality-assumption.html#cb119-8" tabindex="-1"></a>            <span class="at">main =</span> <span class="st">&quot;Multi-normal Q-Q Plot on Residuals&quot;</span>, </span>
<span id="cb119-9"><a href="normality-assumption.html#cb119-9" tabindex="-1"></a>            <span class="at">xlab =</span> <span class="fu">expression</span>(chi<span class="sc">^</span><span class="dv">2</span> <span class="sc">*</span> <span class="st">&quot; quantiles&quot;</span>), </span>
<span id="cb119-10"><a href="normality-assumption.html#cb119-10" tabindex="-1"></a>            <span class="at">ylab =</span> <span class="fu">expression</span>(<span class="st">&quot;Mahalanobis distances &quot;</span><span class="sc">^</span><span class="dv">2</span>))</span></code></pre></div>
<p><img src="multivariate_stats_files/figure-html/unnamed-chunk-84-1.png" width="672" /></p>
<p>Clearly, Case 9 is a candidate for removal and seeing if the results will lead to the same statistical conclusion if the case were retained.</p>
</div>
</div>
<div id="statistical-tests-of-multivariate-normality" class="section level2 hasAnchor" number="19.5">
<h2><span class="header-section-number">19.5</span> Statistical Tests of Multivariate Normality<a href="normality-assumption.html#statistical-tests-of-multivariate-normality" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Just as there are statistical tests of univariate normality, there are of multivariate normality. And, just as was the case with their univariate counterparts, the statistical test is sensitive to sample size, just as any test is. With this, if we have a large sample size, we will likely have a statistical significance when the divergence from normality is only negligible. In other words, this source of evidence should be used in conjunction with plots.</p>
<p>Here is the <code>mshapiro.test()</code> function from the mvnormtest package. This function requires the data be arranged as rows instead of columns, so we’ll use the transpose function, <code>t()</code> within the test.
First, let’s separate the dependent variables by group. Here, we’re using their respective residuals, but many authors simply use the dependent variables on the grounds that researchers would be tempted to analyze the results of their fitted model (which is needed to get the residuals) before analyzing the assumptions.</p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="normality-assumption.html#cb120-1" tabindex="-1"></a>dvs.gp1     <span class="ot">&lt;-</span> <span class="fu">subset</span>(dat, gp <span class="sc">==</span> <span class="dv">1</span>, <span class="at">select =</span> <span class="fu">c</span>(<span class="st">&quot;res1&quot;</span>, <span class="st">&quot;res2&quot;</span>, <span class="st">&quot;res3&quot;</span>))</span>
<span id="cb120-2"><a href="normality-assumption.html#cb120-2" tabindex="-1"></a>dvs.gp2     <span class="ot">&lt;-</span> <span class="fu">subset</span>(dat, gp <span class="sc">==</span> <span class="dv">2</span>, <span class="at">select =</span> <span class="fu">c</span>(<span class="st">&quot;res1&quot;</span>, <span class="st">&quot;res2&quot;</span>, <span class="st">&quot;res3&quot;</span>))</span>
<span id="cb120-3"><a href="normality-assumption.html#cb120-3" tabindex="-1"></a></span>
<span id="cb120-4"><a href="normality-assumption.html#cb120-4" tabindex="-1"></a><span class="fu">library</span>(mvnormtest)</span>
<span id="cb120-5"><a href="normality-assumption.html#cb120-5" tabindex="-1"></a><span class="fu">mshapiro.test</span>( <span class="fu">t</span>(dvs.gp1) )</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  Z
## W = 0.81141, p-value = 2.767e-05</code></pre>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="normality-assumption.html#cb122-1" tabindex="-1"></a><span class="fu">mshapiro.test</span>( <span class="fu">t</span>(dvs.gp2) )</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  Z
## W = 0.94576, p-value = 0.2384</code></pre>
<p>We see results that are consistent with our outliers and plots. The multivariate normality assumption was not met because Group 1 had a multivariate distribution that was significantly different from normal.</p>
</div>
<div id="homogeneity-of-covariance" class="section level2 hasAnchor" number="19.6">
<h2><span class="header-section-number">19.6</span> Homogeneity of Covariance<a href="normality-assumption.html#homogeneity-of-covariance" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Box’s M test can be conducted using the <code>box_m()</code> function from the rstatix package, the <code>boxM()</code> function from the biotools package, or the <code>boxM()</code> function from the heplots package. Let’s arbitrarily use the latter:</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="normality-assumption.html#cb124-1" tabindex="-1"></a><span class="fu">library</span>(heplots)</span>
<span id="cb124-2"><a href="normality-assumption.html#cb124-2" tabindex="-1"></a><span class="fu">boxM</span>(dat[ , <span class="fu">c</span>(<span class="st">&quot;y1&quot;</span>, <span class="st">&quot;y2&quot;</span>, <span class="st">&quot;y3&quot;</span>)], dat[ , <span class="st">&quot;gp&quot;</span>])</span></code></pre></div>
<pre><code>## 
##  Box&#39;s M-test for Homogeneity of Covariance Matrices
## 
## data:  dat[, c(&quot;y1&quot;, &quot;y2&quot;, &quot;y3&quot;)]
## Chi-Sq (approx.) = 30.543, df = 6, p-value = 3.098e-05</code></pre>
<p>This assumption was not met. If we had a balanced design, this might not be an issue. Tabachick and Fidell state that Box’s M test tends to be too sensitive, but in this case, the violation seems to be undeniable.</p>
<p>One thing we could do is examine the covariance matrices for each group, and see whether the smaller group has the larger variance-covariance, which in turn would lead to overly lenient estimations of statistical significance and inflated Type I errors.</p>
<p>Here are the <em>n</em>-sizes:</p>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="normality-assumption.html#cb126-1" tabindex="-1"></a><span class="fu">table</span>(dat<span class="sc">$</span>gp)</span></code></pre></div>
<pre><code>## 
##  1  2 
## 36 23</code></pre>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="normality-assumption.html#cb128-1" tabindex="-1"></a><span class="fu">max</span>(<span class="fu">table</span>(dat<span class="sc">$</span>gp)) <span class="sc">/</span> <span class="fu">min</span>(<span class="fu">table</span>(dat<span class="sc">$</span>gp))</span></code></pre></div>
<pre><code>## [1] 1.565217</code></pre>
<p>Group 1 (<em>n</em> = 36) is over 1.5 times larger than Group 2 (or, Group 2 is about two-thirds as big as Group 1). If we see that Group 2 has larger values in the covariance matrix, our MANOVA test statistics will err on the side of leniency, risking Type I error rate inflation. On the other hand, if Group 1 has larger covariance, we err on the side of conservation, risking loss of statistical power. For credibility in our statistical conclusions, the latter scenario is preferable. Note that if we had equal group sizes, MANOVA is pretty “robust” in its statistical tests; here, we don’t.</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="normality-assumption.html#cb130-1" tabindex="-1"></a>dat1 <span class="ot">&lt;-</span> <span class="fu">subset</span>(dat, gp <span class="sc">==</span> <span class="dv">1</span>)</span>
<span id="cb130-2"><a href="normality-assumption.html#cb130-2" tabindex="-1"></a>dat2 <span class="ot">&lt;-</span> <span class="fu">subset</span>(dat, gp <span class="sc">==</span> <span class="dv">2</span>)</span>
<span id="cb130-3"><a href="normality-assumption.html#cb130-3" tabindex="-1"></a>covm1 <span class="ot">&lt;-</span> <span class="fu">cov</span>(dat1[, <span class="fu">c</span>(<span class="st">&quot;res1&quot;</span>, <span class="st">&quot;res2&quot;</span>, <span class="st">&quot;res3&quot;</span>)])</span>
<span id="cb130-4"><a href="normality-assumption.html#cb130-4" tabindex="-1"></a>covm2 <span class="ot">&lt;-</span> <span class="fu">cov</span>(dat2[, <span class="fu">c</span>(<span class="st">&quot;res1&quot;</span>, <span class="st">&quot;res2&quot;</span>, <span class="st">&quot;res3&quot;</span>)])</span>
<span id="cb130-5"><a href="normality-assumption.html#cb130-5" tabindex="-1"></a><span class="fu">round</span>(covm1, <span class="dv">1</span>)</span></code></pre></div>
<pre><code>##      res1 res2 res3
## res1 23.0 12.4  2.9
## res2 12.4 17.5  4.8
## res3  2.9  4.8 14.0</code></pre>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="normality-assumption.html#cb132-1" tabindex="-1"></a><span class="fu">round</span>(covm2, <span class="dv">1</span>)</span></code></pre></div>
<pre><code>##      res1 res2 res3
## res1  4.4  0.8  2.4
## res2  0.8 25.9  7.7
## res3  2.4  7.7 46.7</code></pre>
<p>The pattern is not consistent in terms of which group has larger variances or covariances. With <code>y1</code>, Group 1 has larger variance (23.0 vs 4.4); with <code>y2</code>, there might be similar variances in the two groups (17.5 and 25.9); with <code>y3</code>, there is lower variance in Group 1 (14.0 vs 46.7). And, we haven’t even compared the covariances, which also seem to differ. What do we do?</p>
<p>Boiling each of these covariance matrices down to a single number will be helpful in identifying which group has higher variance, which in turn is important for determining if our violation of this assumption will result in a more conservative or more liberal statistical conclusion. Pituch and Stevens used SPSS, which included the determinant of the covariance matrix for each group in its output. Our Box test output did not provide this, but we can use the determinants of the by-group residual covariance matrices to accomplish the same thing:</p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="normality-assumption.html#cb134-1" tabindex="-1"></a><span class="fu">det</span>(covm1)</span></code></pre></div>
<pre><code>## [1] 3172.914</code></pre>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="normality-assumption.html#cb136-1" tabindex="-1"></a><span class="fu">det</span>(covm2)</span></code></pre></div>
<pre><code>## [1] 4860.31</code></pre>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="normality-assumption.html#cb138-1" tabindex="-1"></a><span class="fu">det</span>(covm2) <span class="sc">/</span> <span class="fu">det</span>(covm1)</span></code></pre></div>
<pre><code>## [1] 1.531813</code></pre>
<p>The generalized variance of the smaller group is 1.5 times that of the larger group. This suggests that the test will be biased to show an effect when there might not be one—that is, increasing Type I error. This is bad news because if we find statistical significance, we won’t know if it is because of population differences or because of this bias.</p>
<!-- ## Homogeneity of variance -->
<!-- We can examine univariate homogeneity of variance for each variable, to identify if a particular variable's variance is the culprit. We can use the `leveneTest()` in the car package: -->
<!-- ```{r} -->
<!-- library(car) -->
<!-- a1 <- aov(y1 ~ gp, data = dat) -->
<!-- a2 <- aov(y2 ~ gp, data = dat) -->
<!-- a3 <- aov(y3 ~ gp, data = dat) -->
<!-- car::leveneTest(a1) # if add `, center = mean`, will get same as Ch. 6 results. -->
<!-- car::leveneTest(a2) -->
<!-- car::leveneTest(a3) -->
<!-- ``` -->
<!-- We see that with the first and third variables the data do not meet this assumption.  -->
</div>
<div id="conclusions-about-our-statistical-assumptions" class="section level2 hasAnchor" number="19.7">
<h2><span class="header-section-number">19.7</span> Conclusions about our statistical assumptions<a href="normality-assumption.html#conclusions-about-our-statistical-assumptions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The statistical assumptions of multivariate normality and homogeneity of covariance were not met with this data set. Pituch and Stevens recommend transforming the data, as would Tabachnick and Fidell. Other scholars (such Curran and Hancock in their podcast, <a href="https://quantitudepod.org/s2e17-embracing-your-non-normality/">linked to here</a>) do not recommend data transformations but instead recommend robust standard errors be used. We’ll take the robust approach in this example.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="18">
<li id="fn18"><p>A shortcut is to fit an ANOVA for each dependent variable and then examine the plots. That approach would also be examining the normality of the <em>residuals</em> rather than the raw data, which many scholars believe is more appropriate.<a href="normality-assumption.html#fnref18" class="footnote-back">↩︎</a></p></li>
<li id="fn19"><p>We can use the <code>qnorm()</code> function to get the critical value of <em>z</em> at a probability level, such as at <em>p</em> = .01: <code>abs(qnorm(p = .01/2, lower.tail=TRUE)) = 2.58</code>.<a href="normality-assumption.html#fnref19" class="footnote-back">↩︎</a></p></li>
<li id="fn20"><p>This standardization can also be in a single line of code, as in <code>apply(dat[, c("y1", "y2", "y3")], 2, scale)</code>.<a href="normality-assumption.html#fnref20" class="footnote-back">↩︎</a></p></li>
<li id="fn21"><p>Alternatively, we could use <code>dat %&gt;% filter(gp == 1) %&gt;% ggplot(aes(x = scale(y1) )) + geom_density(fill = "wheat", color = "white") + stat_function(fun = dnorm)</code> if we did not want to use the package.<a href="normality-assumption.html#fnref21" class="footnote-back">↩︎</a></p></li>
<li id="fn22"><p>Note that we’re using the term sample and population here because we’re assuming our dependent variables are random (rather than fixed) variables because the cases are randomly sampled from the population.<a href="normality-assumption.html#fnref22" class="footnote-back">↩︎</a></p></li>
<li id="fn23"><p>We could also fit the models and conduct this test on the residuals.<a href="normality-assumption.html#fnref23" class="footnote-back">↩︎</a></p></li>
<li id="fn24"><p>Can also use the <code>mahalanobis_distance()</code> function in the rstatix package.<a href="normality-assumption.html#fnref24" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="descriptive-statistics.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="fitting-the-manova-model.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
