<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1 Terminology and Matrix Manipulations Used in Multivariate Statistics | EDUC 644 Applied Multivariate Statistics</title>
  <meta name="description" content="Course materials for multivariate statistics" />
  <meta name="generator" content="bookdown 0.44 and GitBook 2.6.7" />

  <meta property="og:title" content="1 Terminology and Matrix Manipulations Used in Multivariate Statistics | EDUC 644 Applied Multivariate Statistics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Course materials for multivariate statistics" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1 Terminology and Matrix Manipulations Used in Multivariate Statistics | EDUC 644 Applied Multivariate Statistics" />
  
  <meta name="twitter:description" content="Course materials for multivariate statistics" />
  

<meta name="author" content="George Harrison" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="hotellings-t2.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/tabwid-1.1.3/tabwid.css" rel="stylesheet" />
<script src="libs/tabwid-1.1.3/tabwid.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Multivariate Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><i class="fa fa-check"></i><b>1</b> Terminology and Matrix Manipulations Used in Multivariate Statistics</a>
<ul>
<li class="chapter" data-level="1.1" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#scalars"><i class="fa fa-check"></i><b>1.1</b> Scalars</a></li>
<li class="chapter" data-level="1.2" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#vectors"><i class="fa fa-check"></i><b>1.2</b> Vectors</a></li>
<li class="chapter" data-level="1.3" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#matrices"><i class="fa fa-check"></i><b>1.3</b> Matrices</a></li>
<li class="chapter" data-level="1.4" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#symmetrical-matrices"><i class="fa fa-check"></i><b>1.4</b> Symmetrical Matrices</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#variance-covariance-matrices"><i class="fa fa-check"></i><b>1.4.1</b> Variance-covariance Matrices</a></li>
<li class="chapter" data-level="1.4.2" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#greek-letters"><i class="fa fa-check"></i><b>1.4.2</b> Greek letters</a></li>
<li class="chapter" data-level="1.4.3" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#example-variance-covariance-matrix"><i class="fa fa-check"></i><b>1.4.3</b> Example variance-covariance matrix</a></li>
<li class="chapter" data-level="1.4.4" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#the-diagonal-and-trace"><i class="fa fa-check"></i><b>1.4.4</b> The diagonal and trace</a></li>
<li class="chapter" data-level="1.4.5" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#an-identity-matrix"><i class="fa fa-check"></i><b>1.4.5</b> An identity matrix</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#transposed-vectors-and-matrices"><i class="fa fa-check"></i><b>1.5</b> Transposed Vectors and Matrices</a></li>
<li class="chapter" data-level="1.6" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#matrix-addition-and-subtraction"><i class="fa fa-check"></i><b>1.6</b> Matrix Addition and Subtraction</a></li>
<li class="chapter" data-level="1.7" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#operations-on-matrices-with-a-scalar"><i class="fa fa-check"></i><b>1.7</b> Operations on Matrices with a Scalar</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#sum-of-square-and-cross-product-sscp-matrices"><i class="fa fa-check"></i><b>1.7.1</b> Sum-of-square-and-cross-product (SSCP) matrices</a></li>
<li class="chapter" data-level="1.7.2" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#operations-on-elements-of-a-matrix-example-with-a-correlation-matrix"><i class="fa fa-check"></i><b>1.7.2</b> Operations on elements of a matrix: Example with a correlation matrix</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#matrix-multiplication"><i class="fa fa-check"></i><b>1.8</b> Matrix Multiplication</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#another-example-of-matrix-multiplication-to-get-the-sscp"><i class="fa fa-check"></i><b>1.8.1</b> Another example of matrix multiplication, to get the SSCP</a></li>
<li class="chapter" data-level="1.8.2" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#the-ordering-is-important"><i class="fa fa-check"></i><b>1.8.2</b> The ordering is important</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#inverse-of-a-matrix"><i class="fa fa-check"></i><b>1.9</b> Inverse of a Matrix</a></li>
<li class="chapter" data-level="1.10" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#matrix-determinants-as-generalized-variance"><i class="fa fa-check"></i><b>1.10</b> Matrix determinants, as generalized variance</a></li>
<li class="chapter" data-level="1.11" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#eigenvectors-and-eigenvalues"><i class="fa fa-check"></i><b>1.11</b> Eigenvectors and Eigenvalues</a></li>
<li class="chapter" data-level="1.12" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#summary"><i class="fa fa-check"></i><b>1.12</b> Summary</a></li>
<li class="chapter" data-level="1.13" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#optional-spss-and-r-code-to-manipulate-matrices"><i class="fa fa-check"></i><b>1.13</b> Optional: SPSS and R Code to Manipulate Matrices</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="hotellings-t2.html"><a href="hotellings-t2.html"><i class="fa fa-check"></i><b>2</b> Hotelling’s <span class="math inline">\(T^2\)</span></a>
<ul>
<li class="chapter" data-level="2.1" data-path="hotellings-t2.html"><a href="hotellings-t2.html#within-group-covariance-matrices"><i class="fa fa-check"></i><b>2.1</b> Within-group covariance matrices</a></li>
<li class="chapter" data-level="2.2" data-path="hotellings-t2.html"><a href="hotellings-t2.html#sscp-matrices"><i class="fa fa-check"></i><b>2.2</b> SSCP matrices</a></li>
<li class="chapter" data-level="2.3" data-path="hotellings-t2.html"><a href="hotellings-t2.html#conducting-the-test-using-functions"><i class="fa fa-check"></i><b>2.3</b> Conducting the Test using Functions</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="planned-comparisons-and-contrasts.html"><a href="planned-comparisons-and-contrasts.html"><i class="fa fa-check"></i><b>3</b> Planned Comparisons and Contrasts</a>
<ul>
<li class="chapter" data-level="3.1" data-path="planned-comparisons-and-contrasts.html"><a href="planned-comparisons-and-contrasts.html#data-from-week-1"><i class="fa fa-check"></i><b>3.1</b> Data from Week 1</a></li>
<li class="chapter" data-level="3.2" data-path="planned-comparisons-and-contrasts.html"><a href="planned-comparisons-and-contrasts.html#orthogonal-contrasts"><i class="fa fa-check"></i><b>3.2</b> Orthogonal contrasts</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="planned-comparisons-and-contrasts.html"><a href="planned-comparisons-and-contrasts.html#conditions-for-orthogonal-contrasts"><i class="fa fa-check"></i><b>3.2.1</b> Conditions for orthogonal contrasts</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="planned-comparisons-and-contrasts.html"><a href="planned-comparisons-and-contrasts.html#non-orthogonal-contrasts"><i class="fa fa-check"></i><b>3.3</b> Non-orthogonal contrasts</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="planned-comparisons-and-contrasts.html"><a href="planned-comparisons-and-contrasts.html#accounting-for-type-i-error-in-non-orthogonal-contrasts."><i class="fa fa-check"></i><b>3.3.1</b> Accounting for Type I error in non-orthogonal contrasts.</a></li>
<li class="chapter" data-level="3.3.2" data-path="planned-comparisons-and-contrasts.html"><a href="planned-comparisons-and-contrasts.html#post-hoc-tests"><i class="fa fa-check"></i><b>3.3.2</b> Post-hoc tests</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html"><i class="fa fa-check"></i><b>4</b> Week 03 Statistical Assumptions of MANOVA</a>
<ul>
<li class="chapter" data-level="4.1" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#data"><i class="fa fa-check"></i><b>4.1</b> Data</a></li>
<li class="chapter" data-level="4.2" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#descriptive-statistics"><i class="fa fa-check"></i><b>4.2</b> Descriptive statistics</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#by-group-descriptive-statistics"><i class="fa fa-check"></i><b>4.2.1</b> By-group descriptive statistics</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#normality-assumption"><i class="fa fa-check"></i><b>4.3</b> Normality Assumption</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#univariate-normality"><i class="fa fa-check"></i><b>4.3.1</b> Univariate Normality</a></li>
<li class="chapter" data-level="4.3.2" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#examining-univariate-normality-using-quantile-quantile-plots"><i class="fa fa-check"></i><b>4.3.2</b> Examining univariate normality using quantile-quantile plots</a></li>
<li class="chapter" data-level="4.3.3" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#a-caution-about-statistical-tests-of-statistical-assumptions"><i class="fa fa-check"></i><b>4.3.3</b> A caution about statistical tests of statistical assumptions</a></li>
<li class="chapter" data-level="4.3.4" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#mahalanobis-distance-and-multivariate-outliers"><i class="fa fa-check"></i><b>4.3.4</b> Mahalanobis Distance and Multivariate Outliers</a></li>
<li class="chapter" data-level="4.3.5" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#statistical-tests-of-multivariate-normality"><i class="fa fa-check"></i><b>4.3.5</b> Statistical Tests of Multivariate Normality</a></li>
<li class="chapter" data-level="4.3.6" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#homogeneity-of-covariance"><i class="fa fa-check"></i><b>4.3.6</b> Homogeneity of Covariance</a></li>
<li class="chapter" data-level="4.3.7" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#conclusions-about-our-statistical-assumptions"><i class="fa fa-check"></i><b>4.3.7</b> Conclusions about our statistical assumptions</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#fitting-the-manova-model"><i class="fa fa-check"></i><b>4.4</b> Fitting the MANOVA Model</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#follow-up-analysis-with-univariate-f-tests"><i class="fa fa-check"></i><b>4.4.1</b> Follow-up analysis with univariate <em>F</em>-tests</a></li>
<li class="chapter" data-level="4.4.2" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#effect-size"><i class="fa fa-check"></i><b>4.4.2</b> Effect size</a></li>
<li class="chapter" data-level="4.4.3" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#comparing-the-model-without-outlier"><i class="fa fa-check"></i><b>4.4.3</b> Comparing the Model Without Outlier</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#robust-one-way-manova"><i class="fa fa-check"></i><b>4.5</b> Robust One-way MANOVA</a></li>
<li class="chapter" data-level="4.6" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#summary-1"><i class="fa fa-check"></i><b>4.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html"><i class="fa fa-check"></i><b>5</b> Week 04 Factorial MANOVA</a>
<ul>
<li class="chapter" data-level="5.1" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#following-tabachnick-and-fidells-notes"><i class="fa fa-check"></i><b>5.1</b> Following Tabachnick and Fidell’s notes</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#another-way-to-get-the-sscp_w"><i class="fa fa-check"></i><b>5.1.1</b> Another way to get the <span class="math inline">\(SSCP_W\)</span>:</a></li>
<li class="chapter" data-level="5.1.2" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#mathbfsscp_between-for-each-factor"><i class="fa fa-check"></i><b>5.1.2</b> <span class="math inline">\(\mathbf{SSCP_{Between}}\)</span> for each factor</a></li>
<li class="chapter" data-level="5.1.3" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#mathbfsscp_between-for-the-interaction"><i class="fa fa-check"></i><b>5.1.3</b> <span class="math inline">\(\mathbf{SSCP_{Between}}\)</span> for the interaction</a></li>
<li class="chapter" data-level="5.1.4" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#these-by-hand-calculations-will-be-available-in-manova."><i class="fa fa-check"></i><b>5.1.4</b> These by-hand calculations will be available in <code>manova()</code>.</a></li>
<li class="chapter" data-level="5.1.5" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#calculating-the-generalized-variance"><i class="fa fa-check"></i><b>5.1.5</b> Calculating the generalized variance</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#calculating-wilks-lambda"><i class="fa fa-check"></i><b>5.2</b> Calculating Wilks’ Lambda</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#fit-the-factorial-manova"><i class="fa fa-check"></i><b>5.2.1</b> Fit the factorial MANOVA</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#mancova"><i class="fa fa-check"></i><b>5.3</b> MANCOVA</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#mancova-example"><i class="fa fa-check"></i><b>5.3.1</b> MANCOVA example</a></li>
<li class="chapter" data-level="5.3.2" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#lets-think-about-ordering-and-type-i-sums-of-squares"><i class="fa fa-check"></i><b>5.3.2</b> Let’s think about ordering and Type I sums of squares</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="week-05-discriminant-function-analysis.html"><a href="week-05-discriminant-function-analysis.html"><i class="fa fa-check"></i><b>6</b> Week 05, Discriminant Function Analysis</a>
<ul>
<li class="chapter" data-level="6.0.1" data-path="week-05-discriminant-function-analysis.html"><a href="week-05-discriminant-function-analysis.html#fitting-the-discriminant-function-analysis-model"><i class="fa fa-check"></i><b>6.0.1</b> Fitting the discriminant function analysis model</a></li>
<li class="chapter" data-level="6.0.2" data-path="week-05-discriminant-function-analysis.html"><a href="week-05-discriminant-function-analysis.html#dimension-reduction-analysis"><i class="fa fa-check"></i><b>6.0.2</b> Dimension reduction analysis</a></li>
<li class="chapter" data-level="6.0.3" data-path="week-05-discriminant-function-analysis.html"><a href="week-05-discriminant-function-analysis.html#structure-and-standardized-discriminant-function-coefficients"><i class="fa fa-check"></i><b>6.0.3</b> Structure and standardized discriminant function coefficients</a></li>
<li class="chapter" data-level="6.0.4" data-path="week-05-discriminant-function-analysis.html"><a href="week-05-discriminant-function-analysis.html#discriminant-function-scores"><i class="fa fa-check"></i><b>6.0.4</b> Discriminant function scores</a></li>
<li class="chapter" data-level="6.0.5" data-path="week-05-discriminant-function-analysis.html"><a href="week-05-discriminant-function-analysis.html#group-means-centroids-of-the-discriminant-function-scores"><i class="fa fa-check"></i><b>6.0.5</b> Group means (centroids) of the discriminant-function scores</a></li>
<li class="chapter" data-level="6.0.6" data-path="week-05-discriminant-function-analysis.html"><a href="week-05-discriminant-function-analysis.html#bivariate-scatterplot"><i class="fa fa-check"></i><b>6.0.6</b> Bivariate scatterplot</a></li>
<li class="chapter" data-level="6.1" data-path="week-05-discriminant-function-analysis.html"><a href="week-05-discriminant-function-analysis.html#write-up"><i class="fa fa-check"></i><b>6.1</b> Write-up</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="week-06-principal-components-analysis.html"><a href="week-06-principal-components-analysis.html"><i class="fa fa-check"></i><b>7</b> Week 06: Principal Components Analysis</a>
<ul>
<li class="chapter" data-level="7.1" data-path="week-06-principal-components-analysis.html"><a href="week-06-principal-components-analysis.html#example-1-to-see-some-properties-of-pca"><i class="fa fa-check"></i><b>7.1</b> Example 1, to see some properties of PCA</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="week-06-principal-components-analysis.html"><a href="week-06-principal-components-analysis.html#pca-with-covariance-vs.-correlation"><i class="fa fa-check"></i><b>7.1.1</b> PCA with Covariance vs. Correlation</a></li>
<li class="chapter" data-level="7.1.2" data-path="week-06-principal-components-analysis.html"><a href="week-06-principal-components-analysis.html#unscaled-eigenvectors"><i class="fa fa-check"></i><b>7.1.2</b> Unscaled eigenvectors</a></li>
<li class="chapter" data-level="7.1.3" data-path="week-06-principal-components-analysis.html"><a href="week-06-principal-components-analysis.html#looking-at-the-properties-of-eigenvectors-and-eigenvalues"><i class="fa fa-check"></i><b>7.1.3</b> Looking at the properties of eigenvectors and eigenvalues</a></li>
<li class="chapter" data-level="7.1.4" data-path="week-06-principal-components-analysis.html"><a href="week-06-principal-components-analysis.html#using-the-psych-package"><i class="fa fa-check"></i><b>7.1.4</b> Using the psych package</a></li>
<li class="chapter" data-level="7.1.5" data-path="week-06-principal-components-analysis.html"><a href="week-06-principal-components-analysis.html#determining-how-many-components-to-retain"><i class="fa fa-check"></i><b>7.1.5</b> Determining how many components to retain</a></li>
<li class="chapter" data-level="7.1.6" data-path="week-06-principal-components-analysis.html"><a href="week-06-principal-components-analysis.html#reduced-pca-model"><i class="fa fa-check"></i><b>7.1.6</b> Reduced PCA model</a></li>
<li class="chapter" data-level="7.1.7" data-path="week-06-principal-components-analysis.html"><a href="week-06-principal-components-analysis.html#interpretation-1"><i class="fa fa-check"></i><b>7.1.7</b> Interpretation</a></li>
<li class="chapter" data-level="7.1.8" data-path="week-06-principal-components-analysis.html"><a href="week-06-principal-components-analysis.html#interpretation-of-the-rotated-solution"><i class="fa fa-check"></i><b>7.1.8</b> Interpretation of the rotated solution</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="week-06-principal-components-analysis.html"><a href="week-06-principal-components-analysis.html#example-two"><i class="fa fa-check"></i><b>7.2</b> Example Two</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="week-06-principal-components-analysis.html"><a href="week-06-principal-components-analysis.html#pca-on-unstandardized-scores"><i class="fa fa-check"></i><b>7.2.1</b> PCA on Unstandardized Scores</a></li>
<li class="chapter" data-level="7.2.2" data-path="week-06-principal-components-analysis.html"><a href="week-06-principal-components-analysis.html#pca-on-the-standardized-scores"><i class="fa fa-check"></i><b>7.2.2</b> PCA on the Standardized Scores</a></li>
<li class="chapter" data-level="7.2.3" data-path="week-06-principal-components-analysis.html"><a href="week-06-principal-components-analysis.html#let-the-psych-package-do-the-work"><i class="fa fa-check"></i><b>7.2.3</b> Let the Psych Package Do the Work</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="week-06-principal-components-analysis.html"><a href="week-06-principal-components-analysis.html#heptathlon-example"><i class="fa fa-check"></i><b>7.3</b> Heptathlon example</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="week-06-principal-components-analysis.html"><a href="week-06-principal-components-analysis.html#data-and-data-cleaning"><i class="fa fa-check"></i><b>7.3.1</b> Data and data cleaning</a></li>
<li class="chapter" data-level="7.3.2" data-path="week-06-principal-components-analysis.html"><a href="week-06-principal-components-analysis.html#examine-assumption-of-linearity"><i class="fa fa-check"></i><b>7.3.2</b> Examine assumption of linearity</a></li>
<li class="chapter" data-level="7.3.3" data-path="week-06-principal-components-analysis.html"><a href="week-06-principal-components-analysis.html#multivariate-normality-and-outliers"><i class="fa fa-check"></i><b>7.3.3</b> Multivariate normality and outliers</a></li>
<li class="chapter" data-level="7.3.4" data-path="week-06-principal-components-analysis.html"><a href="week-06-principal-components-analysis.html#re-examine-linearity-and-normality"><i class="fa fa-check"></i><b>7.3.4</b> Re-examine linearity and normality</a></li>
<li class="chapter" data-level="7.3.5" data-path="week-06-principal-components-analysis.html"><a href="week-06-principal-components-analysis.html#fit-the-initial-pca"><i class="fa fa-check"></i><b>7.3.5</b> Fit the initial PCA</a></li>
<li class="chapter" data-level="7.3.6" data-path="week-06-principal-components-analysis.html"><a href="week-06-principal-components-analysis.html#determine-the-number-of-components-to-retain"><i class="fa fa-check"></i><b>7.3.6</b> Determine the number of components to retain</a></li>
<li class="chapter" data-level="7.3.7" data-path="week-06-principal-components-analysis.html"><a href="week-06-principal-components-analysis.html#refit-the-pca-model-using-rotation-if-that-is-acceptable-in-your-field"><i class="fa fa-check"></i><b>7.3.7</b> Refit the PCA model, using rotation if that is acceptable in your field</a></li>
<li class="chapter" data-level="7.3.8" data-path="week-06-principal-components-analysis.html"><a href="week-06-principal-components-analysis.html#interpret-the-components"><i class="fa fa-check"></i><b>7.3.8</b> Interpret the components</a></li>
<li class="chapter" data-level="7.3.9" data-path="week-06-principal-components-analysis.html"><a href="week-06-principal-components-analysis.html#saving-the-scores"><i class="fa fa-check"></i><b>7.3.9</b> Saving the scores</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="week-06-principal-components-analysis.html"><a href="week-06-principal-components-analysis.html#other-example-from-later-in-the-chapter-not-assigned"><i class="fa fa-check"></i><b>7.4</b> Other example from later in the chapter (not assigned)</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="week-06-principal-components-analysis.html"><a href="week-06-principal-components-analysis.html#usairpollution-data"><i class="fa fa-check"></i><b>7.4.1</b> USairpollution Data</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="week-06-principal-components-analysis.html"><a href="week-06-principal-components-analysis.html#another-resource"><i class="fa fa-check"></i><b>7.5</b> Another resource</a></li>
<li class="chapter" data-level="7.6" data-path="week-06-principal-components-analysis.html"><a href="week-06-principal-components-analysis.html#references"><i class="fa fa-check"></i><b>7.6</b> References</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="week-07-exploratory-factor-analysis-part-1.html"><a href="week-07-exploratory-factor-analysis-part-1.html"><i class="fa fa-check"></i><b>8</b> Week 07: Exploratory Factor Analysis, Part 1</a>
<ul>
<li class="chapter" data-level="8.1" data-path="week-07-exploratory-factor-analysis-part-1.html"><a href="week-07-exploratory-factor-analysis-part-1.html#introductory-comments"><i class="fa fa-check"></i><b>8.1</b> Introductory comments</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="week-07-exploratory-factor-analysis-part-1.html"><a href="week-07-exploratory-factor-analysis-part-1.html#packages"><i class="fa fa-check"></i><b>8.1.1</b> Packages</a></li>
<li class="chapter" data-level="8.1.2" data-path="week-07-exploratory-factor-analysis-part-1.html"><a href="week-07-exploratory-factor-analysis-part-1.html#efa-ne-pca"><i class="fa fa-check"></i><b>8.1.2</b> EFA <span class="math inline">\(\ne\)</span> PCA</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="week-07-exploratory-factor-analysis-part-1.html"><a href="week-07-exploratory-factor-analysis-part-1.html#preparatory-steps"><i class="fa fa-check"></i><b>8.2</b> Preparatory steps</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="week-07-exploratory-factor-analysis-part-1.html"><a href="week-07-exploratory-factor-analysis-part-1.html#examining-the-data"><i class="fa fa-check"></i><b>8.2.1</b> Examining the data</a></li>
<li class="chapter" data-level="8.2.2" data-path="week-07-exploratory-factor-analysis-part-1.html"><a href="week-07-exploratory-factor-analysis-part-1.html#addressing-assumptions"><i class="fa fa-check"></i><b>8.2.2</b> Addressing assumptions</a></li>
<li class="chapter" data-level="8.2.3" data-path="week-07-exploratory-factor-analysis-part-1.html"><a href="week-07-exploratory-factor-analysis-part-1.html#determining-factorability"><i class="fa fa-check"></i><b>8.2.3</b> Determining factorability</a></li>
<li class="chapter" data-level="8.2.4" data-path="week-07-exploratory-factor-analysis-part-1.html"><a href="week-07-exploratory-factor-analysis-part-1.html#determining-how-many-factors-to-retain"><i class="fa fa-check"></i><b>8.2.4</b> Determining how many factors to retain</a></li>
<li class="chapter" data-level="8.2.5" data-path="week-07-exploratory-factor-analysis-part-1.html"><a href="week-07-exploratory-factor-analysis-part-1.html#factor-analysis-with-a-data-matrix-raw-data"><i class="fa fa-check"></i><b>8.2.5</b> Factor analysis with a data matrix (raw data)</a></li>
<li class="chapter" data-level="8.2.6" data-path="week-07-exploratory-factor-analysis-part-1.html"><a href="week-07-exploratory-factor-analysis-part-1.html#factor-analysis-with-correlation-data"><i class="fa fa-check"></i><b>8.2.6</b> Factor analysis with correlation data</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="week-07-exploratory-factor-analysis-part-1.html"><a href="week-07-exploratory-factor-analysis-part-1.html#references-1"><i class="fa fa-check"></i><b>8.3</b> References</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="week-08-exploratory-factor-analysis-part-2.html"><a href="week-08-exploratory-factor-analysis-part-2.html"><i class="fa fa-check"></i><b>9</b> Week 08: Exploratory Factor Analysis, Part 2</a>
<ul>
<li class="chapter" data-level="9.1" data-path="week-08-exploratory-factor-analysis-part-2.html"><a href="week-08-exploratory-factor-analysis-part-2.html#factor-analysis-with-correlation-data-1"><i class="fa fa-check"></i><b>9.1</b> Factor analysis with correlation data</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="week-08-exploratory-factor-analysis-part-2.html"><a href="week-08-exploratory-factor-analysis-part-2.html#setting-up-the-data-1"><i class="fa fa-check"></i><b>9.1.1</b> Setting up the data</a></li>
<li class="chapter" data-level="9.1.2" data-path="week-08-exploratory-factor-analysis-part-2.html"><a href="week-08-exploratory-factor-analysis-part-2.html#preparatory-steps-2"><i class="fa fa-check"></i><b>9.1.2</b> Preparatory steps</a></li>
<li class="chapter" data-level="9.1.3" data-path="week-08-exploratory-factor-analysis-part-2.html"><a href="week-08-exploratory-factor-analysis-part-2.html#performing-the-factor-analysis-1"><i class="fa fa-check"></i><b>9.1.3</b> Performing the factor analysis</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="week-08-exploratory-factor-analysis-part-2.html"><a href="week-08-exploratory-factor-analysis-part-2.html#efa-with-categorical-data"><i class="fa fa-check"></i><b>9.2</b> EFA with categorical data</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="week-08-exploratory-factor-analysis-part-2.html"><a href="week-08-exploratory-factor-analysis-part-2.html#describing-categorical-data"><i class="fa fa-check"></i><b>9.2.1</b> Describing categorical data</a></li>
<li class="chapter" data-level="9.2.2" data-path="week-08-exploratory-factor-analysis-part-2.html"><a href="week-08-exploratory-factor-analysis-part-2.html#factor-scores"><i class="fa fa-check"></i><b>9.2.2</b> Factor scores</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="week-08-exploratory-factor-analysis-part-2.html"><a href="week-08-exploratory-factor-analysis-part-2.html#practice"><i class="fa fa-check"></i><b>9.3</b> Practice</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="week-08-exploratory-factor-analysis-part-2.html"><a href="week-08-exploratory-factor-analysis-part-2.html#summary-2"><i class="fa fa-check"></i><b>9.3.1</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="week-08-exploratory-factor-analysis-part-2.html"><a href="week-08-exploratory-factor-analysis-part-2.html#references-2"><i class="fa fa-check"></i><b>9.4</b> References</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="week-09-confirmatory-factor-analysis.html"><a href="week-09-confirmatory-factor-analysis.html"><i class="fa fa-check"></i><b>10</b> Week 09: Confirmatory Factor Analysis</a>
<ul>
<li class="chapter" data-level="10.1" data-path="week-09-confirmatory-factor-analysis.html"><a href="week-09-confirmatory-factor-analysis.html#preparatory-steps-3"><i class="fa fa-check"></i><b>10.1</b> Preparatory steps</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="week-09-confirmatory-factor-analysis.html"><a href="week-09-confirmatory-factor-analysis.html#describing-the-data"><i class="fa fa-check"></i><b>10.1.1</b> Describing the data</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="week-09-confirmatory-factor-analysis.html"><a href="week-09-confirmatory-factor-analysis.html#fitting-a-cfa-model"><i class="fa fa-check"></i><b>10.2</b> Fitting a CFA model</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="week-09-confirmatory-factor-analysis.html"><a href="week-09-confirmatory-factor-analysis.html#making-sure-the-model-was-correctly-estimated"><i class="fa fa-check"></i><b>10.2.1</b> Making sure the model was correctly estimated</a></li>
<li class="chapter" data-level="10.2.2" data-path="week-09-confirmatory-factor-analysis.html"><a href="week-09-confirmatory-factor-analysis.html#evaluating-the-model-fit"><i class="fa fa-check"></i><b>10.2.2</b> Evaluating the model fit</a></li>
<li class="chapter" data-level="10.2.3" data-path="week-09-confirmatory-factor-analysis.html"><a href="week-09-confirmatory-factor-analysis.html#interpretting-the-parameter-estimates"><i class="fa fa-check"></i><b>10.2.3</b> Interpretting the parameter estimates</a></li>
<li class="chapter" data-level="10.2.4" data-path="week-09-confirmatory-factor-analysis.html"><a href="week-09-confirmatory-factor-analysis.html#further-inspecting-our-model"><i class="fa fa-check"></i><b>10.2.4</b> Further inspecting our model</a></li>
<li class="chapter" data-level="10.2.5" data-path="week-09-confirmatory-factor-analysis.html"><a href="week-09-confirmatory-factor-analysis.html#further-inspecting-our-models-parameters"><i class="fa fa-check"></i><b>10.2.5</b> Further inspecting our model’s parameters</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="week-09-confirmatory-factor-analysis.html"><a href="week-09-confirmatory-factor-analysis.html#using-alternative-model-specifications"><i class="fa fa-check"></i><b>10.3</b> Using alternative model specifications</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="week-09-confirmatory-factor-analysis.html"><a href="week-09-confirmatory-factor-analysis.html#rescaling-the-factors-to-be-standardized"><i class="fa fa-check"></i><b>10.3.1</b> Rescaling the factors to be standardized</a></li>
<li class="chapter" data-level="10.3.2" data-path="week-09-confirmatory-factor-analysis.html"><a href="week-09-confirmatory-factor-analysis.html#specifying-a-competing-nested-model"><i class="fa fa-check"></i><b>10.3.2</b> Specifying a competing, nested, model</a></li>
<li class="chapter" data-level="10.3.3" data-path="week-09-confirmatory-factor-analysis.html"><a href="week-09-confirmatory-factor-analysis.html#conducting-model-comparisons"><i class="fa fa-check"></i><b>10.3.3</b> Conducting model comparisons</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="week-09-confirmatory-factor-analysis.html"><a href="week-09-confirmatory-factor-analysis.html#estimating-factor-scores"><i class="fa fa-check"></i><b>10.4</b> Estimating factor scores</a></li>
<li class="chapter" data-level="10.5" data-path="week-09-confirmatory-factor-analysis.html"><a href="week-09-confirmatory-factor-analysis.html#cfa-with-categorical-data"><i class="fa fa-check"></i><b>10.5</b> CFA with categorical data</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="week-09-confirmatory-factor-analysis.html"><a href="week-09-confirmatory-factor-analysis.html#using-data-from-an-r-package"><i class="fa fa-check"></i><b>10.5.1</b> Using data from an R package</a></li>
<li class="chapter" data-level="10.5.2" data-path="week-09-confirmatory-factor-analysis.html"><a href="week-09-confirmatory-factor-analysis.html#preparing-the-data"><i class="fa fa-check"></i><b>10.5.2</b> Preparing the data</a></li>
<li class="chapter" data-level="10.5.3" data-path="week-09-confirmatory-factor-analysis.html"><a href="week-09-confirmatory-factor-analysis.html#describing-the-data-1"><i class="fa fa-check"></i><b>10.5.3</b> Describing the data</a></li>
<li class="chapter" data-level="10.5.4" data-path="week-09-confirmatory-factor-analysis.html"><a href="week-09-confirmatory-factor-analysis.html#fitting-the-cfa-model"><i class="fa fa-check"></i><b>10.5.4</b> Fitting the CFA model</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="week-09-confirmatory-factor-analysis.html"><a href="week-09-confirmatory-factor-analysis.html#way-tldr-summary"><i class="fa fa-check"></i><b>10.6</b> Way TL;DR Summary</a></li>
<li class="chapter" data-level="10.7" data-path="week-09-confirmatory-factor-analysis.html"><a href="week-09-confirmatory-factor-analysis.html#references-3"><i class="fa fa-check"></i><b>10.7</b> References</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">EDUC 644 Applied Multivariate Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="terminology-and-matrix-manipulations-used-in-multivariate-statistics" class="section level1 hasAnchor" number="1">
<h1><span class="header-section-number">1</span> Terminology and Matrix Manipulations Used in Multivariate Statistics<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#terminology-and-matrix-manipulations-used-in-multivariate-statistics" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In this class and beyond, you will encounter published work that assumes you have some knowledge of the mathematical operations that are used in multivariate statistics. This is where matrix algebra comes in. MANOVA, discriminant function analysis, principal components analysis, exploratory &amp; confirmatory factor analyses (and their extensions) all use matrix algebra.</p>
<p>Unfortunately, matrix algebra is completely new to most students in education and the social sciences, which poses a small challenge for us to overcome before we delve into the content of our class. Our purpose is not to study math but to understand the terminology and operations well enough to learn about the fundamental procedures used in multivariate statistics. This in turn serves to help us read and critique existing work and make informed decisions about what options to select while conducting our own multivariate analyses.</p>
<p>With this, our goal is to understand matrix algebra at least enough to understand (a) the mathematical symbols used in the equations involved in applied multivariate statistics, (b) some of the fundamental operations used in multivariate statistics, and (c) the software output from a multivariate model procedure.</p>
<p>We’ll address some types of numeric structures of data used in matrix algebra: scalars, vectors, matrices, and diagonals. Along the way, we’ll look at some operations, such as addition and subtraction, multiplication, and the matrix-algebra version of division, which is called inversion. We’ll also address get introduced to the determinant, which is a single number that represents the generalized variance of a multivariate matrix of data. At the very end, there is some sample R and SPSS code that can be used to conduct some of these matrix operations.</p>
<div id="scalars" class="section level2 hasAnchor" number="1.1">
<h2><span class="header-section-number">1.1</span> Scalars<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#scalars" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>One thing statisticians like to do is use obscure terminology for simple things. The purpose of this is to ensure the rest of us feel incompetent when we encounter these terms—okay, this may not be the real purpose. Back to the point, here:</p>
<ul>
<li><em><em>What is a scalar?</em></em>
<ul>
<li>A scalar is a single number.</li>
</ul></li>
<li><em><em>Why is it called a scalar?</em></em>
<ul>
<li>Because we can use it to rescale other numbers. For example, if we multiply a number by a scalar that is less than 1, it shrinks it; if we multiply by a scalar greater than 1, it expands it. Negative scalars rescale a number in the opposite direction. When we work with matrices, we can rescale them using scalars.</li>
</ul></li>
</ul>
</div>
<div id="vectors" class="section level2 hasAnchor" number="1.2">
<h2><span class="header-section-number">1.2</span> Vectors<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#vectors" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A vector is a series of numbers. The most familiar example is a column of data in a data set—that’s a vector. For example, if we have nine people’s scores on a variable intended to measure their satisfaction with their counseling treatment, we can represent it as a vector:</p>
<p><span class="math display">\[\mathbf{a} = \begin{bmatrix} 1 \\ 3 \\ 2 \\ 4 \\ 6 \\ 6 \\ 5 \\ 5 \\ 4 \end{bmatrix}\]</span></p>
<p>When we display a vector or a matrix, we use brackets around it, as is done above. Vectors are typically symbolized as boldface and lower case. This vector is labeled as <span class="math inline">\(\mathbf{a}\)</span>, arbitrarily, but we could also give it a meaningful label, such as <span class="math inline">\(\mathbf{sa}\)</span>, which is the name of this column of data in our data set, which we’ll see in a minute.</p>
</div>
<div id="matrices" class="section level2 hasAnchor" number="1.3">
<h2><span class="header-section-number">1.3</span> Matrices<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#matrices" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="data-files-as-matrices" class="section level6 hasAnchor" number="1.3.0.0.0.1">
<h6><span class="header-section-number">1.3.0.0.0.1</span> Data Files as Matrices<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#data-files-as-matrices" class="anchor-section" aria-label="Anchor link to header"></a></h6>
<p>We can think of our typical data file as being made up of several vectors side by side each other, as columns. We can also think of a data file as a data matrix.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> Here is a tiny fictitious data set from Pituch and Stevens (2016, Ch. 4) containing nine counseling patients, three of whom are in one group of treatment (receiving a behavior-modification intervention), with the remaining 6 in a second group (receiving cognitive intervention). Each person is then measured on two continuous outcome variables: client satisfaction, <code>sa</code>, and client self-acceptance, <code>csa</code>.</p>
<p>Our data set includes nine observations and three variables, two of which are the dependent variables we just addressed, and one of which is a grouping variable, <code>grp</code>. I suppose we could count the <em>id</em> column as a variable, too, but we typically do not.</p>
<table>
<caption><span id="tab:unnamed-chunk-6">Table 1.1: </span>Our data set</caption>
<thead>
<tr class="header">
<th align="right">id</th>
<th align="right">grp</th>
<th align="right">sa</th>
<th align="right">csa</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">1</td>
<td align="right">3</td>
<td align="right">7</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">2</td>
<td align="right">4</td>
<td align="right">6</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">2</td>
<td align="right">6</td>
<td align="right">8</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">2</td>
<td align="right">6</td>
<td align="right">8</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="right">2</td>
<td align="right">5</td>
<td align="right">10</td>
</tr>
<tr class="even">
<td align="right">8</td>
<td align="right">2</td>
<td align="right">5</td>
<td align="right">10</td>
</tr>
<tr class="odd">
<td align="right">9</td>
<td align="right">2</td>
<td align="right">4</td>
<td align="right">6</td>
</tr>
</tbody>
</table>
<p>A data set is a type of matrix—it is an <span class="math inline">\(N \times p\)</span> (said as “n by p”) data matrix, with <em>N</em> being the number of rows and <em>p</em> being the number of columns.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<p><span class="math display">\[\mathbf{X} = \begin{bmatrix}1&amp;1&amp; 3 \\1&amp;3&amp; 7 \\1&amp;2&amp; 2 \\2&amp;4&amp; 6 \\2&amp;6&amp; 8 \\2&amp;6&amp; 8 \\2&amp;5&amp;10 \\2&amp;5&amp;10 \\2&amp;4&amp; 6 \\\end{bmatrix}\]</span></p>
<p>Sometimes, we hear the term <em><strong>order</strong></em> of a matrix, which is another way to say the number of rows and number of columns; the order of this matrix is <span class="math inline">\(9 \times 3\)</span> (said as “9 by 3”).<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> Each cell in a matrix or vector is called an <em>element</em>. The coordinate of an element is labeled based on its row and column location, in that order. For example, cell <span class="math inline">\(X[3,2]\)</span> is the third row and second column, which is a value of <span class="math inline">\(2\)</span> in our data matrix, corresponding with Person 3’s score on the <code>sa</code> variable.</p>
</div>
</div>
<div id="symmetrical-matrices" class="section level2 hasAnchor" number="1.4">
<h2><span class="header-section-number">1.4</span> Symmetrical Matrices<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#symmetrical-matrices" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Whereas data matrices are usually rectangular (with more <em>N</em> than <em>p</em>), variance-covariance and sum-of-squares-and-cross-products matrices are symmetrical, taking the shape of a square matrix. That is, they have the same number of columns and rows. Their numbers on each side of the off-diagonal are mirrored.</p>
<div id="variance-covariance-matrices" class="section level3 hasAnchor" number="1.4.1">
<h3><span class="header-section-number">1.4.1</span> Variance-covariance Matrices<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#variance-covariance-matrices" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One example of a symmetrical matrix that we often encounter in statistics (and measurement) is the variance-covariance matrix. Each row and each column are the variables, just as we see in a correlation matrix. This is of the order <span class="math inline">\(p \times p\)</span>; for example, if we have two variables, it is a <span class="math inline">\(2 \times 2\)</span> matrix. A <span class="math inline">\(3 \times 3\)</span> covariance is structured like this:</p>
<p><span class="math display">\[\mathbf{S} = \begin{bmatrix} s^2_1 \quad s_{1,2}  \quad s_{1,3} \\[.5em] s_{2,1} \quad s^2_2   \quad s_{2,3} \\[.5em] s_{3,1}  \quad s_{3,2}  \quad s^2_3  \end{bmatrix}\]</span>
The variances are along the diagonal and the covariances on the off-diagonal. Here is another way to write this same matrix:</p>
<p><span class="math display">\[\mathbf{S} = \begin{bmatrix} Var(y_1)  \quad  Cov(y_1,y_2),  \quad Cov(y_1,y_3) \\[1em] Cov(y_2,y_1)  \quad Var(y_2) \quad   Cov(y_2,y_3) \\[1em] Cov(y_3,y_1)  \quad Cov(y_3, y_2)  \quad Var(y_3) \quad   \end{bmatrix}\]</span></p>
<p>The symbol <span class="math inline">\(\mathbf{S}\)</span> is usually used to indicate the observed variance-covariance matrix.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> If we have a correlation matrix, it is usually represented as <span class="math inline">\(\mathbf{R}\)</span>:
<span class="math display">\[\mathbf{R} = \begin{bmatrix} 1  \quad  r_{1,2}  \quad r_{1,3} \\[.5em] r_{2,1} \quad 1   \quad r_{2,3} \\[.5em] r_{3,1}  \quad r_{3,2}  \quad 1  \end{bmatrix}\]</span></p>
<p>Matrices are typically symbolized as boldface and upper case. In this course, we will see matrices labeled as <span class="math inline">\(\mathbf{R}\)</span>, <span class="math inline">\(\mathbf{S}\)</span>, <span class="math inline">\(\mathbf{SSCP}\)</span>, <span class="math inline">\(\mathbf{B}\)</span>, <span class="math inline">\(\mathbf{W}\)</span>, <span class="math inline">\(\mathbf{D}\)</span>, and <span class="math inline">\(\mathbf{C}\)</span>, and some of the more terrifying Greek-symbol matrices used in factor analysis, <span class="math inline">\(\mathbf{\Lambda}\)</span>, <span class="math inline">\(\mathbf{\Sigma}\)</span>, <span class="math inline">\(\mathbf{\Phi}\)</span>, and <span class="math inline">\(\mathbf{\Theta}\)</span>.</p>
</div>
<div id="greek-letters" class="section level3 hasAnchor" number="1.4.2">
<h3><span class="header-section-number">1.4.2</span> Greek letters<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#greek-letters" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We will sometimes encounter two versions of the variance-covariance matrix, <span class="math inline">\(\mathbf{S}\)</span> and <span class="math inline">\(\mathbf{\Sigma}\)</span> (uppercase sigma). Just as is the custom in univariate statistics, Greek letters are often used for the population. For instance, here is the corresponding population variance-covariance matrix for <span class="math inline">\(\mathbf{S}\)</span>:</p>
<p><span class="math display">\[\mathbf{\Sigma} = \begin{bmatrix} \sigma^2_1  \quad \sigma_{1,2}  \quad \sigma_{1,3} \\[.5em] \sigma_{2,1}\ \quad \sigma^2_2   \quad \sigma_{2,3} \\[.5em] \sigma_{3,1}  \quad \sigma_{3,1}  \quad \sigma^2_3  \end{bmatrix}\]</span>
Greek symbols invite extra cognitive load in our learning of stats for those of us who do not speak Greek or who have not worked in statistics for very long. Here’s a general pattern that might help you remember how this works:</p>
<ul>
<li>Frequently, the Greek letters we use for a population statistic have the same initial phonetic sound as their sample counterparts. Here are some examples:
<ul>
<li>the population <strong>m</strong>ean is represented as <span class="math inline">\(\mu\)</span> (pronounced “moo” or sometimes “myoo”),</li>
<li>the population <strong>s</strong>tandard deviation (which is the square root of the variance) is represented as <span class="math inline">\(\sigma\)</span> (sigma),</li>
<li>The population correlation, which is <span class="math inline">\(r\)</span> for the sample, is represented as <span class="math inline">\(\rho\)</span> (rho, as in “row” your boat).</li>
</ul></li>
</ul>
<p>Above, we have a boldfaced uppercase Greek letter sigma (<span class="math inline">\(\mathbf{\Sigma}\)</span>) representing the population variance-covariance matrix and we have lowercase sigmas representing the variances (<span class="math inline">\(\sigma^2_{i}\)</span>) and covariances (<span class="math inline">\(\sigma_{i,j}\)</span>) for each variable or pair of variables. The corresponding <em>sample</em> matrix will be labeled as <span class="math inline">\(\mathbf{S}\)</span> (or sometimes capital sigma hat, <span class="math inline">\(\mathbf{\hat{\Sigma}}\)</span>, to represent an estimate of the population matrix) and will have <span class="math inline">\(s_i\)</span> and <span class="math inline">\(s_{i,j}\)</span> (or <span class="math inline">\(\hat{\sigma^2}_i\)</span> and <span class="math inline">\(\hat{\sigma}_{i,j}\)</span>) in the elements of the matrix.
We’ll see this general pattern with other matrices. For example, in discussions about principal components analysis, we’ll see an uppercase lambda (<span class="math inline">\(\Lambda\)</span>) as a matrix label, with lowercase lambdas (<span class="math inline">\(\mathbf{\lambda_i}\)</span>) along the diagonal. We might see some authors label this same matrix as <span class="math inline">\(\mathbf{L}\)</span> instead of <span class="math inline">\(\mathbf{\Lambda}\)</span>.</p>
</div>
<div id="example-variance-covariance-matrix" class="section level3 hasAnchor" number="1.4.3">
<h3><span class="header-section-number">1.4.3</span> Example variance-covariance matrix<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#example-variance-covariance-matrix" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s look at a variance-covariance matrix of our two dependent variables, <code>sa</code> and <code>csa</code>, from our example data set. The variance is on the diagonal, which is <span class="math inline">\(3.00\)</span> for <code>sa</code> and <span class="math inline">\(7.75\)</span> for <code>csa</code>. The covariance between the two variables is on the off diagonal and is identical, <span class="math inline">\(4.00\)</span> in this case, because the covariance of <code>sa</code> with <code>csa</code> (Cell 1,2) is the same as the covariance of <code>csa</code> with <code>sa</code> (Cell 2,1).</p>
<p>In matrix format, it looks like this:</p>
<p><span class="math display">\[\mathbf{S} = \begin{bmatrix}3.00&amp;4.00 \\4.00&amp;7.75 \\\end{bmatrix}\]</span></p>
<p>The term <em>variance-covariance matrix</em> is long, so people usually use the term <strong>covariance matrix</strong>. This is logical because the covariance of a variable with itself is actually computationally the same as the variance.<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a></p>
</div>
<div id="the-diagonal-and-trace" class="section level3 hasAnchor" number="1.4.4">
<h3><span class="header-section-number">1.4.4</span> The diagonal and trace<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#the-diagonal-and-trace" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Above, we used the term <em>diagonal</em> a few times. The diagonal of a square matrix includes the series of elements from the top left corner to the bottom right corner. Here, the diagonal of our matrix <span class="math inline">\(\mathbf{S}\)</span> is
<span class="math display">\[\text{diag}(\mathbf{S}) = \text{diag}\begin{bmatrix}3.00&amp;4.00 \\4.00&amp;7.75 \\\end{bmatrix} = \begin{bmatrix}3.00&amp;7.75 \end{bmatrix}\]</span>
The diagonal of a covariance matrix includes all the variances. The off-diagonal includes all the covariances.</p>
<p>The trace of a matrix is the sum of the elements in the diagonal:
<span class="math display">\[\text{tr}(\mathbf{S}) = \text{tr}\begin{bmatrix}3.00&amp;4.00 \\4.00&amp;7.75 \\\end{bmatrix} = 10.75\]</span>
We encounter the diagonal and trace in the explanations about the multivariate computation, particularly in principal components analysis.</p>
</div>
<div id="an-identity-matrix" class="section level3 hasAnchor" number="1.4.5">
<h3><span class="header-section-number">1.4.5</span> An identity matrix<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#an-identity-matrix" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>An identity matrix has all ones along the diagonal and zeros in the off-diagonal, here is a <span class="math inline">\(3 \times 3\)</span> identity matrix:</p>
<p><span class="math display">\[\mathbf{I} = \begin{bmatrix}1&amp;0&amp;0 \\0&amp;1&amp;0 \\0&amp;0&amp;1 \\\end{bmatrix}\]</span></p>
</div>
</div>
<div id="transposed-vectors-and-matrices" class="section level2 hasAnchor" number="1.5">
<h2><span class="header-section-number">1.5</span> Transposed Vectors and Matrices<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#transposed-vectors-and-matrices" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>When we see a vector in our multivariate equations, we usually assume it is arranged as a vertical string of numbers. This is how we presented our vector earlier (here, we’ll label it <span class="math inline">\(\mathbf{sa}\)</span>, whereas before, it was <span class="math inline">\(\mathbf{a}\)</span>):
<span class="math display">\[\mathbf{sa}= \begin{bmatrix}1\\3\\2\\4\\6\\6\\5\\5\\4 \end{bmatrix}\]</span>
If we walk over and kicked that vector on its side, we transpose that vector. It’s now a horizontal vector.
<span class="math display">\[\mathbf{sa^{\prime}} = \begin{bmatrix}1&amp;3&amp;2&amp;4&amp;6&amp;6&amp;5&amp;5&amp;4 \end{bmatrix}\]</span></p>
<p>In our course readings, we will see a prime, <span class="math inline">\(\mathbf{\prime}\)</span>, next to a vector or matrix to indicate that it is transposed; for example, the transpose of <span class="math inline">\(\mathbf{S}\)</span> is symbolized as <span class="math inline">\(\mathbf{S^\prime}\)</span>. Many other authors instead use a superscript <strong>T</strong> to indicate transpose: <span class="math inline">\(\mathbf{S}^\intercal\)</span>.</p>
<p>If we transposed the <span class="math inline">\(\mathbf{S}\)</span> matrix above, we would be interchanging the rows and columns, so the first column in <span class="math inline">\(\mathbf{S}\)</span> becomes the first row in <span class="math inline">\(\mathbf{S^\prime}\)</span>, the second column in <span class="math inline">\(\mathbf{S}\)</span> becomes the second row in <span class="math inline">\(\mathbf{S^\prime}\)</span>, and so forth. If we transposed our data matrix, for some reason, it would look like this:</p>
<p><span class="math display">\[\text{Transpose of } \begin{bmatrix}1&amp;1&amp; 3 \\1&amp;3&amp; 7 \\1&amp;2&amp; 2 \\2&amp;4&amp; 6 \\2&amp;6&amp; 8 \\2&amp;6&amp; 8 \\2&amp;5&amp;10 \\2&amp;5&amp;10 \\2&amp;4&amp; 6 \\\end{bmatrix} =  \begin{bmatrix} 1&amp; 1&amp; 1&amp; 2&amp; 2&amp; 2&amp; 2&amp; 2&amp; 2 \\ 1&amp; 3&amp; 2&amp; 4&amp; 6&amp; 6&amp; 5&amp; 5&amp; 4 \\ 3&amp; 7&amp; 2&amp; 6&amp; 8&amp; 8&amp;10&amp;10&amp; 6 \\\end{bmatrix}\]</span></p>
</div>
<div id="matrix-addition-and-subtraction" class="section level2 hasAnchor" number="1.6">
<h2><span class="header-section-number">1.6</span> Matrix Addition and Subtraction<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#matrix-addition-and-subtraction" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We can add two matrices together if they are the same order (recall that <em>order</em> refers to the number of rows and columns). For example, if we added <span class="math inline">\(\mathbf{A}\)</span> and <span class="math inline">\(\mathbf{B}\)</span>, we can get matrix <span class="math inline">\(\mathbf{C}\)</span>.</p>
<p><span class="math display">\[\mathbf{A} = \begin{bmatrix}2&amp;4 \\3&amp;5 \\\end{bmatrix}\]</span>
<span class="math display">\[\mathbf{B} = \begin{bmatrix} 6&amp;10 \\ 8&amp; 2 \\\end{bmatrix}\]</span>
<span class="math display">\[\mathbf{C}= \begin{bmatrix}2&amp;4 \\3&amp;5 \\\end{bmatrix} + \begin{bmatrix} 6&amp;10 \\ 8&amp; 2 \\\end{bmatrix} =
\begin{bmatrix} 8&amp;14 \\11&amp; 7 \\\end{bmatrix}\]</span></p>
<p>This is because <span class="math inline">\(2 + 6 = 8\)</span> for Cell [1,1] of <span class="math inline">\(\mathbf{C}\)</span>,</p>
<p><span class="math inline">\(3 + 8 = 11\)</span> for the Cell [1,2],</p>
<p><span class="math inline">\(4 + 10 = 14\)</span> for the Cell [2,1],</p>
<p>and <span class="math inline">\(5 + 2 = 7\)</span> for the Cell [2,2].</p>
<p>The same procedure works with subtraction.</p>
<p><span class="math display">\[\begin{bmatrix}2&amp;4 \\3&amp;5 \\\end{bmatrix} - \begin{bmatrix} 6&amp;10 \\ 8&amp; 2 \\\end{bmatrix} =
\begin{bmatrix}-4&amp;-6 \\-5&amp; 3 \\\end{bmatrix}\]</span></p>
</div>
<div id="operations-on-matrices-with-a-scalar" class="section level2 hasAnchor" number="1.7">
<h2><span class="header-section-number">1.7</span> Operations on Matrices with a Scalar<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#operations-on-matrices-with-a-scalar" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We can also perform operations on a matrix with a scalar. We could, for instance, let’s take a vector (a one column matrix) and subtract a scalar from it. For example, let’s subtract the mean of <code>sa</code> (which is 4) from each score, to get a vector of deviation scores (or centered scores).</p>
<p><span class="math display">\[\begin{bmatrix}1\\3\\2\\4\\6\\6\\5\\5\\4 \end{bmatrix} - 4 = \begin{bmatrix}-3\\-1\\-2\\ 0\\ 2\\ 2\\ 1\\ 1\\ 0 \end{bmatrix}\]</span></p>
<p>Similarly, we can multiply by a scalar. For example, we can multiply <span class="math inline">\(\mathbf{B}\)</span> by 2:</p>
<p><span class="math display">\[2\mathbf{B}= \begin{bmatrix} 6&amp;10 \\ 8&amp; 2 \\\end{bmatrix} \times 2 = \begin{bmatrix}12&amp;20 \\16&amp; 4 \\\end{bmatrix}\]</span></p>
<div id="sum-of-square-and-cross-product-sscp-matrices" class="section level3 hasAnchor" number="1.7.1">
<h3><span class="header-section-number">1.7.1</span> Sum-of-square-and-cross-product (SSCP) matrices<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#sum-of-square-and-cross-product-sscp-matrices" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In ANOVA, the sum of the squared deviations (or sums of squares, <em>SS</em>, for short) is often used. The SS is the numerator in the calculation of the variance, <span class="math display">\[\frac{\Sigma(y_i-\bar{y})^2}{n-1}\]</span>
This is useful because if our computer program outputs the variance, we can get the SS by multiplying the variance by the denominator (the degrees of freedom), <span class="math display">\[SS_y = \frac{\Sigma(y_i-\bar{y})^2}{n-1} (n-1)\]</span></p>
<p>In MANOVA, we use the matrix version of SS, which is the sum-of-squares-and-cross-products (<strong>SSCP</strong>) matrix. With matrices, we can multiply each element by a single number (again, called a <em>scalar</em>) and get a new matrix.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> Here, we’re multiplying the variance by its degrees of freedom (which is <span class="math inline">\(n-1\)</span>) to get the SSCP matrix.</p>
<p><span class="math display">\[\mathbf{SSCP} = \begin{bmatrix}3.00&amp;4.00 \\4.00&amp;7.75 \\\end{bmatrix} \times 8 = \begin{bmatrix}24.00&amp;32.00 \\32.00&amp;62.00 \\\end{bmatrix}\]</span></p>
</div>
<div id="operations-on-elements-of-a-matrix-example-with-a-correlation-matrix" class="section level3 hasAnchor" number="1.7.2">
<h3><span class="header-section-number">1.7.2</span> Operations on elements of a matrix: Example with a correlation matrix<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#operations-on-elements-of-a-matrix-example-with-a-correlation-matrix" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Similar to scalar addition and subtraction, we can also perform operations on individual elements of a matrix. We might use this to get a correlation matrix from a covariance matrix. The formula for correlation between two variables is <span class="math inline">\(r_{x,y} = \frac{cov(x,y)} {s_xs_y}\)</span>. We can extend this to multiple elements in a covariance matrix to calculate its corresponding correlation matrix. Here’s our covariance matrix from our data set:</p>
<p><span class="math display">\[\mathbf{S} = \begin{bmatrix}3.00&amp;4.00 \\4.00&amp;7.75 \\\end{bmatrix}\]</span></p>
<p>The standard deviation of each of the two variables is the square root of its variance:</p>
<p><span class="math display">\[s_{y1} = \sqrt{3.00} = 1.73\]</span>
<span class="math display">\[s_{y2} = \sqrt{7.75} = 2.78\]</span>
Divide each element of our <span class="math inline">\(\mathbf{S}\)</span> matrix by the product of the standard deviations of the variables on the row and column. If this is on the diagonal, this is the same as the square.<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a></p>
<p><span class="math display">\[\mathbf{R} = \begin{bmatrix} \frac{3.00}{1.73^2} \quad \frac{4.00}{1.73 \times2.78} \\[.5em] \frac{4.00}{1.73 \times2.78}  \quad \frac{7.75}{2.78^2}  \end{bmatrix} = \begin{bmatrix}1.00&amp;0.83 \\0.83&amp;1.00 \\\end{bmatrix}\]</span></p>
</div>
</div>
<div id="matrix-multiplication" class="section level2 hasAnchor" number="1.8">
<h2><span class="header-section-number">1.8</span> Matrix Multiplication<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#matrix-multiplication" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Matrix multiplication is very different from multiplying a matrix by a scalar or performing individual operations on the elements. When we multiply two matrices together, we multiply the elements of the row of the first matrix by the elements of the column of the second matrix and sum them up to a single number, which populates a single cell in the resulting matrix. We then multiply the elements of the next row in the first matrix by the elements in the first column in the second matrix and populate the next cell in the resulting matrix, and so forth. Let’s use a bare-bones example to illustrate this, with <span class="math inline">\(\mathbf{A}\)</span> and <span class="math inline">\(\mathbf{B}\)</span>, which we had used above with matrix addition:</p>
<p><span class="math display">\[\mathbf{AB} = \begin{bmatrix}2&amp;4 \\3&amp;5 \\\end{bmatrix} \begin{bmatrix} 6&amp;10 \\ 8&amp; 2 \\\end{bmatrix} =
\begin{bmatrix}44&amp;28 \\58&amp;40 \\\end{bmatrix}\]</span></p>
<p>The first cell of <span class="math inline">\(\mathbf{AB}\)</span> is calculated as <span class="math inline">\((2 \times 6) + (4 \times 8) = 44\)</span>. In this procedure, the <span class="math inline">\(2\)</span> is from Cell <span class="math inline">\([1,1]\)</span> of the first matrix, the <span class="math inline">\(6\)</span> is from Cell <span class="math inline">\([1,1]\)</span> of the second matrix. Then, the <span class="math inline">\(4\)</span> is from Cell <span class="math inline">\([1,2]\)</span> of the first matrix, while the <span class="math inline">\(8\)</span> is from Cell <span class="math inline">\([2,1]\)</span> of the second matrix. The sum of these products, <span class="math inline">\(44\)</span>, goes in Cell <span class="math inline">\([1,1]\)</span> of matrix <span class="math inline">\(\mathbf{AB}\)</span>.</p>
<p>Row 2 and Column 1 of <span class="math inline">\(\mathbf{AB}\)</span> is calculated as <span class="math inline">\((3 \times 6) + (5 \times 8) = 58\)</span>.</p>
<p>Row 1 and Column 2 of <span class="math inline">\(\mathbf{AB}\)</span> is calculated as <span class="math inline">\((2 \times 10) + (4 \times 2) = 28\)</span>.</p>
<p>Row 2 and Column 2 of <span class="math inline">\(\mathbf{AB}\)</span> is calculated as <span class="math inline">\((3 \times 10) + (5 \times 2) = 40\)</span>.</p>
<p>This procedure only succeeds when the number of columns in the first matrix is the same as the number of rows in second matrix.</p>
<div id="another-example-of-matrix-multiplication-to-get-the-sscp" class="section level3 hasAnchor" number="1.8.1">
<h3><span class="header-section-number">1.8.1</span> Another example of matrix multiplication, to get the SSCP<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#another-example-of-matrix-multiplication-to-get-the-sscp" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Another way to get the <span class="math inline">\(\mathbf{SSCP}\)</span> matrix is to first calculate the deviation scores, <span class="math inline">\(x_{ij} - \bar{x}_j\)</span>, as we did above when we subtracted the mean (4) from the vector <code>sa</code>. If we did this for the other vector, <code>csa</code>, we can then stick them together into a matrix of deviation scores. Then, we can use matrix multiplication of the transpose of this matrix with itself. Arbitrarily, we’ll label this matrix of deviation scores as <span class="math inline">\(\mathbf{C}\)</span>.<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a></p>
<p><span class="math display">\[\mathbf{SSCP} = \mathbf{C^{\prime}C}\]</span>
<span class="math display">\[\mathbf{SSCP} = \begin{bmatrix}-3.00&amp;-1.00&amp;-2.00&amp; 0.00&amp; 2.00&amp; 2.00&amp; 1.00&amp; 1.00&amp; 0.00 \\-3.67&amp; 0.33&amp;-4.67&amp;-0.67&amp; 1.33&amp; 1.33&amp; 3.33&amp; 3.33&amp;-0.67 \\\end{bmatrix} \begin{bmatrix}-3.00&amp;-3.67 \\-1.00&amp; 0.33 \\-2.00&amp;-4.67 \\ 0.00&amp;-0.67 \\ 2.00&amp; 1.33 \\ 2.00&amp; 1.33 \\ 1.00&amp; 3.33 \\ 1.00&amp; 3.33 \\ 0.00&amp;-0.67 \\\end{bmatrix} = \begin{bmatrix}24.00&amp;32.00 \\32.00&amp;62.00 \\\end{bmatrix}\]</span></p>
<p>Notice that the order of the resulting matrix is <span class="math inline">\(2 \times 2\)</span>. This is because there were two rows in the first matrix, <span class="math inline">\(\mathbf{C^\prime}\)</span>, and two columns in the second one, <span class="math inline">\(\mathbf{C}\)</span>. This is the kind of operation we encounter a lot in multivariate statistics.</p>
<p>The sum of the squared deviation scores of the <code>sa</code> variable is calculated using the top row of the first matrix, <span class="math inline">\(\mathbf{C^\prime}\)</span>, and the first column of the second matrix, <span class="math inline">\(\mathbf{C}\)</span>. We’re squaring and summing. When we use the top row of the first matrix and the second column of the second matrix, we are taking the sum of the cross products of <code>sa</code> and <code>csa</code>.</p>
</div>
<div id="the-ordering-is-important" class="section level3 hasAnchor" number="1.8.2">
<h3><span class="header-section-number">1.8.2</span> The ordering is important<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#the-ordering-is-important" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In matrix multiplication, the order is important. Above, we saw the result of <span class="math inline">\(\mathbf{A} \times \mathbf{B}\)</span>:</p>
<p><span class="math display">\[\mathbf{AB} = \begin{bmatrix}2&amp;4 \\3&amp;5 \\\end{bmatrix} \begin{bmatrix} 6&amp;10 \\ 8&amp; 2 \\\end{bmatrix} =
\begin{bmatrix}44&amp;28 \\58&amp;40 \\\end{bmatrix}\]</span></p>
<p>This is a different result from <span class="math inline">\(\mathbf{B} \times \mathbf{A}\)</span>:</p>
<p><span class="math display">\[\mathbf{BA} = \begin{bmatrix} 6&amp;10 \\ 8&amp; 2 \\\end{bmatrix} \begin{bmatrix}2&amp;4 \\3&amp;5 \\\end{bmatrix} =
\begin{bmatrix}42&amp;74 \\22&amp;42 \\\end{bmatrix}\]</span></p>
<p>In the same way, <span class="math inline">\(\mathbf{C^{\prime}C} \ne \mathbf{CC^{\prime}}\)</span>.</p>
</div>
</div>
<div id="inverse-of-a-matrix" class="section level2 hasAnchor" number="1.9">
<h2><span class="header-section-number">1.9</span> Inverse of a Matrix<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#inverse-of-a-matrix" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>It is not possible to divide matrices. Instead, we multiply one matrix by the inverse of another matrix. The inverse is symbolized as a superscript <span class="math inline">\(^-1\)</span> on the matrix. The inverse is analogous to the reciprocal in regular math. For example, the reciprocal of 4 is <span class="math inline">\(1 \div 4 = .25\)</span>, <span class="math display">\[4^{-1} = \frac{1}{4} = 0.25\]</span>
In matrix algebra, inverting a matrix involves several steps.<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a> For this procedure, we can rely on software. For example, in R, we can use the <code>solve()</code> function. In SPSS, we can use the <code>INV()</code> function in the syntax editor. Here is the inverse of a matrix, <span class="math inline">\(\mathbf{S}\)</span>, which is symbolized as <span class="math inline">\(\mathbf{S^{-1}}\)</span>:</p>
<p><span class="math display">\[\mathbf{S} = \begin{bmatrix}3.00&amp;4.00 \\4.00&amp;7.75 \\\end{bmatrix}\]</span></p>
<p><span class="math display">\[\mathbf{S^{-1}} = \begin{bmatrix} 1.07&amp;-0.55 \\-0.55&amp; 0.41 \\\end{bmatrix}\]</span>
If we multiplied <span class="math inline">\(\mathbf{B}\)</span> by this inverted <span class="math inline">\(\mathbf{S}\)</span> matrix, we have something analogous to dividing <span class="math inline">\(\mathbf{B}\)</span> by <span class="math inline">\(\mathbf{S}\)</span>:</p>
<p><span class="math display">\[\mathbf{BS^{-1}} =  \begin{bmatrix} 6&amp;10 \\ 8&amp; 2 \\\end{bmatrix} \begin{bmatrix} 1.07&amp;-0.55 \\-0.55&amp; 0.41 \\\end{bmatrix} = \begin{bmatrix} 0.90&amp; 0.83 \\ 7.45&amp;-3.59 \\\end{bmatrix}\]</span>
We’ll see this when we calculate test-statistic ratios for our hypothesis tests. This is a generalization of univariate test statistics. For example, with ANOVA our <em>F</em>-statistic is with individual numbers, such as <span class="math inline">\(F = MS_b / MS_w\)</span>, which is the same as <span class="math inline">\(F = MS_b \times MS_w^{-1}\)</span>. With MANOVA, we cannot divide matrices, but we can multiply by inverses, such as <span class="math inline">\(\mathbf{B}\mathbf{W^{-1}}\)</span>.</p>
</div>
<div id="matrix-determinants-as-generalized-variance" class="section level2 hasAnchor" number="1.10">
<h2><span class="header-section-number">1.10</span> Matrix determinants, as generalized variance<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#matrix-determinants-as-generalized-variance" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The determinant of a square matrix is a single number that represents the <strong><em>generalized variance</em></strong> of all the data in our multivariate matrix. It is one way to represent the amount of variability in a set of variables after removing their shared variability. This is handy because in ANOVA, we analyze the variance of the Between and Within portions of our single dependent variable. In MANOVA, the variance includes the variances and covariances of multiple dependent variables. For this we use the generalized variance of the Between and Within portions of our data.</p>
<p>It is symbolized as <span class="math inline">\(\text{det}(\mathbf{X})\)</span> or <span class="math inline">\(|\mathbf{X}|\)</span>. It is best to let the computer calculate this. In SPSS, we can use the <code>DET()</code> function in the syntax editor; in R, it is <code>det()</code>. The determinant of our, <span class="math inline">\(\mathbf{S}\)</span> matrix, <span class="math inline">\(|\mathbf{S}|\)</span>, is <span class="math inline">\(7.25\)</span>. Here’s <span class="math inline">\(\mathbf{S}\)</span>, which above was our covariance matrix of our small data set:</p>
<p><span class="math display">\[\mathbf{S} = \begin{bmatrix}3.00&amp;4.00 \\4.00&amp;7.75 \\\end{bmatrix}\]</span></p>
<p><span class="math display">\[|\mathbf{S}| = 7.25\]</span>
For this simple matrix, we could calculate this by hand but with higher-order matrices, this gets tedious very quickly.<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a></p>
<p>We will encounter the determinant when we examine how the test statistic for MANOVA is calculated. Knowledge of its existence also becomes useful when we encounter errors in our software output when we try to conduct some of the advance multivariate methods, such as confirmatory factor analysis.<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a></p>
</div>
<div id="eigenvectors-and-eigenvalues" class="section level2 hasAnchor" number="1.11">
<h2><span class="header-section-number">1.11</span> Eigenvectors and Eigenvalues<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#eigenvectors-and-eigenvalues" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We will address eigenvectors and eigenvalues in this course (but we will not calculate them, as that goes beyond our needs). We can think of eigenvalues as individual numbers that represent the variance of restructured linear combinations of the dependent variables. Eigenvectors are, not surprisingly, vectors of numbers. Each element in the vector serves as a weight on a variable in a manner similar to regression coefficients. The result (analogous to a dependent variable in regression) of this linear combination of weighted variables goes by many names, including composite, component, discrimination function, and so forth. Each observation (each person) in a data set has a score on the component. The variance of each component of scores is the eigenvalue. Many of the test statistics in multivariate methods use eigenvalues.</p>
<p>Eigenvectors and eigenvalues come up especially in principal components analysis but are actually used under the hood in almost all of the multivariate statistics in this class.<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a> We’ll address eigenvalues and eigenvectors using a visual representation. For now, just be aware that these terms exist.</p>
</div>
<div id="summary" class="section level2 hasAnchor" number="1.12">
<h2><span class="header-section-number">1.12</span> Summary<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#summary" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Here are some of the terms we have encountered.</p>
<ul>
<li><strong>scalars</strong> are individual numbers. Usually these are lowercase and <em>not</em> boldfaced.</li>
<li><strong>vectors</strong> are columns of numbers. Usually these are lowercase and boldfaced, as in <span class="math inline">\(\mathbf{a}\)</span>.</li>
<li><strong>matrices</strong> are rectangular or square, with data in each cell. Usually these are uppercase and boldfaced, as in <span class="math inline">\(\mathbf{A}\)</span>.</li>
<li><strong>order</strong> of a matrix is its dimensionality, with rows first and columns second.</li>
<li><strong>elements</strong> are individual numbers in a matrix or vector.</li>
<li><strong>diagonal</strong> is all the elements from the top left to the bottom right of a matrix.</li>
<li><strong>trace</strong> is the sum of all the elements in a diagonal.</li>
<li><strong>transposed</strong> matrices are pushed over so their rows become columns and columns become rows. The symbol is a prime or a superscript T after the matrix, as in <span class="math inline">\(\mathbf{X^\prime}\)</span> or <span class="math inline">\(\mathbf{X}^\intercal\)</span>.</li>
<li><strong>matrix multiplication</strong> is a pain in the neck but is the most common operation we see in multivariate statistics.</li>
<li><strong>inverse</strong> matrices are used when we want to divide one matrix by another. It is symbolized with a superscript <span class="math inline">\(-1\)</span> after the matrix, as in <span class="math inline">\(\mathbf{X^{-1}}\)</span>.</li>
<li><strong>determinant</strong> of a matrix, symbolized as <span class="math inline">\(\text{det}(\mathbf{X})\)</span> or <span class="math inline">\(|\mathbf{X}|\)</span>, is the generalized variance of a matrix.</li>
<li><strong>eigenvectors</strong> and <strong>eigenvalues</strong> are are used in the process of creating linear composites of the dependent variables in a multivariate analysis.</li>
</ul>
</div>
<div id="optional-spss-and-r-code-to-manipulate-matrices" class="section level2 hasAnchor" number="1.13">
<h2><span class="header-section-number">1.13</span> Optional: SPSS and R Code to Manipulate Matrices<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#optional-spss-and-r-code-to-manipulate-matrices" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>This part is optional and for the curious. Here is some code to manually perform some matrix operations. This is using our two dependent variables, <code>sa</code> and <code>csa</code> from our data set, which we’re labeling as <code>y1</code> and <code>y2</code> in the code.</p>
<table>
<caption><span id="tab:unnamed-chunk-16">Table 1.2: </span>Our data set</caption>
<thead>
<tr class="header">
<th align="right">id</th>
<th align="right">grp</th>
<th align="right">sa</th>
<th align="right">csa</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">1</td>
<td align="right">3</td>
<td align="right">7</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">2</td>
<td align="right">4</td>
<td align="right">6</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">2</td>
<td align="right">6</td>
<td align="right">8</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">2</td>
<td align="right">6</td>
<td align="right">8</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="right">2</td>
<td align="right">5</td>
<td align="right">10</td>
</tr>
<tr class="even">
<td align="right">8</td>
<td align="right">2</td>
<td align="right">5</td>
<td align="right">10</td>
</tr>
<tr class="odd">
<td align="right">9</td>
<td align="right">2</td>
<td align="right">4</td>
<td align="right">6</td>
</tr>
</tbody>
</table>
<p>Here is the R code:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-1" tabindex="-1"></a><span class="co"># There are many ways to make a matrix. One is to use the `matrix()` function.</span></span>
<span id="cb2-2"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-2" tabindex="-1"></a><span class="co"># In this example, we have the data in two columns. We can use the </span></span>
<span id="cb2-3"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-3" tabindex="-1"></a><span class="co"># `byrow = TRUE` argument to tell R to fill in the matrix by rows. </span></span>
<span id="cb2-4"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-4" tabindex="-1"></a><span class="co"># The `ncol = 2` argument defines the order as an n x 2 matrix.</span></span>
<span id="cb2-5"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-5" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, </span>
<span id="cb2-6"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-6" tabindex="-1"></a>              <span class="dv">3</span>, <span class="dv">7</span>, </span>
<span id="cb2-7"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-7" tabindex="-1"></a>              <span class="dv">2</span>, <span class="dv">2</span>, </span>
<span id="cb2-8"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-8" tabindex="-1"></a>              <span class="dv">4</span>, <span class="dv">6</span>, </span>
<span id="cb2-9"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-9" tabindex="-1"></a>              <span class="dv">6</span>, <span class="dv">8</span>, </span>
<span id="cb2-10"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-10" tabindex="-1"></a>              <span class="dv">6</span>, <span class="dv">8</span>, </span>
<span id="cb2-11"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-11" tabindex="-1"></a>              <span class="dv">5</span>, <span class="dv">10</span>, </span>
<span id="cb2-12"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-12" tabindex="-1"></a>              <span class="dv">5</span>, <span class="dv">10</span>, </span>
<span id="cb2-13"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-13" tabindex="-1"></a>              <span class="dv">4</span>, <span class="dv">6</span>),</span>
<span id="cb2-14"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-14" tabindex="-1"></a>            <span class="at">byrow =</span> <span class="cn">TRUE</span>,</span>
<span id="cb2-15"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-15" tabindex="-1"></a>            <span class="at">ncol =</span> <span class="dv">2</span>)</span>
<span id="cb2-16"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-16" tabindex="-1"></a>Y <span class="do">## Prints to console</span></span>
<span id="cb2-17"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-17" tabindex="-1"></a></span>
<span id="cb2-18"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-18" tabindex="-1"></a><span class="co"># Another way to create a matrix is by binding columns of equal length data.</span></span>
<span id="cb2-19"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-19" tabindex="-1"></a><span class="co"># Here, we&#39;re calculating the deviation scores of each variable, then </span></span>
<span id="cb2-20"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-20" tabindex="-1"></a><span class="co"># sticking them together with `cbind()`.</span></span>
<span id="cb2-21"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-21" tabindex="-1"></a>y1 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">4</span>)</span>
<span id="cb2-22"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-22" tabindex="-1"></a>y2 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">7</span>, <span class="dv">2</span>, <span class="dv">6</span>, <span class="dv">8</span>, <span class="dv">8</span>,<span class="dv">10</span>,<span class="dv">10</span>, <span class="dv">6</span>)</span>
<span id="cb2-23"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-23" tabindex="-1"></a>C <span class="ot">&lt;-</span> <span class="fu">cbind</span>(y1 <span class="sc">-</span> <span class="fu">mean</span>(y1),</span>
<span id="cb2-24"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-24" tabindex="-1"></a>           y2 <span class="sc">-</span> <span class="fu">mean</span>(y2) )</span>
<span id="cb2-25"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-25" tabindex="-1"></a>C</span>
<span id="cb2-26"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-26" tabindex="-1"></a><span class="co"># Use `%*%` for matrix multiplication. Use `t()` for transposing.</span></span>
<span id="cb2-27"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-27" tabindex="-1"></a>SSCP <span class="ot">&lt;-</span> <span class="fu">t</span>(C) <span class="sc">%*%</span> C</span>
<span id="cb2-28"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-28" tabindex="-1"></a>SSCP</span>
<span id="cb2-29"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-29" tabindex="-1"></a><span class="co"># To get the covariance matrix from SSCP, we divide each element by n - 1.</span></span>
<span id="cb2-30"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-30" tabindex="-1"></a><span class="co"># In other words, we&#39;re dividing the matrix by a scalar.</span></span>
<span id="cb2-31"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-31" tabindex="-1"></a>S <span class="ot">&lt;-</span> SSCP <span class="sc">/</span> (<span class="fu">nrow</span>(Y) <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb2-32"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-32" tabindex="-1"></a>S</span>
<span id="cb2-33"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-33" tabindex="-1"></a><span class="co"># If we wanted to calculate the determinant, we use the `det()` function:</span></span>
<span id="cb2-34"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-34" tabindex="-1"></a><span class="fu">det</span>(S)</span>
<span id="cb2-35"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-35" tabindex="-1"></a><span class="co"># If we wanted the inverse of the matrix, we use the `solve()` function:</span></span>
<span id="cb2-36"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb2-36" tabindex="-1"></a><span class="fu">solve</span>(S)</span></code></pre></div>
<p>Here is the SPSS code to accomplish the same thing.
<!-- So far, `awk` and `sed` languages show up okay in inline. --></p>
<div class="sourceCode" id="cb3"><pre class="sourceCode awk"><code class="sourceCode awk"><span id="cb3-1"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb3-1" tabindex="-1"></a><span class="ot">/*</span><span class="ss"> Tell SPSS that the following will use matrix mode</span><span class="ot">.</span></span>
<span id="cb3-2"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb3-2" tabindex="-1"></a>MATRIX.</span>
<span id="cb3-3"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb3-3" tabindex="-1"></a><span class="ot">/*</span><span class="ss"> Creating two vectors, using semicolons between numbers to make them vertical</span><span class="ot">.</span></span>
<span id="cb3-4"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb3-4" tabindex="-1"></a>COMPUTE y1 <span class="op">=</span> <span class="op">{</span><span class="dv">1</span><span class="op">;</span> <span class="dv">3</span><span class="op">;</span> <span class="dv">2</span><span class="op">;</span> <span class="dv">4</span><span class="op">;</span> <span class="dv">6</span><span class="op">;</span> <span class="dv">6</span><span class="op">;</span> <span class="dv">5</span><span class="op">;</span> <span class="dv">5</span><span class="op">;</span> <span class="dv">4</span><span class="op">}</span>.</span>
<span id="cb3-5"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb3-5" tabindex="-1"></a>COMPUTE y2 <span class="op">=</span> <span class="op">{</span><span class="dv">3</span><span class="op">;</span> <span class="dv">7</span><span class="op">;</span> <span class="dv">2</span><span class="op">;</span> <span class="dv">6</span><span class="op">;</span> <span class="dv">8</span><span class="op">;</span> <span class="dv">8</span><span class="op">;</span><span class="dv">10</span><span class="op">;</span><span class="dv">10</span><span class="op">;</span> <span class="dv">6</span><span class="op">}</span>.</span>
<span id="cb3-6"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb3-6" tabindex="-1"></a><span class="ot">/*</span><span class="ss"> Now subtracting the mean from the vectors to get mean-centered vectors</span><span class="ot">.</span></span>
<span id="cb3-7"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb3-7" tabindex="-1"></a>COMPUTE c1 <span class="op">=</span> y1 <span class="op">-</span> <span class="fl">4.</span></span>
<span id="cb3-8"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb3-8" tabindex="-1"></a>COMPUTE c2 <span class="op">=</span> y2 <span class="op">-</span> <span class="dv">6</span>.<span class="fl">666667.</span></span>
<span id="cb3-9"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb3-9" tabindex="-1"></a><span class="ot">/*</span><span class="ss"> Sticking the two vertical vectors together into a matrix</span><span class="ot">.</span></span>
<span id="cb3-10"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb3-10" tabindex="-1"></a>COMPUTE C <span class="op">=</span> <span class="op">{</span>c1 <span class="op">,</span> c2<span class="op">}</span>.</span>
<span id="cb3-11"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb3-11" tabindex="-1"></a><span class="ot">/*</span><span class="ss"> Calculating the SSCP using matrix multiplication of the transpose of C and C</span><span class="ot">.</span></span>
<span id="cb3-12"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb3-12" tabindex="-1"></a>COMPUTE tranC <span class="op">=</span> TRANSPOS<span class="op">(</span>C<span class="op">)</span>.</span>
<span id="cb3-13"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb3-13" tabindex="-1"></a>COMPUTE SS_CP <span class="op">=</span> tranC <span class="op">*</span> C.</span>
<span id="cb3-14"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb3-14" tabindex="-1"></a><span class="ot">/*</span><span class="ss"> Dividing the SSCP by n-1 to get the covariance matrix</span><span class="ot">.</span></span>
<span id="cb3-15"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb3-15" tabindex="-1"></a>COMPUTE S <span class="op">=</span> SS_CP <span class="op">/</span> <span class="fl">8.</span></span>
<span id="cb3-16"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb3-16" tabindex="-1"></a><span class="ot">/*</span><span class="ss"> Computing the determinant and the inverse of S</span><span class="ot">.</span></span>
<span id="cb3-17"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb3-17" tabindex="-1"></a>COMPUTE DETS <span class="op">=</span> DET<span class="op">(</span>S<span class="op">)</span>.</span>
<span id="cb3-18"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb3-18" tabindex="-1"></a>COMPUTE INVS <span class="op">=</span> INV<span class="op">(</span>S<span class="op">)</span>.</span>
<span id="cb3-19"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb3-19" tabindex="-1"></a><span class="ot">/*</span><span class="ss"> Print the results</span><span class="ot">.</span></span>
<span id="cb3-20"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb3-20" tabindex="-1"></a>PRINT C.</span>
<span id="cb3-21"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb3-21" tabindex="-1"></a>PRINT TranC.</span>
<span id="cb3-22"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb3-22" tabindex="-1"></a>PRINT SS_CP <span class="op">/</span>title <span class="op">=</span> <span class="st">&quot;SSCP Matrix&quot;</span>.</span>
<span id="cb3-23"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb3-23" tabindex="-1"></a>PRINT S <span class="op">/</span>title <span class="op">=</span> <span class="st">&quot;Covariance Matrix S&quot;</span>.</span>
<span id="cb3-24"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb3-24" tabindex="-1"></a>PRINT DETS <span class="op">/</span>title <span class="op">=</span> <span class="st">&quot;Determinant of S&quot;</span>.</span>
<span id="cb3-25"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb3-25" tabindex="-1"></a>PRINT INVS <span class="op">/</span>title  <span class="op">=</span> <span class="st">&quot;Inverse of S&quot;</span>.</span>
<span id="cb3-26"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb3-26" tabindex="-1"></a><span class="ot">/*</span><span class="ss"> Close the matrix mode</span><span class="ot">.</span></span>
<span id="cb3-27"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#cb3-27" tabindex="-1"></a><span class="cf">END</span> MATRIX.</span></code></pre></div>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Strictly speaking, a matrix has all of the columns in the same type of format, such as all numeric, whereas our data files often have one column in one format, such as character (or text) for persons’ names, and other columns in a different format, such as numeric.<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>Terminology in statistics is not always so neat and clean. In other contexts, we reserve upper case <em>N</em> for the number of units in a population, whereas here, it represents the total number of units in the sample regardless of which group they are in. The lowercase <em>n</em> is used to represent the number of units in a group.<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>I know, right? Why don’t we just call it <em>dimensions</em> instead of <em>order</em>.<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>Unfortunately, some authors such as Tabachnick and Fidell, annoyingly turn around and also label the sum-of-squares-and-cross-products (SSCP) matrix as <span class="math inline">\(\mathbf{S}\)</span>—which seems like a concerted effort to confuse the bananas out of us when we’re learning this material. However, this is to avoid the confusion of assuming that the symbol <span class="math inline">\(\mathbf{SSCP}\)</span> represents the result of the matrix multiplication of four matrices, <span class="math inline">\(\mathbf{S} \times \mathbf{S} \times \mathbf{C} \times \mathbf{P}\)</span>. For this reason, we try to use single letters to represent matrices and vectors.<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>This is easy to see if we think of the cross-products of a variable with itself as the square. If we use the formula for covariance between two variables (say, <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>), <span class="math inline">\(Cov(x,y) = \frac{\Sigma(x-\bar{x})(y-\bar{y})}{n-1}\)</span>, and replace <span class="math inline">\(y\)</span> with <span class="math inline">\(x\)</span>, we get the formula for the variance of x, <span class="math inline">\(Cov(x,x) = \frac{\Sigma(x-\bar{x})(x-\bar{x})}{n-1} = \frac{\Sigma(x-\bar{x})^2}{n-1} = Var(x)\)</span>.<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>This is <strong>not</strong> matrix multiplication, as we’re simply rescaling each element in the matrix by the scalar.<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>If you’re comfortable manipulating matrices, you can also try a more general approach to getting <span class="math inline">\(\mathbf{R}\)</span> from <span class="math inline">\(\mathbf{S}\)</span>: Save these standard deviations as the diagonal of a new <span class="math inline">\(p \times p\)</span> matrix with zeros on the off diagonal, call it <span class="math inline">\(\mathbf{D}\)</span> (for convenience), then use matrix algebra with its inverse, <span class="math inline">\(\mathbf{D^{-1}}\)</span> (which is introduced below), and the covariance matrix, <span class="math inline">\(\mathbf{S}\)</span> using this formula: <span class="math inline">\(\mathbf{R} = \mathbf{D^{-1}} \mathbf{S}\mathbf{D^{-1}}\)</span>.<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>Maybe <span class="math inline">\(\mathbf{C}\)</span> is not a bad label after all given that subtracting the vector’s mean from each element results in a vector of mean <strong>c</strong>entered scores.<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p>One of the steps in matrix inversion involves dividing the cells of a matrix of cofactors (which we do not need to address) by the determinant of the matrix. When we have a determinant that is zero, we will get an undefined matrix.<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p>With a <span class="math inline">\(2 \times 2\)</span> matrix, like this, the determinant is the product of the diagonal minus the product of the antidiagonal, in this case, it is <span class="math inline">\((3 \times 7.75) - (4 \times 4) = 23.25 - 16 = 7.25\)</span>. With a simple <span class="math inline">\(2 \times 2\)</span> covariance matrix, this is the sum of the product of the variances minus the sum of the product of the covariances. With a <span class="math inline">\(3 \times 3\)</span>, it’s more tedious and we should forget trying to do this by hand with a <span class="math inline">\(4 \times 4\)</span> matrix.<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#fnref10" class="footnote-back">↩︎</a></p></li>
<li id="fn11"><p>For example, if we see an error that says our matrix was <em>not positive definite</em>, it means our determinant is negative.
When this is negative or zero, and we want to compute generalized variance (of a residual matrix, e.g.), our computer software complains because variance should not be negative.<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#fnref11" class="footnote-back">↩︎</a></p></li>
<li id="fn12"><p>The exception will be confirmatory factor analysis.<a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#fnref12" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="hotellings-t2.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
