<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>25 MANCOVA | Week 09: Confirmatory Factor Analysis</title>
  <meta name="description" content="Course materials for multivariate statistics" />
  <meta name="generator" content="bookdown 0.44 and GitBook 2.6.7" />

  <meta property="og:title" content="25 MANCOVA | Week 09: Confirmatory Factor Analysis" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Course materials for multivariate statistics" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="25 MANCOVA | Week 09: Confirmatory Factor Analysis" />
  
  <meta name="twitter:description" content="Course materials for multivariate statistics" />
  

<meta name="author" content="EDUC 644" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="calculating-wilks-lambda.html"/>
<link rel="next" href="write-up.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/tabwid-1.1.3/tabwid.css" rel="stylesheet" />
<script src="libs/tabwid-1.1.3/tabwid.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 1em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Multivariate Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="scalars.html"><a href="scalars.html"><i class="fa fa-check"></i><b>1</b> Scalars</a></li>
<li class="chapter" data-level="2" data-path="vectors.html"><a href="vectors.html"><i class="fa fa-check"></i><b>2</b> Vectors</a></li>
<li class="chapter" data-level="3" data-path="matrices.html"><a href="matrices.html"><i class="fa fa-check"></i><b>3</b> Matrices</a>
<ul>
<li class="chapter" data-level="3.1" data-path="matrices.html"><a href="matrices.html#data-files-as-matrices"><i class="fa fa-check"></i><b>3.1</b> Data Files as Matrices</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="symmetrical-matrices.html"><a href="symmetrical-matrices.html"><i class="fa fa-check"></i><b>4</b> Symmetrical Matrices</a>
<ul>
<li class="chapter" data-level="4.1" data-path="symmetrical-matrices.html"><a href="symmetrical-matrices.html#variance-covariance-matrices"><i class="fa fa-check"></i><b>4.1</b> Variance-covariance Matrices</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="symmetrical-matrices.html"><a href="symmetrical-matrices.html#greek-letters"><i class="fa fa-check"></i><b>4.1.1</b> Greek letters</a></li>
<li class="chapter" data-level="4.1.2" data-path="symmetrical-matrices.html"><a href="symmetrical-matrices.html#example-variance-covariance-matrix"><i class="fa fa-check"></i><b>4.1.2</b> Example variance-covariance matrix</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="symmetrical-matrices.html"><a href="symmetrical-matrices.html#the-diagonal-and-trace"><i class="fa fa-check"></i><b>4.2</b> The diagonal and trace</a></li>
<li class="chapter" data-level="4.3" data-path="symmetrical-matrices.html"><a href="symmetrical-matrices.html#an-identity-matrix"><i class="fa fa-check"></i><b>4.3</b> An identity matrix</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="transposed-vectors-and-matrices.html"><a href="transposed-vectors-and-matrices.html"><i class="fa fa-check"></i><b>5</b> Transposed Vectors and Matrices</a></li>
<li class="chapter" data-level="6" data-path="matrix-addition-and-subtraction.html"><a href="matrix-addition-and-subtraction.html"><i class="fa fa-check"></i><b>6</b> Matrix Addition and Subtraction</a></li>
<li class="chapter" data-level="7" data-path="operations-on-matrices-with-a-scalar.html"><a href="operations-on-matrices-with-a-scalar.html"><i class="fa fa-check"></i><b>7</b> Operations on Matrices with a Scalar</a>
<ul>
<li class="chapter" data-level="7.1" data-path="operations-on-matrices-with-a-scalar.html"><a href="operations-on-matrices-with-a-scalar.html#sum-of-square-and-cross-product-sscp-matrices"><i class="fa fa-check"></i><b>7.1</b> Sum-of-square-and-cross-product (SSCP) matrices</a></li>
<li class="chapter" data-level="7.2" data-path="operations-on-matrices-with-a-scalar.html"><a href="operations-on-matrices-with-a-scalar.html#operations-on-elements-of-a-matrix-example-with-a-correlation-matrix"><i class="fa fa-check"></i><b>7.2</b> Operations on elements of a matrix: Example with a correlation matrix</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="matrix-multiplication.html"><a href="matrix-multiplication.html"><i class="fa fa-check"></i><b>8</b> Matrix Multiplication</a>
<ul>
<li class="chapter" data-level="8.1" data-path="matrix-multiplication.html"><a href="matrix-multiplication.html#another-example-of-matrix-multiplication-to-get-the-sscp"><i class="fa fa-check"></i><b>8.1</b> Another example of matrix multiplication, to get the SSCP</a></li>
<li class="chapter" data-level="8.2" data-path="matrix-multiplication.html"><a href="matrix-multiplication.html#the-ordering-is-important"><i class="fa fa-check"></i><b>8.2</b> The ordering is important</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="inverse-of-a-matrix.html"><a href="inverse-of-a-matrix.html"><i class="fa fa-check"></i><b>9</b> Inverse of a Matrix</a></li>
<li class="chapter" data-level="10" data-path="matrix-determinants-as-generalized-variance.html"><a href="matrix-determinants-as-generalized-variance.html"><i class="fa fa-check"></i><b>10</b> Matrix determinants, as generalized variance</a></li>
<li class="chapter" data-level="11" data-path="eigenvectors-and-eigenvalues.html"><a href="eigenvectors-and-eigenvalues.html"><i class="fa fa-check"></i><b>11</b> Eigenvectors and Eigenvalues</a></li>
<li class="chapter" data-level="12" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>12</b> Summary</a></li>
<li class="chapter" data-level="13" data-path="optional-spss-and-r-code-to-manipulate-matrices.html"><a href="optional-spss-and-r-code-to-manipulate-matrices.html"><i class="fa fa-check"></i><b>13</b> Optional: SPSS and R Code to Manipulate Matrices</a></li>
<li class="chapter" data-level="14" data-path="hotellings-t2.html"><a href="hotellings-t2.html"><i class="fa fa-check"></i><b>14</b> Hotelling’s <span class="math inline">\(T^2\)</span></a>
<ul>
<li class="chapter" data-level="14.1" data-path="hotellings-t2.html"><a href="hotellings-t2.html#within-group-covariance-matrices"><i class="fa fa-check"></i><b>14.1</b> Within-group covariance matrices</a></li>
<li class="chapter" data-level="14.2" data-path="hotellings-t2.html"><a href="hotellings-t2.html#sscp-matrices"><i class="fa fa-check"></i><b>14.2</b> SSCP matrices</a></li>
<li class="chapter" data-level="14.3" data-path="hotellings-t2.html"><a href="hotellings-t2.html#conducting-the-test-using-functions"><i class="fa fa-check"></i><b>14.3</b> Conducting the Test using Functions</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="data-from-week-1.html"><a href="data-from-week-1.html"><i class="fa fa-check"></i><b>15</b> Data from Week 1</a></li>
<li class="chapter" data-level="16" data-path="orthogonal-contrasts.html"><a href="orthogonal-contrasts.html"><i class="fa fa-check"></i><b>16</b> Orthogonal contrasts</a>
<ul>
<li class="chapter" data-level="16.1" data-path="orthogonal-contrasts.html"><a href="orthogonal-contrasts.html#conditions-for-orthogonal-contrasts"><i class="fa fa-check"></i><b>16.1</b> Conditions for orthogonal contrasts</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="orthogonal-contrasts.html"><a href="orthogonal-contrasts.html#an-analogy-for-these-conditions"><i class="fa fa-check"></i><b>16.1.1</b> An analogy for these conditions</a></li>
<li class="chapter" data-level="16.1.2" data-path="orthogonal-contrasts.html"><a href="orthogonal-contrasts.html#accounting-for-type-i-error-in-non-orthogonal-contrasts."><i class="fa fa-check"></i><b>16.1.2</b> Accounting for Type I error in non-orthogonal contrasts.</a></li>
<li class="chapter" data-level="16.1.3" data-path="orthogonal-contrasts.html"><a href="orthogonal-contrasts.html#bonferronithe-more-conservative-pizza-sauce"><i class="fa fa-check"></i><b>16.1.3</b> Bonferroni—the more conservative pizza sauce</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="orthogonal-contrasts.html"><a href="orthogonal-contrasts.html#post-hoc-tests"><i class="fa fa-check"></i><b>16.2</b> Post-hoc tests</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>17</b> Data</a></li>
<li class="chapter" data-level="18" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html"><i class="fa fa-check"></i><b>18</b> Descriptive statistics</a>
<ul>
<li class="chapter" data-level="18.1" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html#by-group-descriptive-statistics"><i class="fa fa-check"></i><b>18.1</b> By-group descriptive statistics</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="normality-assumption.html"><a href="normality-assumption.html"><i class="fa fa-check"></i><b>19</b> Normality Assumption</a>
<ul>
<li class="chapter" data-level="19.1" data-path="normality-assumption.html"><a href="normality-assumption.html#univariate-normality"><i class="fa fa-check"></i><b>19.1</b> Univariate Normality</a>
<ul>
<li class="chapter" data-level="19.1.1" data-path="normality-assumption.html"><a href="normality-assumption.html#identifying-univariate-outliers-within-groups"><i class="fa fa-check"></i><b>19.1.1</b> Identifying univariate outliers within groups</a></li>
<li class="chapter" data-level="19.1.2" data-path="normality-assumption.html"><a href="normality-assumption.html#kurtosis-and-skew"><i class="fa fa-check"></i><b>19.1.2</b> Kurtosis and skew</a></li>
<li class="chapter" data-level="19.1.3" data-path="normality-assumption.html"><a href="normality-assumption.html#examining-univariate-normality-using-density-plots"><i class="fa fa-check"></i><b>19.1.3</b> Examining univariate normality using density plots</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="normality-assumption.html"><a href="normality-assumption.html#examining-univariate-normality-using-quantile-quantile-plots"><i class="fa fa-check"></i><b>19.2</b> Examining univariate normality using quantile-quantile plots</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="normality-assumption.html"><a href="normality-assumption.html#univariate-q-q-plots-from-other-packages"><i class="fa fa-check"></i><b>19.2.1</b> Univariate Q-Q plots from other packages</a></li>
<li class="chapter" data-level="19.2.2" data-path="normality-assumption.html"><a href="normality-assumption.html#statistical-tests-of-univariate-normality"><i class="fa fa-check"></i><b>19.2.2</b> Statistical tests of univariate normality</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="normality-assumption.html"><a href="normality-assumption.html#a-caution-about-statistical-tests-of-statistical-assumptions"><i class="fa fa-check"></i><b>19.3</b> A caution about statistical tests of statistical assumptions</a></li>
<li class="chapter" data-level="19.4" data-path="normality-assumption.html"><a href="normality-assumption.html#mahalanobis-distance-and-multivariate-outliers"><i class="fa fa-check"></i><b>19.4</b> Mahalanobis Distance and Multivariate Outliers</a>
<ul>
<li class="chapter" data-level="19.4.1" data-path="normality-assumption.html"><a href="normality-assumption.html#outliers"><i class="fa fa-check"></i><b>19.4.1</b> Outliers</a></li>
<li class="chapter" data-level="19.4.2" data-path="normality-assumption.html"><a href="normality-assumption.html#mahalanobis-distance-using-residuals"><i class="fa fa-check"></i><b>19.4.2</b> Mahalanobis Distance using Residuals</a></li>
<li class="chapter" data-level="19.4.3" data-path="normality-assumption.html"><a href="normality-assumption.html#multivariate-residual-q-q-plot-by-group"><i class="fa fa-check"></i><b>19.4.3</b> Multivariate residual Q-Q plot by group</a></li>
</ul></li>
<li class="chapter" data-level="19.5" data-path="normality-assumption.html"><a href="normality-assumption.html#statistical-tests-of-multivariate-normality"><i class="fa fa-check"></i><b>19.5</b> Statistical Tests of Multivariate Normality</a></li>
<li class="chapter" data-level="19.6" data-path="normality-assumption.html"><a href="normality-assumption.html#homogeneity-of-covariance"><i class="fa fa-check"></i><b>19.6</b> Homogeneity of Covariance</a></li>
<li class="chapter" data-level="19.7" data-path="normality-assumption.html"><a href="normality-assumption.html#conclusions-about-our-statistical-assumptions"><i class="fa fa-check"></i><b>19.7</b> Conclusions about our statistical assumptions</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="fitting-the-manova-model.html"><a href="fitting-the-manova-model.html"><i class="fa fa-check"></i><b>20</b> Fitting the MANOVA Model</a>
<ul>
<li class="chapter" data-level="20.0.1" data-path="fitting-the-manova-model.html"><a href="fitting-the-manova-model.html#interpretation"><i class="fa fa-check"></i><b>20.0.1</b> Interpretation</a></li>
<li class="chapter" data-level="20.1" data-path="fitting-the-manova-model.html"><a href="fitting-the-manova-model.html#follow-up-analysis-with-univariate-f-tests"><i class="fa fa-check"></i><b>20.1</b> Follow-up analysis with univariate <em>F</em>-tests</a></li>
<li class="chapter" data-level="20.2" data-path="fitting-the-manova-model.html"><a href="fitting-the-manova-model.html#effect-size"><i class="fa fa-check"></i><b>20.2</b> Effect size</a></li>
<li class="chapter" data-level="20.3" data-path="fitting-the-manova-model.html"><a href="fitting-the-manova-model.html#comparing-the-model-without-outlier"><i class="fa fa-check"></i><b>20.3</b> Comparing the Model Without Outlier</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="robust-one-way-manova.html"><a href="robust-one-way-manova.html"><i class="fa fa-check"></i><b>21</b> Robust One-way MANOVA</a></li>
<li class="chapter" data-level="22" data-path="summary-1.html"><a href="summary-1.html"><i class="fa fa-check"></i><b>22</b> Summary</a></li>
<li class="chapter" data-level="23" data-path="following-tabachnick-and-fidells-notes.html"><a href="following-tabachnick-and-fidells-notes.html"><i class="fa fa-check"></i><b>23</b> Following Tabachnick and Fidell’s notes</a>
<ul>
<li class="chapter" data-level="23.1" data-path="following-tabachnick-and-fidells-notes.html"><a href="following-tabachnick-and-fidells-notes.html#another-way-to-get-the-sscp_w"><i class="fa fa-check"></i><b>23.1</b> Another way to get the <span class="math inline">\(SSCP_W\)</span>:</a></li>
<li class="chapter" data-level="23.2" data-path="following-tabachnick-and-fidells-notes.html"><a href="following-tabachnick-and-fidells-notes.html#mathbfsscp_between-for-each-factor"><i class="fa fa-check"></i><b>23.2</b> <span class="math inline">\(\mathbf{SSCP_{Between}}\)</span> for each factor</a></li>
<li class="chapter" data-level="23.3" data-path="following-tabachnick-and-fidells-notes.html"><a href="following-tabachnick-and-fidells-notes.html#mathbfsscp_between-for-the-interaction"><i class="fa fa-check"></i><b>23.3</b> <span class="math inline">\(\mathbf{SSCP_{Between}}\)</span> for the interaction</a></li>
<li class="chapter" data-level="23.4" data-path="following-tabachnick-and-fidells-notes.html"><a href="following-tabachnick-and-fidells-notes.html#these-by-hand-calculations-will-be-available-in-manova."><i class="fa fa-check"></i><b>23.4</b> These by-hand calculations will be available in <code>manova()</code>.</a></li>
<li class="chapter" data-level="23.5" data-path="following-tabachnick-and-fidells-notes.html"><a href="following-tabachnick-and-fidells-notes.html#calculating-the-generalized-variance"><i class="fa fa-check"></i><b>23.5</b> Calculating the generalized variance</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="calculating-wilks-lambda.html"><a href="calculating-wilks-lambda.html"><i class="fa fa-check"></i><b>24</b> Calculating Wilks’ Lambda</a>
<ul>
<li class="chapter" data-level="24.1" data-path="calculating-wilks-lambda.html"><a href="calculating-wilks-lambda.html#fit-the-factorial-manova"><i class="fa fa-check"></i><b>24.1</b> Fit the factorial MANOVA</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="mancova.html"><a href="mancova.html"><i class="fa fa-check"></i><b>25</b> MANCOVA</a>
<ul>
<li class="chapter" data-level="25.1" data-path="mancova.html"><a href="mancova.html#mancova-example"><i class="fa fa-check"></i><b>25.1</b> MANCOVA example</a></li>
<li class="chapter" data-level="25.2" data-path="mancova.html"><a href="mancova.html#lets-think-about-ordering-and-type-i-sums-of-squares"><i class="fa fa-check"></i><b>25.2</b> Let’s think about ordering and Type I sums of squares</a>
<ul>
<li class="chapter" data-level="25.2.1" data-path="mancova.html"><a href="mancova.html#adjusted-means"><i class="fa fa-check"></i><b>25.2.1</b> Adjusted means</a></li>
</ul></li>
<li class="chapter" data-level="25.3" data-path="mancova.html"><a href="mancova.html#fitting-the-discriminant-function-analysis-model"><i class="fa fa-check"></i><b>25.3</b> Fitting the discriminant function analysis model</a></li>
<li class="chapter" data-level="25.4" data-path="mancova.html"><a href="mancova.html#dimension-reduction-analysis"><i class="fa fa-check"></i><b>25.4</b> Dimension reduction analysis</a>
<ul>
<li class="chapter" data-level="25.4.1" data-path="mancova.html"><a href="mancova.html#effect-sizes"><i class="fa fa-check"></i><b>25.4.1</b> Effect sizes</a></li>
</ul></li>
<li class="chapter" data-level="25.5" data-path="mancova.html"><a href="mancova.html#structure-and-standardized-discriminant-function-coefficients"><i class="fa fa-check"></i><b>25.5</b> Structure and standardized discriminant function coefficients</a></li>
<li class="chapter" data-level="25.6" data-path="mancova.html"><a href="mancova.html#discriminant-function-scores"><i class="fa fa-check"></i><b>25.6</b> Discriminant function scores</a></li>
<li class="chapter" data-level="25.7" data-path="mancova.html"><a href="mancova.html#group-means-centroids-of-the-discriminant-function-scores"><i class="fa fa-check"></i><b>25.7</b> Group means (centroids) of the discriminant-function scores</a></li>
<li class="chapter" data-level="25.8" data-path="mancova.html"><a href="mancova.html#bivariate-scatterplot"><i class="fa fa-check"></i><b>25.8</b> Bivariate scatterplot</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="write-up.html"><a href="write-up.html"><i class="fa fa-check"></i><b>26</b> Write-up</a></li>
<li class="chapter" data-level="27" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html"><i class="fa fa-check"></i><b>27</b> Example 1, to see some properties of PCA</a>
<ul>
<li class="chapter" data-level="27.1" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#pca-with-covariance-vs.-correlation"><i class="fa fa-check"></i><b>27.1</b> PCA with Covariance vs. Correlation</a></li>
<li class="chapter" data-level="27.2" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#unscaled-eigenvectors"><i class="fa fa-check"></i><b>27.2</b> Unscaled eigenvectors</a></li>
<li class="chapter" data-level="27.3" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#looking-at-the-properties-of-eigenvectors-and-eigenvalues"><i class="fa fa-check"></i><b>27.3</b> Looking at the properties of eigenvectors and eigenvalues</a>
<ul>
<li class="chapter" data-level="27.3.1" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#eigenvalues-add-up-to-total-observed-variance"><i class="fa fa-check"></i><b>27.3.1</b> Eigenvalues add up to total observed variance</a></li>
<li class="chapter" data-level="27.3.2" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#each-components-proportion-of-variance"><i class="fa fa-check"></i><b>27.3.2</b> Each component’s proportion of variance</a></li>
<li class="chapter" data-level="27.3.3" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#rescaling-the-eigenvectors"><i class="fa fa-check"></i><b>27.3.3</b> Rescaling the eigenvectors</a></li>
<li class="chapter" data-level="27.3.4" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#reproducing-the-covariance-or-correlation-matrix"><i class="fa fa-check"></i><b>27.3.4</b> Reproducing the covariance (or correlation) matrix</a></li>
<li class="chapter" data-level="27.3.5" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#summary-of-the-vectors-and-matrices"><i class="fa fa-check"></i><b>27.3.5</b> Summary of the vectors and matrices</a></li>
</ul></li>
<li class="chapter" data-level="27.4" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#using-the-psych-package"><i class="fa fa-check"></i><b>27.4</b> Using the psych package</a></li>
<li class="chapter" data-level="27.5" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#determining-how-many-components-to-retain"><i class="fa fa-check"></i><b>27.5</b> Determining how many components to retain</a>
<ul>
<li class="chapter" data-level="27.5.1" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#kaisers-rule"><i class="fa fa-check"></i><b>27.5.1</b> 1. Kaiser’s rule</a></li>
<li class="chapter" data-level="27.5.2" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#scree-plot"><i class="fa fa-check"></i><b>27.5.2</b> 2. Scree plot</a></li>
<li class="chapter" data-level="27.5.3" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#parallel-analysis"><i class="fa fa-check"></i><b>27.5.3</b> 3. Parallel analysis</a></li>
</ul></li>
<li class="chapter" data-level="27.6" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#reduced-pca-model"><i class="fa fa-check"></i><b>27.6</b> Reduced PCA model</a></li>
<li class="chapter" data-level="27.7" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#interpretation-1"><i class="fa fa-check"></i><b>27.7</b> Interpretation</a>
<ul>
<li class="chapter" data-level="27.7.1" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#plot"><i class="fa fa-check"></i><b>27.7.1</b> Plot</a></li>
</ul></li>
<li class="chapter" data-level="27.8" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#interpretation-of-the-rotated-solution"><i class="fa fa-check"></i><b>27.8</b> Interpretation of the rotated solution</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="example-two.html"><a href="example-two.html"><i class="fa fa-check"></i><b>28</b> Example Two</a>
<ul>
<li class="chapter" data-level="28.1" data-path="example-two.html"><a href="example-two.html#pca-on-unstandardized-scores"><i class="fa fa-check"></i><b>28.1</b> PCA on Unstandardized Scores</a>
<ul>
<li class="chapter" data-level="28.1.1" data-path="example-two.html"><a href="example-two.html#hand-calculating-component-scores-from-this-pca"><i class="fa fa-check"></i><b>28.1.1</b> Hand calculating component scores from this PCA</a></li>
</ul></li>
<li class="chapter" data-level="28.2" data-path="example-two.html"><a href="example-two.html#pca-on-the-standardized-scores"><i class="fa fa-check"></i><b>28.2</b> PCA on the Standardized Scores</a>
<ul>
<li class="chapter" data-level="28.2.1" data-path="example-two.html"><a href="example-two.html#calculating-component-scores"><i class="fa fa-check"></i><b>28.2.1</b> Calculating component scores</a></li>
<li class="chapter" data-level="28.2.2" data-path="example-two.html"><a href="example-two.html#using-the-rescaled-eigenvectors-to-interpret-the-components"><i class="fa fa-check"></i><b>28.2.2</b> Using the rescaled eigenvectors to interpret the components</a></li>
</ul></li>
<li class="chapter" data-level="28.3" data-path="example-two.html"><a href="example-two.html#let-the-psych-package-do-the-work"><i class="fa fa-check"></i><b>28.3</b> Let the Psych Package Do the Work</a>
<ul>
<li class="chapter" data-level="28.3.1" data-path="example-two.html"><a href="example-two.html#view-the-component-scores"><i class="fa fa-check"></i><b>28.3.1</b> View the component scores</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="29" data-path="heptathlon-example.html"><a href="heptathlon-example.html"><i class="fa fa-check"></i><b>29</b> Heptathlon example</a>
<ul>
<li class="chapter" data-level="29.1" data-path="heptathlon-example.html"><a href="heptathlon-example.html#data-and-data-cleaning"><i class="fa fa-check"></i><b>29.1</b> Data and data cleaning</a></li>
<li class="chapter" data-level="29.2" data-path="heptathlon-example.html"><a href="heptathlon-example.html#examine-assumption-of-linearity"><i class="fa fa-check"></i><b>29.2</b> Examine assumption of linearity</a></li>
<li class="chapter" data-level="29.3" data-path="heptathlon-example.html"><a href="heptathlon-example.html#multivariate-normality-and-outliers"><i class="fa fa-check"></i><b>29.3</b> Multivariate normality and outliers</a></li>
<li class="chapter" data-level="29.4" data-path="heptathlon-example.html"><a href="heptathlon-example.html#re-examine-linearity-and-normality"><i class="fa fa-check"></i><b>29.4</b> Re-examine linearity and normality</a></li>
<li class="chapter" data-level="29.5" data-path="heptathlon-example.html"><a href="heptathlon-example.html#fit-the-initial-pca"><i class="fa fa-check"></i><b>29.5</b> Fit the initial PCA</a></li>
<li class="chapter" data-level="29.6" data-path="heptathlon-example.html"><a href="heptathlon-example.html#determine-the-number-of-components-to-retain"><i class="fa fa-check"></i><b>29.6</b> Determine the number of components to retain</a></li>
<li class="chapter" data-level="29.7" data-path="heptathlon-example.html"><a href="heptathlon-example.html#refit-the-pca-model-using-rotation-if-that-is-acceptable-in-your-field"><i class="fa fa-check"></i><b>29.7</b> Refit the PCA model, using rotation if that is acceptable in your field</a></li>
<li class="chapter" data-level="29.8" data-path="heptathlon-example.html"><a href="heptathlon-example.html#interpret-the-components"><i class="fa fa-check"></i><b>29.8</b> Interpret the components</a></li>
<li class="chapter" data-level="29.9" data-path="heptathlon-example.html"><a href="heptathlon-example.html#saving-the-scores"><i class="fa fa-check"></i><b>29.9</b> Saving the scores</a></li>
</ul></li>
<li class="chapter" data-level="30" data-path="other-example-from-later-in-the-chapter-not-assigned.html"><a href="other-example-from-later-in-the-chapter-not-assigned.html"><i class="fa fa-check"></i><b>30</b> Other example from later in the chapter (not assigned)</a>
<ul>
<li class="chapter" data-level="30.1" data-path="other-example-from-later-in-the-chapter-not-assigned.html"><a href="other-example-from-later-in-the-chapter-not-assigned.html#usairpollution-data"><i class="fa fa-check"></i><b>30.1</b> USairpollution Data</a></li>
</ul></li>
<li class="chapter" data-level="31" data-path="another-resource.html"><a href="another-resource.html"><i class="fa fa-check"></i><b>31</b> Another resource</a></li>
<li class="chapter" data-level="32" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>32</b> References</a></li>
<li class="chapter" data-level="33" data-path="introductory-comments.html"><a href="introductory-comments.html"><i class="fa fa-check"></i><b>33</b> Introductory comments</a>
<ul>
<li class="chapter" data-level="33.1" data-path="introductory-comments.html"><a href="introductory-comments.html#packages"><i class="fa fa-check"></i><b>33.1</b> Packages</a></li>
<li class="chapter" data-level="33.2" data-path="introductory-comments.html"><a href="introductory-comments.html#efa-ne-pca"><i class="fa fa-check"></i><b>33.2</b> EFA <span class="math inline">\(\ne\)</span> PCA</a></li>
</ul></li>
<li class="chapter" data-level="34" data-path="preparatory-steps.html"><a href="preparatory-steps.html"><i class="fa fa-check"></i><b>34</b> Preparatory steps</a>
<ul>
<li class="chapter" data-level="34.1" data-path="preparatory-steps.html"><a href="preparatory-steps.html#examining-the-data"><i class="fa fa-check"></i><b>34.1</b> Examining the data</a>
<ul>
<li class="chapter" data-level="34.1.1" data-path="preparatory-steps.html"><a href="preparatory-steps.html#descriptive-statistics-1"><i class="fa fa-check"></i><b>34.1.1</b> Descriptive statistics</a></li>
</ul></li>
<li class="chapter" data-level="34.2" data-path="preparatory-steps.html"><a href="preparatory-steps.html#addressing-assumptions"><i class="fa fa-check"></i><b>34.2</b> Addressing assumptions</a>
<ul>
<li class="chapter" data-level="34.2.1" data-path="preparatory-steps.html"><a href="preparatory-steps.html#linearity"><i class="fa fa-check"></i><b>34.2.1</b> Linearity</a></li>
<li class="chapter" data-level="34.2.2" data-path="preparatory-steps.html"><a href="preparatory-steps.html#outliers-and-multivariate-normality"><i class="fa fa-check"></i><b>34.2.2</b> Outliers and multivariate normality</a></li>
<li class="chapter" data-level="34.2.3" data-path="preparatory-steps.html"><a href="preparatory-steps.html#absence-of-perfect-multicollinearity"><i class="fa fa-check"></i><b>34.2.3</b> Absence of perfect multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="34.3" data-path="preparatory-steps.html"><a href="preparatory-steps.html#determining-factorability"><i class="fa fa-check"></i><b>34.3</b> Determining factorability</a></li>
<li class="chapter" data-level="34.4" data-path="preparatory-steps.html"><a href="preparatory-steps.html#determining-how-many-factors-to-retain"><i class="fa fa-check"></i><b>34.4</b> Determining how many factors to retain</a>
<ul>
<li class="chapter" data-level="34.4.1" data-path="preparatory-steps.html"><a href="preparatory-steps.html#parallel-analysis-1"><i class="fa fa-check"></i><b>34.4.1</b> Parallel analysis</a></li>
</ul></li>
<li class="chapter" data-level="34.5" data-path="preparatory-steps.html"><a href="preparatory-steps.html#factor-analysis-with-a-data-matrix-raw-data"><i class="fa fa-check"></i><b>34.5</b> Factor analysis with a data matrix (raw data)</a>
<ul>
<li class="chapter" data-level="34.5.1" data-path="preparatory-steps.html"><a href="preparatory-steps.html#determine-how-much-of-the-variance-is-explained-by-the-n-factors"><i class="fa fa-check"></i><b>34.5.1</b> Determine how much of the variance is explained by the <em>n</em> factors</a></li>
<li class="chapter" data-level="34.5.2" data-path="preparatory-steps.html"><a href="preparatory-steps.html#fit-the-efa-with-rotation-for-interpretation"><i class="fa fa-check"></i><b>34.5.2</b> Fit the EFA with rotation, for interpretation</a></li>
<li class="chapter" data-level="34.5.3" data-path="preparatory-steps.html"><a href="preparatory-steps.html#reduced-correlation-matrix"><i class="fa fa-check"></i><b>34.5.3</b> Reduced correlation matrix</a></li>
<li class="chapter" data-level="34.5.4" data-path="preparatory-steps.html"><a href="preparatory-steps.html#examining-pattern-coefficients-the-factor-loadings"><i class="fa fa-check"></i><b>34.5.4</b> Examining pattern coefficients (the factor loadings)</a></li>
</ul></li>
<li class="chapter" data-level="34.6" data-path="preparatory-steps.html"><a href="preparatory-steps.html#factor-analysis-with-correlation-data"><i class="fa fa-check"></i><b>34.6</b> Factor analysis with correlation data</a>
<ul>
<li class="chapter" data-level="34.6.1" data-path="preparatory-steps.html"><a href="preparatory-steps.html#setting-up-the-data"><i class="fa fa-check"></i><b>34.6.1</b> Setting up the data</a></li>
<li class="chapter" data-level="34.6.2" data-path="preparatory-steps.html"><a href="preparatory-steps.html#preparatory-steps-1"><i class="fa fa-check"></i><b>34.6.2</b> Preparatory steps</a></li>
<li class="chapter" data-level="34.6.3" data-path="preparatory-steps.html"><a href="preparatory-steps.html#performing-the-factor-analysis"><i class="fa fa-check"></i><b>34.6.3</b> Performing the factor analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="35" data-path="references-1.html"><a href="references-1.html"><i class="fa fa-check"></i><b>35</b> References</a></li>
<li class="chapter" data-level="36" data-path="factor-analysis-with-correlation-data-1.html"><a href="factor-analysis-with-correlation-data-1.html"><i class="fa fa-check"></i><b>36</b> Factor analysis with correlation data</a>
<ul>
<li class="chapter" data-level="36.1" data-path="factor-analysis-with-correlation-data-1.html"><a href="factor-analysis-with-correlation-data-1.html#setting-up-the-data-1"><i class="fa fa-check"></i><b>36.1</b> Setting up the data</a>
<ul>
<li class="chapter" data-level="36.1.1" data-path="factor-analysis-with-correlation-data-1.html"><a href="factor-analysis-with-correlation-data-1.html#some-extra-stuff-importing-half-the-correlation-matrix"><i class="fa fa-check"></i><b>36.1.1</b> Some extra stuff: Importing half the correlation matrix</a></li>
</ul></li>
<li class="chapter" data-level="36.2" data-path="factor-analysis-with-correlation-data-1.html"><a href="factor-analysis-with-correlation-data-1.html#preparatory-steps-2"><i class="fa fa-check"></i><b>36.2</b> Preparatory steps</a>
<ul>
<li class="chapter" data-level="36.2.1" data-path="factor-analysis-with-correlation-data-1.html"><a href="factor-analysis-with-correlation-data-1.html#factorability"><i class="fa fa-check"></i><b>36.2.1</b> Factorability</a></li>
<li class="chapter" data-level="36.2.2" data-path="factor-analysis-with-correlation-data-1.html"><a href="factor-analysis-with-correlation-data-1.html#number-of-factors"><i class="fa fa-check"></i><b>36.2.2</b> Number of factors</a></li>
</ul></li>
<li class="chapter" data-level="36.3" data-path="factor-analysis-with-correlation-data-1.html"><a href="factor-analysis-with-correlation-data-1.html#performing-the-factor-analysis-1"><i class="fa fa-check"></i><b>36.3</b> Performing the factor analysis</a></li>
</ul></li>
<li class="chapter" data-level="37" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html"><i class="fa fa-check"></i><b>37</b> EFA with categorical data</a>
<ul>
<li class="chapter" data-level="37.1" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html#describing-categorical-data"><i class="fa fa-check"></i><b>37.1</b> Describing categorical data</a>
<ul>
<li class="chapter" data-level="37.1.1" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html#plotting-categorical-data"><i class="fa fa-check"></i><b>37.1.1</b> Plotting categorical data</a></li>
<li class="chapter" data-level="37.1.2" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html#specifying-the-variable-type-as-ordinal"><i class="fa fa-check"></i><b>37.1.2</b> Specifying the variable type as ordinal</a></li>
<li class="chapter" data-level="37.1.3" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html#getting-the-correlation-matrix"><i class="fa fa-check"></i><b>37.1.3</b> Getting the correlation matrix</a></li>
<li class="chapter" data-level="37.1.4" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html#appraising-the-factorability-and-determining-the-number-of-factors-to-retain"><i class="fa fa-check"></i><b>37.1.4</b> Appraising the factorability and determining the number of factors to retain</a></li>
<li class="chapter" data-level="37.1.5" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html#factor-analysis-on-the-polychoric-matrix"><i class="fa fa-check"></i><b>37.1.5</b> Factor analysis on the polychoric matrix</a></li>
<li class="chapter" data-level="37.1.6" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html#the-polycor-package-if-needed"><i class="fa fa-check"></i><b>37.1.6</b> The polycor package, if needed</a></li>
</ul></li>
<li class="chapter" data-level="37.2" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html#factor-scores"><i class="fa fa-check"></i><b>37.2</b> Factor scores</a>
<ul>
<li class="chapter" data-level="37.2.1" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html#which-factor-scores-to-use"><i class="fa fa-check"></i><b>37.2.1</b> Which factor scores to use?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="38" data-path="practice.html"><a href="practice.html"><i class="fa fa-check"></i><b>38</b> Practice</a>
<ul>
<li class="chapter" data-level="38.1" data-path="practice.html"><a href="practice.html#summary-2"><i class="fa fa-check"></i><b>38.1</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="39" data-path="references-2.html"><a href="references-2.html"><i class="fa fa-check"></i><b>39</b> References</a></li>
<li class="chapter" data-level="40" data-path="preparatory-steps-3.html"><a href="preparatory-steps-3.html"><i class="fa fa-check"></i><b>40</b> Preparatory steps</a>
<ul>
<li class="chapter" data-level="40.1" data-path="preparatory-steps-3.html"><a href="preparatory-steps-3.html#describing-the-data"><i class="fa fa-check"></i><b>40.1</b> Describing the data</a>
<ul>
<li class="chapter" data-level="40.1.1" data-path="preparatory-steps-3.html"><a href="preparatory-steps-3.html#an-article-reported-r-and-the-sds-so-how-can-i-get-s"><i class="fa fa-check"></i><b>40.1.1</b> An article reported R and the SDs, so how can I get S?</a></li>
<li class="chapter" data-level="40.1.2" data-path="preparatory-steps-3.html"><a href="preparatory-steps-3.html#describing-from-a-categorical-perspective"><i class="fa fa-check"></i><b>40.1.2</b> Describing from a categorical perspective</a></li>
<li class="chapter" data-level="40.1.3" data-path="preparatory-steps-3.html"><a href="preparatory-steps-3.html#addressing-assumptions-1"><i class="fa fa-check"></i><b>40.1.3</b> Addressing assumptions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="41" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html"><i class="fa fa-check"></i><b>41</b> Fitting a CFA model</a>
<ul>
<li class="chapter" data-level="41.1" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#making-sure-the-model-was-correctly-estimated"><i class="fa fa-check"></i><b>41.1</b> Making sure the model was correctly estimated</a></li>
<li class="chapter" data-level="41.2" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#evaluating-the-model-fit"><i class="fa fa-check"></i><b>41.2</b> Evaluating the model fit</a></li>
<li class="chapter" data-level="41.3" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#interpretting-the-parameter-estimates"><i class="fa fa-check"></i><b>41.3</b> Interpretting the parameter estimates</a></li>
<li class="chapter" data-level="41.4" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#further-inspecting-our-model"><i class="fa fa-check"></i><b>41.4</b> Further inspecting our model</a>
<ul>
<li class="chapter" data-level="41.4.1" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#looking-at-the-models-covariance-matrices"><i class="fa fa-check"></i><b>41.4.1</b> Looking at the model’s covariance matrices</a></li>
</ul></li>
<li class="chapter" data-level="41.5" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#further-inspecting-our-models-parameters"><i class="fa fa-check"></i><b>41.5</b> Further inspecting our model’s parameters</a>
<ul>
<li class="chapter" data-level="41.5.1" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#seeing-which-parameters-were-estimated"><i class="fa fa-check"></i><b>41.5.1</b> Seeing which parameters were estimated</a></li>
<li class="chapter" data-level="41.5.2" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#optional-saving-parameter-estimates-to-a-data-frame"><i class="fa fa-check"></i><b>41.5.2</b> Optional: Saving parameter estimates to a data frame</a></li>
<li class="chapter" data-level="41.5.3" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#generating-path-diagrams"><i class="fa fa-check"></i><b>41.5.3</b> Generating path diagrams</a></li>
<li class="chapter" data-level="41.5.4" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#examining-modification-indices"><i class="fa fa-check"></i><b>41.5.4</b> Examining modification indices</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="42" data-path="using-alternative-model-specifications.html"><a href="using-alternative-model-specifications.html"><i class="fa fa-check"></i><b>42</b> Using alternative model specifications</a>
<ul>
<li class="chapter" data-level="42.1" data-path="using-alternative-model-specifications.html"><a href="using-alternative-model-specifications.html#rescaling-the-factors-to-be-standardized"><i class="fa fa-check"></i><b>42.1</b> Rescaling the factors to be standardized</a></li>
<li class="chapter" data-level="42.2" data-path="using-alternative-model-specifications.html"><a href="using-alternative-model-specifications.html#specifying-a-competing-nested-model"><i class="fa fa-check"></i><b>42.2</b> Specifying a competing, nested, model</a></li>
<li class="chapter" data-level="42.3" data-path="using-alternative-model-specifications.html"><a href="using-alternative-model-specifications.html#conducting-model-comparisons"><i class="fa fa-check"></i><b>42.3</b> Conducting model comparisons</a></li>
</ul></li>
<li class="chapter" data-level="43" data-path="estimating-factor-scores.html"><a href="estimating-factor-scores.html"><i class="fa fa-check"></i><b>43</b> Estimating factor scores</a></li>
<li class="chapter" data-level="44" data-path="cfa-with-categorical-data.html"><a href="cfa-with-categorical-data.html"><i class="fa fa-check"></i><b>44</b> CFA with categorical data</a>
<ul>
<li class="chapter" data-level="44.1" data-path="cfa-with-categorical-data.html"><a href="cfa-with-categorical-data.html#using-data-from-an-r-package"><i class="fa fa-check"></i><b>44.1</b> Using data from an R package</a></li>
<li class="chapter" data-level="44.2" data-path="cfa-with-categorical-data.html"><a href="cfa-with-categorical-data.html#preparing-the-data"><i class="fa fa-check"></i><b>44.2</b> Preparing the data</a></li>
<li class="chapter" data-level="44.3" data-path="cfa-with-categorical-data.html"><a href="cfa-with-categorical-data.html#describing-the-data-1"><i class="fa fa-check"></i><b>44.3</b> Describing the data</a></li>
<li class="chapter" data-level="44.4" data-path="cfa-with-categorical-data.html"><a href="cfa-with-categorical-data.html#fitting-the-cfa-model"><i class="fa fa-check"></i><b>44.4</b> Fitting the CFA model</a></li>
</ul></li>
<li class="chapter" data-level="45" data-path="way-tldr-summary.html"><a href="way-tldr-summary.html"><i class="fa fa-check"></i><b>45</b> Way TL;DR Summary</a></li>
<li class="chapter" data-level="46" data-path="references-3.html"><a href="references-3.html"><i class="fa fa-check"></i><b>46</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Week 09: Confirmatory Factor Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="mancova" class="section level1 hasAnchor" number="25">
<h1><span class="header-section-number">25</span> MANCOVA<a href="mancova.html#mancova" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Whereas in MANOVA, we compare group levels on the means on the dependent variables, in MANCOVA, we compare the group levels on the adjusted means of the dependent variables. The means are adjusted after accounting for the variability in the dependent variables that is explained by the covariate(s).</p>
<p>The omnibus null hypothesis in a one-way MANOVA with <em>p</em> dependent variables and <em>j</em> levels in the factor can be displayed like this:</p>
<p><span class="math display">\[
H_0: \text{ }
\begin{bmatrix}
\mu_{11}\\
\mu_{12}\\
\vdots \\
\mu_{1p}\\
\end{bmatrix}
=
\begin{bmatrix}
\mu_{21}\\
\mu_{22}\\
\vdots \\
\mu_{2p}\\
\end{bmatrix}
= \cdots =
\begin{bmatrix}
\mu_{j1}\\
\mu_{j2}\\
\vdots \\
\mu_{jp}\\
\end{bmatrix}
\]</span></p>
<p>Its counterpart in MANCOVA is this, where each <span class="math inline">\(\mu^*\)</span> represents the population mean after having adjusted for the covariate.</p>
<p><span class="math display">\[
H_0: \text{ }
\begin{bmatrix}
\mu^*_{11}\\
\mu^*_{12}\\
\vdots \\
\mu^*_{1p}\\
\end{bmatrix}
=
\begin{bmatrix}
\mu^*_{21}\\
\mu^*_{22}\\
\vdots \\
\mu^*_{2p}\\
\end{bmatrix}
= \cdots =
\begin{bmatrix}
\mu^*_{j1}\\
\mu^*_{j2}\\
\vdots \\
\mu^*_{jp}\\
\end{bmatrix}
\]</span></p>
<div id="mancova-example" class="section level2 hasAnchor" number="25.1">
<h2><span class="header-section-number">25.1</span> MANCOVA example<a href="mancova.html#mancova-example" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We can include <code>IQ</code> as a covariate because presumably it was measured and recorded before the treatment intervention was carried out. The following code is one way—not the best way perhaps—of including the covariate:</p>
<div class="sourceCode" id="cb235"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb235-1"><a href="mancova.html#cb235-1" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">manova</span>(<span class="fu">cbind</span>(wratR, wratA) <span class="sc">~</span> treat <span class="sc">+</span> disab <span class="sc">+</span> IQ <span class="sc">+</span> treat<span class="sc">:</span>disab, <span class="at">data =</span> dat)</span>
<span id="cb235-2"><a href="mancova.html#cb235-2" tabindex="-1"></a><span class="fu">summary.manova</span>(fit, <span class="at">test =</span> <span class="st">&quot;Pillai&quot;</span>)</span></code></pre></div>
<pre><code>##             Df  Pillai approx F num Df den Df    Pr(&gt;F)    
## treat        1 0.90138   45.701      2     10 9.328e-06 ***
## disab        2 0.83269    3.923      4     22   0.01494 *  
## IQ           1 0.44867    4.069      2     10   0.05094 .  
## treat:disab  2 0.06126    0.174      4     22   0.94950    
## Residuals   11                                             
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb237-1"><a href="mancova.html#cb237-1" tabindex="-1"></a><span class="fu">summary.manova</span>(fit, <span class="at">test =</span> <span class="st">&quot;Wilks&quot;</span>)</span></code></pre></div>
<pre><code>##             Df   Wilks approx F num Df den Df    Pr(&gt;F)    
## treat        1 0.09862   45.701      2     10 9.328e-06 ***
## disab        2 0.17401    6.986      4     20  0.001089 ** 
## IQ           1 0.55133    4.069      2     10  0.050941 .  
## treat:disab  2 0.93896    0.160      4     20  0.956106    
## Residuals   11                                             
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The results differ from what was reported in the chapter with SPSS because R <code>manova()</code> uses Type I sums of squares, where the order of entry of the independent variable is important. In contrast, SPSS uses Type III sums of squares, where every variable is adjusted for every other variable.</p>
<p>There is a package written for conducting MANCOVA (and MANOVA) which has some nice output. This <code>mancova()</code> procedure enters the covariate <em>after</em> the main effects whereas if we include our covariate in <code>manova()</code>, we have more control over its order into the model, which comes into play when we make our case about how to specify the model.</p>
<div class="sourceCode" id="cb239"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb239-1"><a href="mancova.html#cb239-1" tabindex="-1"></a><span class="fu">library</span>(jmv)</span>
<span id="cb239-2"><a href="mancova.html#cb239-2" tabindex="-1"></a>manc.fit <span class="ot">&lt;-</span> jmv<span class="sc">::</span><span class="fu">mancova</span>(<span class="at">data =</span> dat,</span>
<span id="cb239-3"><a href="mancova.html#cb239-3" tabindex="-1"></a>                    <span class="at">deps =</span> <span class="fu">vars</span>(wratR, wratA),</span>
<span id="cb239-4"><a href="mancova.html#cb239-4" tabindex="-1"></a>                    <span class="at">covs =</span> IQ,</span>
<span id="cb239-5"><a href="mancova.html#cb239-5" tabindex="-1"></a>                    <span class="at">factors =</span> <span class="fu">c</span>(treat, disab), </span>
<span id="cb239-6"><a href="mancova.html#cb239-6" tabindex="-1"></a>                    <span class="at">multivar =</span> <span class="fu">list</span>(<span class="st">&quot;wilks&quot;</span>))</span></code></pre></div>
<p>This code does not print to PDF but you can run it in R to see the results. This is from the Jamovi package, which also has a point-and-click version of R. The output looks nice.</p>
<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb240-1"><a href="mancova.html#cb240-1" tabindex="-1"></a>manc.fit<span class="sc">$</span>multivar </span></code></pre></div>
<!-- ```{r echo = F} -->
<!-- anc.fit <- jmv::ancova(data = dat, -->
<!--                     dep = wratR, -->
<!--                     covs = IQ, -->
<!--                     factors = c(treat, disab), -->
<!--                     ss = "3", -->
<!--                     effectSize = "partEta") -->
<!-- anc.fit$main  -->
<!-- ``` -->
<p>We can also see the output as a data frame. There may be a way to use the broom package to get a pretty output but for now, we can use the <code>round()</code> function on the relevent columns of the output to make it slightly more readable.</p>
<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb241-1"><a href="mancova.html#cb241-1" tabindex="-1"></a>mancova.jamovi <span class="ot">&lt;-</span>manc.fit<span class="sc">$</span>multivar<span class="sc">$</span>asDF</span>
<span id="cb241-2"><a href="mancova.html#cb241-2" tabindex="-1"></a><span class="fu">row.names</span>(mancova.jamovi) <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb241-3"><a href="mancova.html#cb241-3" tabindex="-1"></a>mancova.jamovi[, <span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">7</span>)] <span class="ot">&lt;-</span> <span class="fu">round</span>( mancova.jamovi[, <span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">7</span>)], <span class="dv">3</span>)</span>
<span id="cb241-4"><a href="mancova.html#cb241-4" tabindex="-1"></a>mancova.jamovi</span></code></pre></div>
<pre><code>##   term[wilks]   test[wilks] stat[wilks] f[wilks] df1[wilks] df2[wilks] p[wilks]
## 1       treat Wilks&#39; Lambda       0.099   45.701          2         10    0.000
## 2       disab Wilks&#39; Lambda       0.174    6.986          4         20    0.001
## 3 treat:disab Wilks&#39; Lambda       0.939    0.160          4         20    0.956
## 4          IQ Wilks&#39; Lambda       0.551    4.069          2         10    0.051</code></pre>
<p>Let’s compare those results to that of the MANOVA model <strong>without</strong> the covariate:</p>
<div class="sourceCode" id="cb243"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb243-1"><a href="mancova.html#cb243-1" tabindex="-1"></a>man.fit <span class="ot">&lt;-</span> <span class="fu">manova</span>(<span class="fu">cbind</span>(wratR, wratA) <span class="sc">~</span> treat <span class="sc">+</span> disab <span class="sc">+</span> treat<span class="sc">:</span>disab, <span class="at">data =</span> dat)</span>
<span id="cb243-2"><a href="mancova.html#cb243-2" tabindex="-1"></a>(man.sum <span class="ot">&lt;-</span> <span class="fu">summary.manova</span>(man.fit, <span class="at">test =</span> <span class="st">&quot;Wilks&quot;</span>))</span></code></pre></div>
<pre><code>##             Df   Wilks approx F num Df den Df    Pr(&gt;F)    
## treat        1 0.13772   34.436      2     11 1.839e-05 ***
## disab        2 0.25526    5.386      4     22  0.003528 ** 
## treat:disab  2 0.90807    0.272      4     22  0.893037    
## Residuals   12                                             
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb245"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb245-1"><a href="mancova.html#cb245-1" tabindex="-1"></a>manc.fit <span class="ot">&lt;-</span> <span class="fu">manova</span>(<span class="fu">cbind</span>(wratR, wratA) <span class="sc">~</span> treat <span class="sc">+</span> disab <span class="sc">+</span> IQ <span class="sc">+</span> treat<span class="sc">:</span>disab, <span class="at">data =</span> dat)</span>
<span id="cb245-2"><a href="mancova.html#cb245-2" tabindex="-1"></a>(manc.sum <span class="ot">&lt;-</span> <span class="fu">summary.manova</span>(manc.fit, <span class="at">test =</span> <span class="st">&quot;Wilks&quot;</span>))</span></code></pre></div>
<pre><code>##             Df   Wilks approx F num Df den Df    Pr(&gt;F)    
## treat        1 0.09862   45.701      2     10 9.328e-06 ***
## disab        2 0.17401    6.986      4     20  0.001089 ** 
## IQ           1 0.55133    4.069      2     10  0.050941 .  
## treat:disab  2 0.93896    0.160      4     20  0.956106    
## Residuals   11                                             
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>What do you notice about the <em>F</em>-statistic and <em>p</em>-values for the treatment variable?</p>
<p>We can also compare the error SSCP matrices. We see that the model with the covariate has lower covariance matrix elements and a lower generalized variance.</p>
<div class="sourceCode" id="cb247"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb247-1"><a href="mancova.html#cb247-1" tabindex="-1"></a><span class="fu">det</span>(man.sum<span class="sc">$</span>SS<span class="sc">$</span>Residuals)</span></code></pre></div>
<pre><code>## [1] 292436.3</code></pre>
<div class="sourceCode" id="cb249"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb249-1"><a href="mancova.html#cb249-1" tabindex="-1"></a><span class="fu">det</span>(manc.sum<span class="sc">$</span>SS<span class="sc">$</span>Residuals)</span></code></pre></div>
<pre><code>## [1] 171032.8</code></pre>
<p>Compare that to the following model, which has the covariate with a different specification. What do you notice about the ordering of the variables in the right side of the equation? And, what do you notice about the effects of (a) the covariate and (b) the treatment variable compared to the previous MANCOVA model?</p>
<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb251-1"><a href="mancova.html#cb251-1" tabindex="-1"></a>manc.fit.IQ1 <span class="ot">&lt;-</span> <span class="fu">manova</span>(<span class="fu">cbind</span>(wratR, wratA) <span class="sc">~</span> IQ <span class="sc">+</span> treat <span class="sc">+</span> disab <span class="sc">+</span> treat<span class="sc">:</span>disab, <span class="at">data =</span> dat)</span>
<span id="cb251-2"><a href="mancova.html#cb251-2" tabindex="-1"></a>(manc.sum.IQ1 <span class="ot">&lt;-</span> <span class="fu">summary.manova</span>(manc.fit.IQ1, <span class="at">test =</span> <span class="st">&quot;Wilks&quot;</span>))</span></code></pre></div>
<pre><code>##             Df   Wilks approx F num Df den Df    Pr(&gt;F)    
## IQ           1 0.23880   15.938      2     10 0.0007765 ***
## treat        1 0.10427   42.952      2     10 1.233e-05 ***
## disab        2 0.25608    4.881      4     20 0.0065404 ** 
## treat:disab  2 0.93896    0.160      4     20 0.9561057    
## Residuals   11                                             
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>This next model below is <strong>not</strong> a MANCOVA because we are including interactions with the covariate. However, we can use this model to examine whether the effect of treatment (or disability) <em><em>depends</em></em> on the level of IQ. If it does, we can<strong>not</strong> conduct a MANCOVA because this also suggests that the assumption of homogeneity of regression slopes has been violated. As an alternative, we can a multivariate regression with the interaction in the model—if that is appropriate for our research question. Fortunately, in this case, the interaction is not significant, so we can conduct a MANOVA (we probably should have done that first.)</p>
<div class="sourceCode" id="cb253"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb253-1"><a href="mancova.html#cb253-1" tabindex="-1"></a>manc.fit.IQints <span class="ot">&lt;-</span> <span class="fu">manova</span>(<span class="fu">cbind</span>(wratR, wratA) <span class="sc">~</span> IQ <span class="sc">+</span> treat <span class="sc">+</span> disab <span class="sc">+</span> IQ<span class="sc">:</span>treat <span class="sc">+</span> IQ<span class="sc">:</span>disab <span class="sc">+</span> treat<span class="sc">:</span>disab, <span class="at">data =</span> dat)</span>
<span id="cb253-2"><a href="mancova.html#cb253-2" tabindex="-1"></a>(manc.sum.IQints <span class="ot">&lt;-</span> <span class="fu">summary.manova</span>(manc.fit.IQints, <span class="at">test =</span> <span class="st">&quot;Wilks&quot;</span>))</span></code></pre></div>
<pre><code>##             Df   Wilks approx F num Df den Df    Pr(&gt;F)    
## IQ           1 0.21243   12.976      2      7 0.0044185 ** 
## treat        1 0.08324   38.547      2      7 0.0001664 ***
## disab        2 0.22024    3.958      4     14 0.0236389 *  
## IQ:treat     1 0.97273    0.098      2      7 0.9077480    
## IQ:disab     2 0.70411    0.671      4     14 0.6227926    
## treat:disab  2 0.93601    0.118      4     14 0.9740075    
## Residuals    8                                             
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>We see from the above model that the interactions of the factors with the covariate are not statistically significant; therefore, we can argue support for the assumption of homogeneity of regression slopes—or more accurately for the multivariate model, homogeneity of hyperplanes, as Pituch and Stevens call it.</p>
</div>
<div id="lets-think-about-ordering-and-type-i-sums-of-squares" class="section level2 hasAnchor" number="25.2">
<h2><span class="header-section-number">25.2</span> Let’s think about ordering and Type I sums of squares<a href="mancova.html#lets-think-about-ordering-and-type-i-sums-of-squares" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Here are some things to consider in using R vs SPSS with MANOVA and MANCOVA. SPSS uses Type III sums of squares (which is the go-to sums of squares in regression in both R and SPSS). However, R’s <code>manova()</code> function (which is what the Jamovi package uses) uses only Type I sums of squares, which means that the <strong>order of the variables</strong> in the model is important. Variables first in the model are estimated without controlling for the other variables. The second variable controls for the first variable; the third for the first two variables, and so forth.</p>
<p>The Jamovi package’s <code>macova()</code> function uses Type I errors and includes the covariate <em>after</em> the factors, no matter how many there are. In other words, if we believe that we are presenting our effects after having accounted for the covariates, we would be incorrect. However, if the covariate is completely unrelated to the other independent variables (as is the case in randomized control trials), this would be acceptable.</p>
<p>If we use Type I sums of squares, it is important to report that we used Type I sums of squares and that we report the order we included them in the model. It makes sense to include earlier in the equation the variables that are not likely affected by the other variables. For example, if the study takes into account pre-test scores before the intervention was conducted, they can be included first, as we are taking into account all of the variation in the outcome variables that are explained by those pre-intervention test scores. This can also be done for demographic variables that that are not determined by the treatment or other factors in the model.</p>
<p>Another way to approach it is to consider if our primary research question was based on an experiment (which is the purpose for which MANOVA was developed), such that cases had been randomly assigned to treatment or control conditions. If that were the case, we could place our treatment factor variable as the first variable in the equation. The rationale is that in expectation the levels of the treatment variable will be identical. Only by random luck (or lack thereof) will the levels of the treatment differ in the covariate means.</p>
<p>Let’s examine the model with the covariate as the first entry in the equation. Notice how the parameter for <code>treat</code> has changed.</p>
<div class="sourceCode" id="cb255"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb255-1"><a href="mancova.html#cb255-1" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">manova</span>(<span class="fu">cbind</span>(wratR, wratA) <span class="sc">~</span> IQ <span class="sc">+</span> treat <span class="sc">+</span> disab <span class="sc">+</span> treat<span class="sc">:</span>disab, <span class="at">data =</span> dat)</span>
<span id="cb255-2"><a href="mancova.html#cb255-2" tabindex="-1"></a><span class="fu">summary.manova</span>(fit, <span class="at">test =</span> <span class="st">&quot;Wilks&quot;</span>)</span></code></pre></div>
<pre><code>##             Df   Wilks approx F num Df den Df    Pr(&gt;F)    
## IQ           1 0.23880   15.938      2     10 0.0007765 ***
## treat        1 0.10427   42.952      2     10 1.233e-05 ***
## disab        2 0.25608    4.881      4     20 0.0065404 ** 
## treat:disab  2 0.93896    0.160      4     20 0.9561057    
## Residuals   11                                             
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div id="adjusted-means" class="section level3 hasAnchor" number="25.2.1">
<h3><span class="header-section-number">25.2.1</span> Adjusted means<a href="mancova.html#adjusted-means" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Using the <code>effect()</code> function from the effects package on the output of the <code>aov()</code> model, we can obtain the adjusted means per group; that is, the mean on a DV after partialing out the variance due to the <code>IQ</code> covariate. We can specify the sums-of-squares type with the <code>type =</code> argument, which came from the car package.</p>
<div class="sourceCode" id="cb257"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb257-1"><a href="mancova.html#cb257-1" tabindex="-1"></a><span class="fu">library</span>(effects)</span>
<span id="cb257-2"><a href="mancova.html#cb257-2" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb257-3"><a href="mancova.html#cb257-3" tabindex="-1"></a>a1 <span class="ot">&lt;-</span> <span class="fu">aov</span>(wratR <span class="sc">~</span> IQ <span class="sc">+</span> treat <span class="sc">+</span> disab <span class="sc">+</span>  treat<span class="sc">:</span>disab, <span class="at">data =</span> dat)</span>
<span id="cb257-4"><a href="mancova.html#cb257-4" tabindex="-1"></a><span class="fu">summary</span>(a1, <span class="at">type =</span> <span class="st">&quot;III&quot;</span>)</span></code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## IQ           1  215.7   215.7   4.490   0.0577 .  
## treat        1 2020.3  2020.3  42.049 4.52e-05 ***
## disab        2  391.2   195.6   4.071   0.0475 *  
## treat:disab  2    2.1     1.0   0.021   0.9789    
## Residuals   11  528.5    48.0                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb259"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb259-1"><a href="mancova.html#cb259-1" tabindex="-1"></a>adj.mean.int <span class="ot">&lt;-</span> <span class="fu">effect</span>(<span class="st">&quot;treat:disab&quot;</span>, a1, <span class="at">se =</span> <span class="cn">TRUE</span>) </span>
<span id="cb259-2"><a href="mancova.html#cb259-2" tabindex="-1"></a><span class="co"># but this interaction was NS, so we don&#39;t need this.</span></span>
<span id="cb259-3"><a href="mancova.html#cb259-3" tabindex="-1"></a>adj.mean.treat <span class="ot">&lt;-</span> <span class="fu">effect</span>(<span class="st">&quot;treat&quot;</span>, a1, <span class="at">se =</span> <span class="cn">TRUE</span>) </span>
<span id="cb259-4"><a href="mancova.html#cb259-4" tabindex="-1"></a><span class="fu">summary</span>(adj.mean.treat)</span></code></pre></div>
<pre><code>## 
##  treat effect
## treat
##        C        T 
## 78.39268 99.82954 
## 
##  Lower 95 Percent Confidence Limits
## treat
##        C        T 
## 73.30206 94.73893 
## 
##  Upper 95 Percent Confidence Limits
## treat
##        C        T 
##  83.4833 104.9202</code></pre>
<div class="sourceCode" id="cb261"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb261-1"><a href="mancova.html#cb261-1" tabindex="-1"></a>adj.mean.disab <span class="ot">&lt;-</span> <span class="fu">effect</span>(<span class="st">&quot;disab&quot;</span>, a1, <span class="at">se =</span> <span class="cn">TRUE</span>) </span>
<span id="cb261-2"><a href="mancova.html#cb261-2" tabindex="-1"></a><span class="fu">summary</span>(adj.mean.disab)</span></code></pre></div>
<pre><code>## 
##  disab effect
## disab
##     Mild Moderate   Severe 
## 95.39814 88.78388 83.15132 
## 
##  Lower 95 Percent Confidence Limits
## disab
##     Mild Moderate   Severe 
## 88.94537 82.55259 76.64580 
## 
##  Upper 95 Percent Confidence Limits
## disab
##      Mild  Moderate    Severe 
## 101.85091  95.01517  89.65684</code></pre>

<p>The following code follows the first example in Chapter 10 of Pituch and Stevens. The results are not exactly the same, with some discriminant-function scores being opposite in sign or slightly different from those in SPSS. This is because the algorithms in SPSS and R differ; however, the interpretations are the same.</p>
<p>The data are the same as those from previous chapters, in the <code>SENIORWISE.sav</code> data set.</p>
<div class="sourceCode" id="cb263"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb263-1"><a href="mancova.html#cb263-1" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb263-2"><a href="mancova.html#cb263-2" tabindex="-1"></a><span class="fu">library</span>(haven)</span>
<span id="cb263-3"><a href="mancova.html#cb263-3" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">read_sav</span>(<span class="st">&quot;SENIORWISE.sav&quot;</span>)</span>
<span id="cb263-4"><a href="mancova.html#cb263-4" tabindex="-1"></a><span class="fu">names</span>(dat) <span class="ot">&lt;-</span> <span class="fu">tolower</span>(<span class="fu">names</span>(dat))</span>
<span id="cb263-5"><a href="mancova.html#cb263-5" tabindex="-1"></a>dat<span class="sc">$</span>group <span class="ot">&lt;-</span> haven<span class="sc">::</span><span class="fu">as_factor</span>(dat<span class="sc">$</span>group)</span>
<span id="cb263-6"><a href="mancova.html#cb263-6" tabindex="-1"></a><span class="fu">glimpse</span>(dat)</span></code></pre></div>
<pre><code>## Rows: 300
## Columns: 5
## $ self_efficacy &lt;dbl&gt; 71.12113, 52.79091, 48.47966, 44.68057, 63.27477, 57.46376, 63.44811, 55.29445…
## $ verbal        &lt;dbl&gt; 68.77818, 65.92806, 47.47397, 53.70983, 62.73965, 61.65866, 61.41480, 44.31990…
## $ dafs          &lt;dbl&gt; 84.16686, 61.80243, 38.93529, 77.71841, 60.50377, 58.31163, 47.58763, 52.05460…
## $ group         &lt;fct&gt; Memory Training, Memory Training, Memory Training, Memory Training, Memory Tra…
## $ case          &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22,…</code></pre>
</div>
</div>
<div id="fitting-the-discriminant-function-analysis-model" class="section level2 hasAnchor" number="25.3">
<h2><span class="header-section-number">25.3</span> Fitting the discriminant function analysis model<a href="mancova.html#fitting-the-discriminant-function-analysis-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As is usual in R, there are many different ways to accomplish the same thing. The MASS package, and its <code>lda()</code> function seems to be one frequently used function for conducting linear discriminant function analysis in R.</p>
<p>More conveniently, the <a href="https://rdrr.io/cran/DFA.CANCOR/man/DFA.html">DFA.CANCOR</a> package provides output that is similar to that of SPSS and SAS and provides an output that is easy to use.</p>
<p>In the <code>DFA.CANCOR::DFA()</code> function, we specify the data, the group variable, the discriminant variables (which were the dependent variables in MANOVA), and we set <code>predictive = FALSE</code> because we’re doing <em>descriptive</em> discriminant analysis (rather than classification, which is discussed later in the chapter). I also set <code>verbos = FALSE</code> but you can set it to <code>TRUE</code> (the default) if you want to see the lengthy output. We can save the output to an object and request specific information, stored as lists (which we can read about in the help file), from that output. You can examine the plot they provide if you set that the <code>TRUE</code>.</p>
<div class="sourceCode" id="cb265"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb265-1"><a href="mancova.html#cb265-1" tabindex="-1"></a><span class="co"># install.packages(&quot;DFA.CANCOR&quot;)</span></span>
<span id="cb265-2"><a href="mancova.html#cb265-2" tabindex="-1"></a><span class="fu">library</span>(DFA.CANCOR)</span>
<span id="cb265-3"><a href="mancova.html#cb265-3" tabindex="-1"></a>fit.dfa <span class="ot">&lt;-</span> <span class="fu">DFA</span>(<span class="at">data =</span> dat, </span>
<span id="cb265-4"><a href="mancova.html#cb265-4" tabindex="-1"></a>            <span class="at">groups =</span> <span class="st">&quot;group&quot;</span>, </span>
<span id="cb265-5"><a href="mancova.html#cb265-5" tabindex="-1"></a>            <span class="at">variables =</span> <span class="fu">c</span>(<span class="st">&quot;self_efficacy&quot;</span>, <span class="st">&quot;verbal&quot;</span>, <span class="st">&quot;dafs&quot;</span>),</span>
<span id="cb265-6"><a href="mancova.html#cb265-6" tabindex="-1"></a>            <span class="at">predictive =</span> <span class="cn">FALSE</span>,</span>
<span id="cb265-7"><a href="mancova.html#cb265-7" tabindex="-1"></a>            <span class="at">plot =</span> <span class="cn">FALSE</span>,</span>
<span id="cb265-8"><a href="mancova.html#cb265-8" tabindex="-1"></a>            <span class="at">verbos =</span> <span class="cn">FALSE</span>) <span class="co"># verbose = TRUE is the default and outputs everything.</span></span></code></pre></div>
</div>
<div id="dimension-reduction-analysis" class="section level2 hasAnchor" number="25.4">
<h2><span class="header-section-number">25.4</span> Dimension reduction analysis<a href="mancova.html#dimension-reduction-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Here are the results reported in Table 10.4 (p. 401) of our reading.</p>
<p>Here are the eigenvalues:</p>
<div class="sourceCode" id="cb266"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb266-1"><a href="mancova.html#cb266-1" tabindex="-1"></a>fit.dfa<span class="sc">$</span>evals</span></code></pre></div>
<pre><code>##  Function eigenvalue proportion of variance canonical r
##         1 0.29047037             0.91909386   0.4744352
##         2 0.02556957             0.08090614   0.1578989</code></pre>
<p>We learned in MANOVA that Wilks’ lambda can be calculated as
<span class="math display">\[\Lambda = \frac{|\mathbf{W}|}{|\mathbf{W} + \mathbf{B}|}\]</span>
It can also be calculated from the eigenvalues as
<span class="math display">\[\Lambda = \frac{1}{1 + \phi_1} \times \frac{1}{1 + \phi_2} \times \cdots \times \frac{1}{1 + \phi_r}\]</span>
In R, we can use the following code to compute this equation:</p>
<div class="sourceCode" id="cb268"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb268-1"><a href="mancova.html#cb268-1" tabindex="-1"></a>Wilks.Lambda <span class="ot">&lt;-</span> <span class="fu">prod</span>( <span class="dv">1</span> <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> fit.dfa<span class="sc">$</span>evals[ ,<span class="dv">2</span>]) )</span>
<span id="cb268-2"><a href="mancova.html#cb268-2" tabindex="-1"></a>Wilks.Lambda</span></code></pre></div>
<pre><code>## [1] 0.7555911</code></pre>
<p>The statistical test is distributed as a <span class="math inline">\(\chi^2\)</span> with <span class="math inline">\(p(k-1)\)</span> degrees of freedom.</p>
<div class="sourceCode" id="cb270"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb270-1"><a href="mancova.html#cb270-1" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="fu">nrow</span>(dat)</span>
<span id="cb270-2"><a href="mancova.html#cb270-2" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="dv">3</span> <span class="co"># number of discriminant variables (DVs if we were doing MANOVA)</span></span>
<span id="cb270-3"><a href="mancova.html#cb270-3" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">levels</span>(dat<span class="sc">$</span>group))</span>
<span id="cb270-4"><a href="mancova.html#cb270-4" tabindex="-1"></a>df <span class="ot">&lt;-</span> p<span class="sc">*</span>(k<span class="dv">-1</span>)</span>
<span id="cb270-5"><a href="mancova.html#cb270-5" tabindex="-1"></a>eigenvalues <span class="ot">&lt;-</span> fit.dfa<span class="sc">$</span>evals[ ,<span class="dv">2</span>]</span>
<span id="cb270-6"><a href="mancova.html#cb270-6" tabindex="-1"></a>Chi.sqr <span class="ot">&lt;-</span> (N <span class="sc">-</span> <span class="dv">1</span> <span class="sc">-</span> (p <span class="sc">+</span> k) <span class="sc">/</span> <span class="dv">2</span>) <span class="sc">*</span> <span class="fu">sum</span>(<span class="fu">log</span>(<span class="dv">1</span> <span class="sc">+</span> eigenvalues))</span>
<span id="cb270-7"><a href="mancova.html#cb270-7" tabindex="-1"></a>Chi.sqr</span></code></pre></div>
<pre><code>## [1] 82.95546</code></pre>
<p>And here is the <em>p</em>-value:</p>
<div class="sourceCode" id="cb272"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb272-1"><a href="mancova.html#cb272-1" tabindex="-1"></a><span class="fu">pchisq</span>(Chi.sqr, <span class="at">df =</span> df, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## [1] 8.74953e-16</code></pre>
<p>With the second discriminant function, we use the rest of the eigenvalues in the equation. In this case, there is only one:</p>
<div class="sourceCode" id="cb274"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb274-1"><a href="mancova.html#cb274-1" tabindex="-1"></a>Wilks.Lambda2 <span class="ot">&lt;-</span> <span class="fu">prod</span>( <span class="dv">1</span> <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> eigenvalues[<span class="dv">2</span>] ) )</span>
<span id="cb274-2"><a href="mancova.html#cb274-2" tabindex="-1"></a>Wilks.Lambda2</span></code></pre></div>
<pre><code>## [1] 0.9750679</code></pre>
<p>The statistical test is now of the remaining function(s):</p>
<div class="sourceCode" id="cb276"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb276-1"><a href="mancova.html#cb276-1" tabindex="-1"></a>df2 <span class="ot">&lt;-</span> (p<span class="dv">-1</span>)<span class="sc">*</span>(k<span class="dv">-2</span>)</span>
<span id="cb276-2"><a href="mancova.html#cb276-2" tabindex="-1"></a>Chi.sqr <span class="ot">&lt;-</span> (N <span class="sc">-</span> <span class="dv">1</span> <span class="sc">-</span> (p <span class="sc">+</span> k) <span class="sc">/</span> <span class="dv">2</span>) <span class="sc">*</span> <span class="fu">sum</span>(<span class="fu">log</span>(<span class="dv">1</span> <span class="sc">+</span> fit.dfa<span class="sc">$</span>evals[<span class="dv">2</span>,<span class="dv">2</span>]))</span>
<span id="cb276-3"><a href="mancova.html#cb276-3" tabindex="-1"></a>p.value <span class="ot">&lt;-</span> <span class="fu">pchisq</span>(Chi.sqr, <span class="at">df =</span> df2, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span>
<span id="cb276-4"><a href="mancova.html#cb276-4" tabindex="-1"></a></span>
<span id="cb276-5"><a href="mancova.html#cb276-5" tabindex="-1"></a>Chi.sqr</span></code></pre></div>
<pre><code>## [1] 7.473449</code></pre>
<div class="sourceCode" id="cb278"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb278-1"><a href="mancova.html#cb278-1" tabindex="-1"></a>p.value</span></code></pre></div>
<pre><code>## [1] 0.02383204</code></pre>
<p>Alternatively, we can pull up the results from our output of the <code>DFA()</code> function.</p>
<p>Here are the statistical tests:</p>
<div class="sourceCode" id="cb280"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb280-1"><a href="mancova.html#cb280-1" tabindex="-1"></a>fit.dfa<span class="sc">$</span>mv_Wilk</span></code></pre></div>
<pre><code>##             Wilk&#39;s Lambda F-approx. df1 df2            p
## 1 through 2     0.7555911 14.791342   6 590 8.764499e-16
## 2 through 2     0.9750679  3.784297   2 296 2.383204e-02</code></pre>
<p>Because Wilk’s Lambda with the second discriminant function resulted in <code>NaN</code>, let’s look at the Pillai’s trace statistics:</p>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb282-1"><a href="mancova.html#cb282-1" tabindex="-1"></a>fit.dfa<span class="sc">$</span>mv_Pillai</span></code></pre></div>
<pre><code>##             Pillai-Bartlett Trace F-approx. df1 df2            p
## 1 through 2            0.25002083 14.096580   6 592 4.933440e-15
## 2 through 2            0.02493207  3.809866   2 596 2.269257e-02</code></pre>
<p>The Wilks’ lambda for the second discriminant function in R showed up as <code>NaN</code> (not a number), but the Pillai’s trace results were successful, so we used those and conluded that we can use all two discriminant functions.</p>
<p>Note that we have three levels to the group variable, so <span class="math inline">\(k - 1 = 2\)</span>. We have three discriminant variables (<code>self_efficacy</code>, <code>verbal</code>, and <code>dafs</code>), so <span class="math inline">\(p = 3\)</span>. The maximum number of discriminant functions we can get with these data is <span class="math inline">\(min(p, k-1)\)</span>, which is two. The model with the second discriminant function is statistically significant, so we can include both the first and second discriminant function in our analysis. <strong>If</strong> only the first model were significant, we would interpret only that first discriminant function; in other words, we could reduce the number of dimensions to one.</p>
<div id="effect-sizes" class="section level3 hasAnchor" number="25.4.1">
<h3><span class="header-section-number">25.4.1</span> Effect sizes<a href="mancova.html#effect-sizes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can look at the effect size in two different ways: 1) as the proportion of between-group variance that is accounted for by each discriminant function, and 2) the proportion of variance in the discriminant variable that is between groups. Here’s the first one, which uses the sums-of-squares.<a href="#fn26" class="footnote-ref" id="fnref26"><sup>26</sup></a></p>
<div class="sourceCode" id="cb284"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb284-1"><a href="mancova.html#cb284-1" tabindex="-1"></a>(N <span class="sc">-</span> k)<span class="sc">*</span>eigenvalues <span class="sc">/</span> <span class="fu">sum</span>((N <span class="sc">-</span> k)<span class="sc">*</span>eigenvalues )</span></code></pre></div>
<pre><code>##                       
## 0.91909386 0.08090614</code></pre>
<p>Which are the same values in the <code>proportion of variance</code> column in the output:</p>
<div class="sourceCode" id="cb286"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb286-1"><a href="mancova.html#cb286-1" tabindex="-1"></a>fit.dfa<span class="sc">$</span>evals</span></code></pre></div>
<pre><code>##  Function eigenvalue proportion of variance canonical r
##         1 0.29047037             0.91909386   0.4744352
##         2 0.02556957             0.08090614   0.1578989</code></pre>
<p>The first discriminant function explains 92% of the between-group variance, which is a strong effect. The second one was 8.10% of the variance, which is much lower.</p>
<p>The other effect size is the proportion of variance in the discriminating variable that is explained by the group, which is analogous to eta-squared.</p>
<div class="sourceCode" id="cb288"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb288-1"><a href="mancova.html#cb288-1" tabindex="-1"></a>canon.cor <span class="ot">&lt;-</span> fit.dfa<span class="sc">$</span>evals[, <span class="dv">4</span>]</span>
<span id="cb288-2"><a href="mancova.html#cb288-2" tabindex="-1"></a>canon.cor</span></code></pre></div>
<pre><code>##                     
## 0.4744352 0.1578989</code></pre>
<div class="sourceCode" id="cb290"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb290-1"><a href="mancova.html#cb290-1" tabindex="-1"></a>canon.cor<span class="sc">^</span><span class="dv">2</span></span></code></pre></div>
<pre><code>##                       
## 0.22508876 0.02493207</code></pre>
<p>So, about 23% of the variance in the first discriminant function is explained by the group variable; about 2.50% of that of the second discriminant function is explained by the group variable.</p>
</div>
</div>
<div id="structure-and-standardized-discriminant-function-coefficients" class="section level2 hasAnchor" number="25.5">
<h2><span class="header-section-number">25.5</span> Structure and standardized discriminant function coefficients<a href="mancova.html#structure-and-standardized-discriminant-function-coefficients" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Here are the results that are displayed in Table 10.5 (p. 403) of the text.</p>
<div class="sourceCode" id="cb292"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb292-1"><a href="mancova.html#cb292-1" tabindex="-1"></a>fit.dfa<span class="sc">$</span>coefs_structure</span></code></pre></div>
<pre><code>##               Function 1 Function 2
## self_efficacy -0.8199226  0.3637932
## verbal        -0.7656266 -0.6366741
## dafs          -0.6760304  0.2335248</code></pre>
<div class="sourceCode" id="cb294"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb294-1"><a href="mancova.html#cb294-1" tabindex="-1"></a>fit.dfa<span class="sc">$</span>coefs_standardized</span></code></pre></div>
<pre><code>##               Function 1 Function 2
## self_efficacy -0.5714374  0.5478547
## verbal        -0.4399244 -1.0593537
## dafs          -0.2829758  0.5262326</code></pre>
<p>This is where we interpret what the discriminant functions mean. We use the standardized discriminant-function coefficients for this purpose unless only the first one was found statistically significant. Pituch and Stevens observed that the three standardized coefficients on the first composite variable are somewhat similar. We see that self-efficacy and verbal constituted good proportions of this discriminant function—their standardized DF coefficients indicated that this relationship was, respectively, about about 0.57 and 0.44 of a standard deviation unit of the discriminant function. This result makes sense because self-efficacy in memory skills and verbal memory skills will be related if the self-efficacy belief held by the seniors was accurate. The third one, DAFS (daily functioning skills) was somewhat related to the discriminant function, at 0.28. Note that all three are the same sign, which means the three discriminant variables relate to the discriminant function in the same direction. Our interpretation of this discriminant function is a matter of judgement. Any ideas on how to label this discriminant function?</p>
<p>The second discriminant function had one relationship, with verbal memory of -1.06, that stood out stronger than the other two. It was also in the opposite direction to the other two observed variables’ relationships to this composite variable. This second function seems to represent verbal memory beyond what the first function had represented.</p>
</div>
<div id="discriminant-function-scores" class="section level2 hasAnchor" number="25.6">
<h2><span class="header-section-number">25.6</span> Discriminant function scores<a href="mancova.html#discriminant-function-scores" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Each case in our data set has a discriminant function score. This is their score on the composite (AKA discriminant function), which is calculated based on the unstandardized (raw) coefficients.</p>
<div class="sourceCode" id="cb296"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb296-1"><a href="mancova.html#cb296-1" tabindex="-1"></a>fit.dfa<span class="sc">$</span>coefs_raw</span></code></pre></div>
<pre><code>##                Function 1  Function 2
## self_efficacy -0.06128037  0.05875138
## verbal        -0.04621916 -0.11129737
## dafs          -0.02972191  0.05527201</code></pre>
<p>For example, Case 1 has a discriminant function score of
<span class="math display">\[d_{(i=1),1} = -2.67\]</span></p>
<p>which comes from the raw coefficients and an intercept. Here are the raw scores on the discriminant variables (the DVs if we do MANOVA) for Case 1 (using some excessive tidyverse coding to get around the troubles with tibbles):</p>
<div class="sourceCode" id="cb298"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb298-1"><a href="mancova.html#cb298-1" tabindex="-1"></a>(dat[<span class="dv">1</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>]) <span class="sc">%&gt;%</span> <span class="fu">data.frame</span>() <span class="sc">%&gt;%</span> <span class="fu">round</span>(., <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##   self_efficacy verbal  dafs
## 1         71.12  68.78 84.17</code></pre>
<p>Their discriminant function score is calculated as</p>
<p><span class="math display">\[d_{(i=1),1} = 7.37 +
-0.0613 (71.12) + -0.0462 (68.78) + -0.0297 (84.17) \]</span></p>
<p>Here are the results that are displayed in Table 10.9 (p. 407) of the text. We’ll use these to calculate the centroids that are reported in Table 10.6. Each person’s discriminant-function score is recorded in the output, which we can attach to the data. Here, I’m labeling discriminant function 1 and 2 <code>d1</code> and <code>d2</code>.</p>
<div class="sourceCode" id="cb300"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb300-1"><a href="mancova.html#cb300-1" tabindex="-1"></a>dat[, <span class="fu">c</span>(<span class="st">&quot;d1&quot;</span>, <span class="st">&quot;d2&quot;</span>)] <span class="ot">&lt;-</span> fit.dfa<span class="sc">$</span>dfa_scores[, <span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb300-2"><a href="mancova.html#cb300-2" tabindex="-1"></a><span class="fu">head</span>(dat, <span class="dv">10</span>)</span></code></pre></div>
<pre><code>## # A tibble: 10 × 7
##    self_efficacy verbal  dafs group            case     d1      d2
##            &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;           &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
##  1          71.1   68.8  84.2 Memory Training     1 -2.67   1.16  
##  2          52.8   65.9  61.8 Memory Training     2 -0.750 -0.834 
##  3          48.5   47.5  38.9 Memory Training     3  1.05  -0.297 
##  4          44.7   53.7  77.7 Memory Training     4 -0.161  0.929 
##  5          63.3   62.7  60.5 Memory Training     5 -1.21   0.0649
##  6          57.5   61.7  58.3 Memory Training     6 -0.735 -0.277 
##  7          63.4   61.4  47.6 Memory Training     7 -0.772 -0.491 
##  8          55.3   44.3  52.1 Memory Training     8  0.385  1.18  
##  9          52.8   67.7  61.1 Memory Training     9 -0.810 -1.07  
## 10          46.0   52.5  36.8 Memory Training    10  1.03  -1.12</code></pre>
</div>
<div id="group-means-centroids-of-the-discriminant-function-scores" class="section level2 hasAnchor" number="25.7">
<h2><span class="header-section-number">25.7</span> Group means (centroids) of the discriminant-function scores<a href="mancova.html#group-means-centroids-of-the-discriminant-function-scores" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Here are the results that are displayed in Table 10.6 (p. 404) of the text. We can use dplyr’s <code>group_by()</code> and <code>summarize()</code> functions, then save the means as a small data frame, which we’ll use in the plot reported in our reading. We can also add the standard deviations.<a href="#fn27" class="footnote-ref" id="fnref27"><sup>27</sup></a> If we want, we can also include the raw scores of the discriminant variables, though these would be earlier in the report when we reported the descriptive statistics.</p>
<div class="sourceCode" id="cb302"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb302-1"><a href="mancova.html#cb302-1" tabindex="-1"></a>grpcentroids <span class="ot">&lt;-</span> dat <span class="sc">%&gt;%</span></span>
<span id="cb302-2"><a href="mancova.html#cb302-2" tabindex="-1"></a>  <span class="fu">group_by</span>(group) <span class="sc">%&gt;%</span> </span>
<span id="cb302-3"><a href="mancova.html#cb302-3" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">M1 =</span> <span class="fu">mean</span>(d1),</span>
<span id="cb302-4"><a href="mancova.html#cb302-4" tabindex="-1"></a>            <span class="at">M2 =</span> <span class="fu">mean</span>(d2),</span>
<span id="cb302-5"><a href="mancova.html#cb302-5" tabindex="-1"></a>            <span class="at">SD1 =</span> <span class="fu">sd</span>(d1),</span>
<span id="cb302-6"><a href="mancova.html#cb302-6" tabindex="-1"></a>            <span class="at">SD2 =</span> <span class="fu">sd</span>(d2),</span>
<span id="cb302-7"><a href="mancova.html#cb302-7" tabindex="-1"></a>            <span class="at">m_sef=</span> <span class="fu">mean</span>(self_efficacy),</span>
<span id="cb302-8"><a href="mancova.html#cb302-8" tabindex="-1"></a>            <span class="at">m_ver=</span> <span class="fu">mean</span>(verbal),</span>
<span id="cb302-9"><a href="mancova.html#cb302-9" tabindex="-1"></a>            <span class="at">m_daf=</span> <span class="fu">mean</span>(dafs))</span>
<span id="cb302-10"><a href="mancova.html#cb302-10" tabindex="-1"></a>grpcentroids <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="fu">where</span>(is.numeric), round, <span class="dv">2</span>))</span></code></pre></div>
<pre><code>## # A tibble: 3 × 8
##   group              M1    M2   SD1   SD2 m_sef m_ver m_daf
##   &lt;fct&gt;           &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 Memory Training -0.76 -0.01  1.01  1.07  58.5  60.2  59.2
## 2 Health Training  0.36  0.2   0.99  0.95  50.6  50.8  52.4
## 3 Control          0.4  -0.19  1.01  0.98  49.0  52.9  51.2</code></pre>
<p>Alternatively, we can use the output from the function to get the same report of the centroid means.</p>
<div class="sourceCode" id="cb304"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb304-1"><a href="mancova.html#cb304-1" tabindex="-1"></a>fit.dfa<span class="sc">$</span>centroids</span></code></pre></div>
<pre><code>##                 Function 1  Function 2
## Memory Training -0.7579728 -0.01040184
## Health Training  0.3575702  0.19985504
## Control          0.4004027 -0.18945320</code></pre>
</div>
<div id="bivariate-scatterplot" class="section level2 hasAnchor" number="25.8">
<h2><span class="header-section-number">25.8</span> Bivariate scatterplot<a href="mancova.html#bivariate-scatterplot" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The plot like that in Figure 10.2 is not automatically generated by the <code>DFA()</code> function, probably because this is only meaningful when we have two discriminant functions, but we can use ggplot with the discriminant-function scores to do something similar. Here, we’re using the discriminant-function scores we had attached to the data, plotting them on a scatterplot, and then using the group centroids we just calculated and saved to the <code>grpcentroids</code> object to overlay the group means. Note that the sign of the discriminant functions is reversed compared to that of SPSS—in other words, those who scored positive in SPSS scored negative in R. What we’re interested in is the difference between the groups, not in their signs, so the interpretation is the same.</p>
<div class="sourceCode" id="cb306"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb306-1"><a href="mancova.html#cb306-1" tabindex="-1"></a>dat <span class="sc">%&gt;%</span> </span>
<span id="cb306-2"><a href="mancova.html#cb306-2" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> d1, <span class="at">y =</span> d2)) <span class="sc">+</span> </span>
<span id="cb306-3"><a href="mancova.html#cb306-3" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> .<span class="dv">2</span>) <span class="sc">+</span> </span>
<span id="cb306-4"><a href="mancova.html#cb306-4" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> grpcentroids, <span class="fu">aes</span>(<span class="at">x =</span> M1, <span class="at">y =</span> M2, <span class="at">shape =</span> group), </span>
<span id="cb306-5"><a href="mancova.html#cb306-5" tabindex="-1"></a>             <span class="at">color =</span> <span class="st">&quot;dark red&quot;</span>, </span>
<span id="cb306-6"><a href="mancova.html#cb306-6" tabindex="-1"></a>             <span class="at">size =</span> <span class="dv">4</span>)</span></code></pre></div>
<p><img src="multivariate_stats_files/figure-html/unnamed-chunk-154-1.png" width="672" /></p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="26">
<li id="fn26"><p>Recall that we can calculate the sums of squares as the variance times the degrees of freedom. The eigenvalues are variances of the discriminant functions.<a href="mancova.html#fnref26" class="footnote-back">↩︎</a></p></li>
<li id="fn27"><p>Note that because these are standardized scores, the standard deviation of the entire sample across the groups is <span class="math inline">\(1.00\)</span> but within each group, it not necessarily be <span class="math inline">\(1.00\)</span>.<a href="mancova.html#fnref27" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="calculating-wilks-lambda.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="write-up.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
