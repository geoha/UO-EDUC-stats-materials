<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>8 Example Two | EDUC 644 Applied Multivariate Statistics</title>
  <meta name="description" content="Course materials for multivariate statistics" />
  <meta name="generator" content="bookdown 0.44 and GitBook 2.6.7" />

  <meta property="og:title" content="8 Example Two | EDUC 644 Applied Multivariate Statistics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Course materials for multivariate statistics" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="8 Example Two | EDUC 644 Applied Multivariate Statistics" />
  
  <meta name="twitter:description" content="Course materials for multivariate statistics" />
  

<meta name="author" content="George Harrison" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="example-1-to-see-some-properties-of-pca.html"/>
<link rel="next" href="heptathlon-example.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/tabwid-1.1.3/tabwid.css" rel="stylesheet" />
<script src="libs/tabwid-1.1.3/tabwid.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Multivariate Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><i class="fa fa-check"></i><b>1</b> Terminology and Matrix Manipulations Used in Multivariate Statistics</a>
<ul>
<li class="chapter" data-level="1.1" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#scalars"><i class="fa fa-check"></i><b>1.1</b> Scalars</a></li>
<li class="chapter" data-level="1.2" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#vectors"><i class="fa fa-check"></i><b>1.2</b> Vectors</a></li>
<li class="chapter" data-level="1.3" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#matrices"><i class="fa fa-check"></i><b>1.3</b> Matrices</a></li>
<li class="chapter" data-level="1.4" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#symmetrical-matrices"><i class="fa fa-check"></i><b>1.4</b> Symmetrical Matrices</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#variance-covariance-matrices"><i class="fa fa-check"></i><b>1.4.1</b> Variance-covariance Matrices</a></li>
<li class="chapter" data-level="1.4.2" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#greek-letters"><i class="fa fa-check"></i><b>1.4.2</b> Greek letters</a></li>
<li class="chapter" data-level="1.4.3" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#example-variance-covariance-matrix"><i class="fa fa-check"></i><b>1.4.3</b> Example variance-covariance matrix</a></li>
<li class="chapter" data-level="1.4.4" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#the-diagonal-and-trace"><i class="fa fa-check"></i><b>1.4.4</b> The diagonal and trace</a></li>
<li class="chapter" data-level="1.4.5" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#an-identity-matrix"><i class="fa fa-check"></i><b>1.4.5</b> An identity matrix</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#transposed-vectors-and-matrices"><i class="fa fa-check"></i><b>1.5</b> Transposed Vectors and Matrices</a></li>
<li class="chapter" data-level="1.6" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#matrix-addition-and-subtraction"><i class="fa fa-check"></i><b>1.6</b> Matrix Addition and Subtraction</a></li>
<li class="chapter" data-level="1.7" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#operations-on-matrices-with-a-scalar"><i class="fa fa-check"></i><b>1.7</b> Operations on Matrices with a Scalar</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#sum-of-square-and-cross-product-sscp-matrices"><i class="fa fa-check"></i><b>1.7.1</b> Sum-of-square-and-cross-product (SSCP) matrices</a></li>
<li class="chapter" data-level="1.7.2" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#operations-on-elements-of-a-matrix-example-with-a-correlation-matrix"><i class="fa fa-check"></i><b>1.7.2</b> Operations on elements of a matrix: Example with a correlation matrix</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#matrix-multiplication"><i class="fa fa-check"></i><b>1.8</b> Matrix Multiplication</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#another-example-of-matrix-multiplication-to-get-the-sscp"><i class="fa fa-check"></i><b>1.8.1</b> Another example of matrix multiplication, to get the SSCP</a></li>
<li class="chapter" data-level="1.8.2" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#the-ordering-is-important"><i class="fa fa-check"></i><b>1.8.2</b> The ordering is important</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#inverse-of-a-matrix"><i class="fa fa-check"></i><b>1.9</b> Inverse of a Matrix</a></li>
<li class="chapter" data-level="1.10" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#matrix-determinants-as-generalized-variance"><i class="fa fa-check"></i><b>1.10</b> Matrix determinants, as generalized variance</a></li>
<li class="chapter" data-level="1.11" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#eigenvectors-and-eigenvalues"><i class="fa fa-check"></i><b>1.11</b> Eigenvectors and Eigenvalues</a></li>
<li class="chapter" data-level="1.12" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#summary"><i class="fa fa-check"></i><b>1.12</b> Summary</a></li>
<li class="chapter" data-level="1.13" data-path="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html"><a href="terminology-and-matrix-manipulations-used-in-multivariate-statistics.html#optional-spss-and-r-code-to-manipulate-matrices"><i class="fa fa-check"></i><b>1.13</b> Optional: SPSS and R Code to Manipulate Matrices</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="hotellings-t2.html"><a href="hotellings-t2.html"><i class="fa fa-check"></i><b>2</b> Hotelling’s <span class="math inline">\(T^2\)</span></a>
<ul>
<li class="chapter" data-level="2.1" data-path="hotellings-t2.html"><a href="hotellings-t2.html#within-group-covariance-matrices"><i class="fa fa-check"></i><b>2.1</b> Within-group covariance matrices</a></li>
<li class="chapter" data-level="2.2" data-path="hotellings-t2.html"><a href="hotellings-t2.html#sscp-matrices"><i class="fa fa-check"></i><b>2.2</b> SSCP matrices</a></li>
<li class="chapter" data-level="2.3" data-path="hotellings-t2.html"><a href="hotellings-t2.html#conducting-the-test-using-functions"><i class="fa fa-check"></i><b>2.3</b> Conducting the Test using Functions</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="planned-comparisons-and-contrasts.html"><a href="planned-comparisons-and-contrasts.html"><i class="fa fa-check"></i><b>3</b> Planned Comparisons and Contrasts</a>
<ul>
<li class="chapter" data-level="3.1" data-path="planned-comparisons-and-contrasts.html"><a href="planned-comparisons-and-contrasts.html#data-from-week-1"><i class="fa fa-check"></i><b>3.1</b> Data from Week 1</a></li>
<li class="chapter" data-level="3.2" data-path="planned-comparisons-and-contrasts.html"><a href="planned-comparisons-and-contrasts.html#orthogonal-contrasts"><i class="fa fa-check"></i><b>3.2</b> Orthogonal contrasts</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="planned-comparisons-and-contrasts.html"><a href="planned-comparisons-and-contrasts.html#conditions-for-orthogonal-contrasts"><i class="fa fa-check"></i><b>3.2.1</b> Conditions for orthogonal contrasts</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="planned-comparisons-and-contrasts.html"><a href="planned-comparisons-and-contrasts.html#non-orthogonal-contrasts"><i class="fa fa-check"></i><b>3.3</b> Non-orthogonal contrasts</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="planned-comparisons-and-contrasts.html"><a href="planned-comparisons-and-contrasts.html#accounting-for-type-i-error-in-non-orthogonal-contrasts."><i class="fa fa-check"></i><b>3.3.1</b> Accounting for Type I error in non-orthogonal contrasts.</a></li>
<li class="chapter" data-level="3.3.2" data-path="planned-comparisons-and-contrasts.html"><a href="planned-comparisons-and-contrasts.html#post-hoc-tests"><i class="fa fa-check"></i><b>3.3.2</b> Post-hoc tests</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html"><i class="fa fa-check"></i><b>4</b> Week 03 Statistical Assumptions of MANOVA</a>
<ul>
<li class="chapter" data-level="4.1" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#data"><i class="fa fa-check"></i><b>4.1</b> Data</a></li>
<li class="chapter" data-level="4.2" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#descriptive-statistics"><i class="fa fa-check"></i><b>4.2</b> Descriptive statistics</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#by-group-descriptive-statistics"><i class="fa fa-check"></i><b>4.2.1</b> By-group descriptive statistics</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#normality-assumption"><i class="fa fa-check"></i><b>4.3</b> Normality Assumption</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#univariate-normality"><i class="fa fa-check"></i><b>4.3.1</b> Univariate Normality</a></li>
<li class="chapter" data-level="4.3.2" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#examining-univariate-normality-using-quantile-quantile-plots"><i class="fa fa-check"></i><b>4.3.2</b> Examining univariate normality using quantile-quantile plots</a></li>
<li class="chapter" data-level="4.3.3" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#a-caution-about-statistical-tests-of-statistical-assumptions"><i class="fa fa-check"></i><b>4.3.3</b> A caution about statistical tests of statistical assumptions</a></li>
<li class="chapter" data-level="4.3.4" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#mahalanobis-distance-and-multivariate-outliers"><i class="fa fa-check"></i><b>4.3.4</b> Mahalanobis Distance and Multivariate Outliers</a></li>
<li class="chapter" data-level="4.3.5" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#statistical-tests-of-multivariate-normality"><i class="fa fa-check"></i><b>4.3.5</b> Statistical Tests of Multivariate Normality</a></li>
<li class="chapter" data-level="4.3.6" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#homogeneity-of-covariance"><i class="fa fa-check"></i><b>4.3.6</b> Homogeneity of Covariance</a></li>
<li class="chapter" data-level="4.3.7" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#conclusions-about-our-statistical-assumptions"><i class="fa fa-check"></i><b>4.3.7</b> Conclusions about our statistical assumptions</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#fitting-the-manova-model"><i class="fa fa-check"></i><b>4.4</b> Fitting the MANOVA Model</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#follow-up-analysis-with-univariate-f-tests"><i class="fa fa-check"></i><b>4.4.1</b> Follow-up analysis with univariate <em>F</em>-tests</a></li>
<li class="chapter" data-level="4.4.2" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#effect-size"><i class="fa fa-check"></i><b>4.4.2</b> Effect size</a></li>
<li class="chapter" data-level="4.4.3" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#comparing-the-model-without-outlier"><i class="fa fa-check"></i><b>4.4.3</b> Comparing the Model Without Outlier</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#robust-one-way-manova"><i class="fa fa-check"></i><b>4.5</b> Robust One-way MANOVA</a></li>
<li class="chapter" data-level="4.6" data-path="week-03-statistical-assumptions-of-manova.html"><a href="week-03-statistical-assumptions-of-manova.html#summary-1"><i class="fa fa-check"></i><b>4.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html"><i class="fa fa-check"></i><b>5</b> Week 04 Factorial MANOVA</a>
<ul>
<li class="chapter" data-level="5.1" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#drawing-from-ch.-7-of-tabachnick-fidell"><i class="fa fa-check"></i><b>5.1</b> Drawing from Ch. 7 of Tabachnick &amp; Fidell</a></li>
<li class="chapter" data-level="5.2" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#following-tabachnick-and-fidells-notes"><i class="fa fa-check"></i><b>5.2</b> Following Tabachnick and Fidell’s notes</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#another-way-to-get-the-sscp_w"><i class="fa fa-check"></i><b>5.2.1</b> Another way to get the <span class="math inline">\(SSCP_W\)</span>:</a></li>
<li class="chapter" data-level="5.2.2" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#mathbfsscp_between-for-each-factor"><i class="fa fa-check"></i><b>5.2.2</b> <span class="math inline">\(\mathbf{SSCP_{Between}}\)</span> for each factor</a></li>
<li class="chapter" data-level="5.2.3" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#mathbfsscp_between-for-the-interaction"><i class="fa fa-check"></i><b>5.2.3</b> <span class="math inline">\(\mathbf{SSCP_{Between}}\)</span> for the interaction</a></li>
<li class="chapter" data-level="5.2.4" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#these-by-hand-calculations-will-be-available-in-manova."><i class="fa fa-check"></i><b>5.2.4</b> These by-hand calculations will be available in <code>manova()</code>.</a></li>
<li class="chapter" data-level="5.2.5" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#calculating-the-generalized-variance"><i class="fa fa-check"></i><b>5.2.5</b> Calculating the generalized variance</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#calculating-wilks-lambda"><i class="fa fa-check"></i><b>5.3</b> Calculating Wilks’ Lambda</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#fit-the-factorial-manova"><i class="fa fa-check"></i><b>5.3.1</b> Fit the factorial MANOVA</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#mancova"><i class="fa fa-check"></i><b>5.4</b> MANCOVA</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#mancova-example"><i class="fa fa-check"></i><b>5.4.1</b> MANCOVA example</a></li>
<li class="chapter" data-level="5.4.2" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#lets-think-about-ordering-and-type-i-sums-of-squares"><i class="fa fa-check"></i><b>5.4.2</b> Let’s think about ordering and Type I sums of squares</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#fitting-the-discriminant-function-analysis-model"><i class="fa fa-check"></i><b>5.5</b> Fitting the discriminant function analysis model</a></li>
<li class="chapter" data-level="5.6" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#dimension-reduction-analysis"><i class="fa fa-check"></i><b>5.6</b> Dimension reduction analysis</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#effect-sizes"><i class="fa fa-check"></i><b>5.6.1</b> Effect sizes</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#structure-and-standardized-discriminant-function-coefficients"><i class="fa fa-check"></i><b>5.7</b> Structure and standardized discriminant function coefficients</a></li>
<li class="chapter" data-level="5.8" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#discriminant-function-scores"><i class="fa fa-check"></i><b>5.8</b> Discriminant function scores</a></li>
<li class="chapter" data-level="5.9" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#group-means-centroids-of-the-discriminant-function-scores"><i class="fa fa-check"></i><b>5.9</b> Group means (centroids) of the discriminant-function scores</a></li>
<li class="chapter" data-level="5.10" data-path="week-04-factorial-manova.html"><a href="week-04-factorial-manova.html#bivariate-scatterplot"><i class="fa fa-check"></i><b>5.10</b> Bivariate scatterplot</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="write-up.html"><a href="write-up.html"><i class="fa fa-check"></i><b>6</b> Write-up</a></li>
<li class="chapter" data-level="7" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html"><i class="fa fa-check"></i><b>7</b> Example 1, to see some properties of PCA</a>
<ul>
<li class="chapter" data-level="7.1" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#pca-with-covariance-vs.-correlation"><i class="fa fa-check"></i><b>7.1</b> PCA with Covariance vs. Correlation</a></li>
<li class="chapter" data-level="7.2" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#unscaled-eigenvectors"><i class="fa fa-check"></i><b>7.2</b> Unscaled eigenvectors</a></li>
<li class="chapter" data-level="7.3" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#looking-at-the-properties-of-eigenvectors-and-eigenvalues"><i class="fa fa-check"></i><b>7.3</b> Looking at the properties of eigenvectors and eigenvalues</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#eigenvalues-add-up-to-total-observed-variance"><i class="fa fa-check"></i><b>7.3.1</b> Eigenvalues add up to total observed variance</a></li>
<li class="chapter" data-level="7.3.2" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#each-components-proportion-of-variance"><i class="fa fa-check"></i><b>7.3.2</b> Each component’s proportion of variance</a></li>
<li class="chapter" data-level="7.3.3" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#rescaling-the-eigenvectors"><i class="fa fa-check"></i><b>7.3.3</b> Rescaling the eigenvectors</a></li>
<li class="chapter" data-level="7.3.4" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#reproducing-the-covariance-or-correlation-matrix"><i class="fa fa-check"></i><b>7.3.4</b> Reproducing the covariance (or correlation) matrix</a></li>
<li class="chapter" data-level="7.3.5" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#summary-of-the-vectors-and-matrices"><i class="fa fa-check"></i><b>7.3.5</b> Summary of the vectors and matrices</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#using-the-psych-package"><i class="fa fa-check"></i><b>7.4</b> Using the psych package</a></li>
<li class="chapter" data-level="7.5" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#determining-how-many-components-to-retain"><i class="fa fa-check"></i><b>7.5</b> Determining how many components to retain</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#kaisers-rule"><i class="fa fa-check"></i><b>7.5.1</b> 1. Kaiser’s rule</a></li>
<li class="chapter" data-level="7.5.2" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#scree-plot"><i class="fa fa-check"></i><b>7.5.2</b> 2. Scree plot</a></li>
<li class="chapter" data-level="7.5.3" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#parallel-analysis"><i class="fa fa-check"></i><b>7.5.3</b> 3. Parallel analysis</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#reduced-pca-model"><i class="fa fa-check"></i><b>7.6</b> Reduced PCA model</a></li>
<li class="chapter" data-level="7.7" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#interpretation-1"><i class="fa fa-check"></i><b>7.7</b> Interpretation</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#plot"><i class="fa fa-check"></i><b>7.7.1</b> Plot</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="example-1-to-see-some-properties-of-pca.html"><a href="example-1-to-see-some-properties-of-pca.html#interpretation-of-the-rotated-solution"><i class="fa fa-check"></i><b>7.8</b> Interpretation of the rotated solution</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="example-two.html"><a href="example-two.html"><i class="fa fa-check"></i><b>8</b> Example Two</a>
<ul>
<li class="chapter" data-level="8.1" data-path="example-two.html"><a href="example-two.html#pca-on-unstandardized-scores"><i class="fa fa-check"></i><b>8.1</b> PCA on Unstandardized Scores</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="example-two.html"><a href="example-two.html#hand-calculating-component-scores-from-this-pca"><i class="fa fa-check"></i><b>8.1.1</b> Hand calculating component scores from this PCA</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="example-two.html"><a href="example-two.html#pca-on-the-standardized-scores"><i class="fa fa-check"></i><b>8.2</b> PCA on the Standardized Scores</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="example-two.html"><a href="example-two.html#calculating-component-scores"><i class="fa fa-check"></i><b>8.2.1</b> Calculating component scores</a></li>
<li class="chapter" data-level="8.2.2" data-path="example-two.html"><a href="example-two.html#using-the-rescaled-eigenvectors-to-interpret-the-components"><i class="fa fa-check"></i><b>8.2.2</b> Using the rescaled eigenvectors to interpret the components</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="example-two.html"><a href="example-two.html#let-the-psych-package-do-the-work"><i class="fa fa-check"></i><b>8.3</b> Let the Psych Package Do the Work</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="example-two.html"><a href="example-two.html#view-the-component-scores"><i class="fa fa-check"></i><b>8.3.1</b> View the component scores</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="heptathlon-example.html"><a href="heptathlon-example.html"><i class="fa fa-check"></i><b>9</b> Heptathlon example</a>
<ul>
<li class="chapter" data-level="9.1" data-path="heptathlon-example.html"><a href="heptathlon-example.html#data-and-data-cleaning"><i class="fa fa-check"></i><b>9.1</b> Data and data cleaning</a></li>
<li class="chapter" data-level="9.2" data-path="heptathlon-example.html"><a href="heptathlon-example.html#examine-assumption-of-linearity"><i class="fa fa-check"></i><b>9.2</b> Examine assumption of linearity</a></li>
<li class="chapter" data-level="9.3" data-path="heptathlon-example.html"><a href="heptathlon-example.html#multivariate-normality-and-outliers"><i class="fa fa-check"></i><b>9.3</b> Multivariate normality and outliers</a></li>
<li class="chapter" data-level="9.4" data-path="heptathlon-example.html"><a href="heptathlon-example.html#re-examine-linearity-and-normality"><i class="fa fa-check"></i><b>9.4</b> Re-examine linearity and normality</a></li>
<li class="chapter" data-level="9.5" data-path="heptathlon-example.html"><a href="heptathlon-example.html#fit-the-initial-pca"><i class="fa fa-check"></i><b>9.5</b> Fit the initial PCA</a></li>
<li class="chapter" data-level="9.6" data-path="heptathlon-example.html"><a href="heptathlon-example.html#determine-the-number-of-components-to-retain"><i class="fa fa-check"></i><b>9.6</b> Determine the number of components to retain</a></li>
<li class="chapter" data-level="9.7" data-path="heptathlon-example.html"><a href="heptathlon-example.html#refit-the-pca-model-using-rotation-if-that-is-acceptable-in-your-field"><i class="fa fa-check"></i><b>9.7</b> Refit the PCA model, using rotation if that is acceptable in your field</a></li>
<li class="chapter" data-level="9.8" data-path="heptathlon-example.html"><a href="heptathlon-example.html#interpret-the-components"><i class="fa fa-check"></i><b>9.8</b> Interpret the components</a></li>
<li class="chapter" data-level="9.9" data-path="heptathlon-example.html"><a href="heptathlon-example.html#saving-the-scores"><i class="fa fa-check"></i><b>9.9</b> Saving the scores</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="other-example-from-later-in-the-chapter-not-assigned.html"><a href="other-example-from-later-in-the-chapter-not-assigned.html"><i class="fa fa-check"></i><b>10</b> Other example from later in the chapter (not assigned)</a>
<ul>
<li class="chapter" data-level="10.1" data-path="other-example-from-later-in-the-chapter-not-assigned.html"><a href="other-example-from-later-in-the-chapter-not-assigned.html#usairpollution-data"><i class="fa fa-check"></i><b>10.1</b> USairpollution Data</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="another-resource.html"><a href="another-resource.html"><i class="fa fa-check"></i><b>11</b> Another resource</a></li>
<li class="chapter" data-level="12" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>12</b> References</a></li>
<li class="chapter" data-level="13" data-path="introductory-comments.html"><a href="introductory-comments.html"><i class="fa fa-check"></i><b>13</b> Introductory comments</a>
<ul>
<li class="chapter" data-level="13.1" data-path="introductory-comments.html"><a href="introductory-comments.html#packages"><i class="fa fa-check"></i><b>13.1</b> Packages</a></li>
<li class="chapter" data-level="13.2" data-path="introductory-comments.html"><a href="introductory-comments.html#efa-ne-pca"><i class="fa fa-check"></i><b>13.2</b> EFA <span class="math inline">\(\ne\)</span> PCA</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="preparatory-steps.html"><a href="preparatory-steps.html"><i class="fa fa-check"></i><b>14</b> Preparatory steps</a>
<ul>
<li class="chapter" data-level="14.1" data-path="preparatory-steps.html"><a href="preparatory-steps.html#examining-the-data"><i class="fa fa-check"></i><b>14.1</b> Examining the data</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="preparatory-steps.html"><a href="preparatory-steps.html#descriptive-statistics-1"><i class="fa fa-check"></i><b>14.1.1</b> Descriptive statistics</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="preparatory-steps.html"><a href="preparatory-steps.html#addressing-assumptions"><i class="fa fa-check"></i><b>14.2</b> Addressing assumptions</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="preparatory-steps.html"><a href="preparatory-steps.html#linearity"><i class="fa fa-check"></i><b>14.2.1</b> Linearity</a></li>
<li class="chapter" data-level="14.2.2" data-path="preparatory-steps.html"><a href="preparatory-steps.html#outliers-and-multivariate-normality"><i class="fa fa-check"></i><b>14.2.2</b> Outliers and multivariate normality</a></li>
<li class="chapter" data-level="14.2.3" data-path="preparatory-steps.html"><a href="preparatory-steps.html#absence-of-perfect-multicollinearity"><i class="fa fa-check"></i><b>14.2.3</b> Absence of perfect multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="preparatory-steps.html"><a href="preparatory-steps.html#determining-factorability"><i class="fa fa-check"></i><b>14.3</b> Determining factorability</a></li>
<li class="chapter" data-level="14.4" data-path="preparatory-steps.html"><a href="preparatory-steps.html#determining-how-many-factors-to-retain"><i class="fa fa-check"></i><b>14.4</b> Determining how many factors to retain</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="preparatory-steps.html"><a href="preparatory-steps.html#parallel-analysis-1"><i class="fa fa-check"></i><b>14.4.1</b> Parallel analysis</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="preparatory-steps.html"><a href="preparatory-steps.html#factor-analysis-with-a-data-matrix-raw-data"><i class="fa fa-check"></i><b>14.5</b> Factor analysis with a data matrix (raw data)</a>
<ul>
<li class="chapter" data-level="14.5.1" data-path="preparatory-steps.html"><a href="preparatory-steps.html#determine-how-much-of-the-variance-is-explained-by-the-n-factors"><i class="fa fa-check"></i><b>14.5.1</b> Determine how much of the variance is explained by the <em>n</em> factors</a></li>
<li class="chapter" data-level="14.5.2" data-path="preparatory-steps.html"><a href="preparatory-steps.html#fit-the-efa-with-rotation-for-interpretation"><i class="fa fa-check"></i><b>14.5.2</b> Fit the EFA with rotation, for interpretation</a></li>
<li class="chapter" data-level="14.5.3" data-path="preparatory-steps.html"><a href="preparatory-steps.html#reduced-correlation-matrix"><i class="fa fa-check"></i><b>14.5.3</b> Reduced correlation matrix</a></li>
<li class="chapter" data-level="14.5.4" data-path="preparatory-steps.html"><a href="preparatory-steps.html#examining-pattern-coefficients-the-factor-loadings"><i class="fa fa-check"></i><b>14.5.4</b> Examining pattern coefficients (the factor loadings)</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="preparatory-steps.html"><a href="preparatory-steps.html#factor-analysis-with-correlation-data"><i class="fa fa-check"></i><b>14.6</b> Factor analysis with correlation data</a>
<ul>
<li class="chapter" data-level="14.6.1" data-path="preparatory-steps.html"><a href="preparatory-steps.html#setting-up-the-data"><i class="fa fa-check"></i><b>14.6.1</b> Setting up the data</a></li>
<li class="chapter" data-level="14.6.2" data-path="preparatory-steps.html"><a href="preparatory-steps.html#preparatory-steps-1"><i class="fa fa-check"></i><b>14.6.2</b> Preparatory steps</a></li>
<li class="chapter" data-level="14.6.3" data-path="preparatory-steps.html"><a href="preparatory-steps.html#performing-the-factor-analysis"><i class="fa fa-check"></i><b>14.6.3</b> Performing the factor analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="references-1.html"><a href="references-1.html"><i class="fa fa-check"></i><b>15</b> References</a></li>
<li class="chapter" data-level="16" data-path="factor-analysis-with-correlation-data-1.html"><a href="factor-analysis-with-correlation-data-1.html"><i class="fa fa-check"></i><b>16</b> Factor analysis with correlation data</a>
<ul>
<li class="chapter" data-level="16.1" data-path="factor-analysis-with-correlation-data-1.html"><a href="factor-analysis-with-correlation-data-1.html#setting-up-the-data-1"><i class="fa fa-check"></i><b>16.1</b> Setting up the data</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="factor-analysis-with-correlation-data-1.html"><a href="factor-analysis-with-correlation-data-1.html#some-extra-stuff-importing-half-the-correlation-matrix"><i class="fa fa-check"></i><b>16.1.1</b> Some extra stuff: Importing half the correlation matrix</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="factor-analysis-with-correlation-data-1.html"><a href="factor-analysis-with-correlation-data-1.html#preparatory-steps-2"><i class="fa fa-check"></i><b>16.2</b> Preparatory steps</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="factor-analysis-with-correlation-data-1.html"><a href="factor-analysis-with-correlation-data-1.html#factorability"><i class="fa fa-check"></i><b>16.2.1</b> Factorability</a></li>
<li class="chapter" data-level="16.2.2" data-path="factor-analysis-with-correlation-data-1.html"><a href="factor-analysis-with-correlation-data-1.html#number-of-factors"><i class="fa fa-check"></i><b>16.2.2</b> Number of factors</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="factor-analysis-with-correlation-data-1.html"><a href="factor-analysis-with-correlation-data-1.html#performing-the-factor-analysis-1"><i class="fa fa-check"></i><b>16.3</b> Performing the factor analysis</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html"><i class="fa fa-check"></i><b>17</b> EFA with categorical data</a>
<ul>
<li class="chapter" data-level="17.1" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html#describing-categorical-data"><i class="fa fa-check"></i><b>17.1</b> Describing categorical data</a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html#plotting-categorical-data"><i class="fa fa-check"></i><b>17.1.1</b> Plotting categorical data</a></li>
<li class="chapter" data-level="17.1.2" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html#specifying-the-variable-type-as-ordinal"><i class="fa fa-check"></i><b>17.1.2</b> Specifying the variable type as ordinal</a></li>
<li class="chapter" data-level="17.1.3" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html#getting-the-correlation-matrix"><i class="fa fa-check"></i><b>17.1.3</b> Getting the correlation matrix</a></li>
<li class="chapter" data-level="17.1.4" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html#appraising-the-factorability-and-determining-the-number-of-factors-to-retain"><i class="fa fa-check"></i><b>17.1.4</b> Appraising the factorability and determining the number of factors to retain</a></li>
<li class="chapter" data-level="17.1.5" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html#factor-analysis-on-the-polychoric-matrix"><i class="fa fa-check"></i><b>17.1.5</b> Factor analysis on the polychoric matrix</a></li>
<li class="chapter" data-level="17.1.6" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html#the-polycor-package-if-needed"><i class="fa fa-check"></i><b>17.1.6</b> The polycor package, if needed</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html#factor-scores"><i class="fa fa-check"></i><b>17.2</b> Factor scores</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="efa-with-categorical-data.html"><a href="efa-with-categorical-data.html#which-factor-scores-to-use"><i class="fa fa-check"></i><b>17.2.1</b> Which factor scores to use?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="practice.html"><a href="practice.html"><i class="fa fa-check"></i><b>18</b> Practice</a>
<ul>
<li class="chapter" data-level="18.1" data-path="practice.html"><a href="practice.html#summary-2"><i class="fa fa-check"></i><b>18.1</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="references-2.html"><a href="references-2.html"><i class="fa fa-check"></i><b>19</b> References</a></li>
<li class="chapter" data-level="20" data-path="preparatory-steps-3.html"><a href="preparatory-steps-3.html"><i class="fa fa-check"></i><b>20</b> Preparatory steps</a>
<ul>
<li class="chapter" data-level="20.1" data-path="preparatory-steps-3.html"><a href="preparatory-steps-3.html#describing-the-data"><i class="fa fa-check"></i><b>20.1</b> Describing the data</a>
<ul>
<li class="chapter" data-level="20.1.1" data-path="preparatory-steps-3.html"><a href="preparatory-steps-3.html#an-article-reported-r-and-the-sds-so-how-can-i-get-s"><i class="fa fa-check"></i><b>20.1.1</b> An article reported R and the SDs, so how can I get S?</a></li>
<li class="chapter" data-level="20.1.2" data-path="preparatory-steps-3.html"><a href="preparatory-steps-3.html#describing-from-a-categorical-perspective"><i class="fa fa-check"></i><b>20.1.2</b> Describing from a categorical perspective</a></li>
<li class="chapter" data-level="20.1.3" data-path="preparatory-steps-3.html"><a href="preparatory-steps-3.html#addressing-assumptions-1"><i class="fa fa-check"></i><b>20.1.3</b> Addressing assumptions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html"><i class="fa fa-check"></i><b>21</b> Fitting a CFA model</a>
<ul>
<li class="chapter" data-level="21.1" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#making-sure-the-model-was-correctly-estimated"><i class="fa fa-check"></i><b>21.1</b> Making sure the model was correctly estimated</a></li>
<li class="chapter" data-level="21.2" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#evaluating-the-model-fit"><i class="fa fa-check"></i><b>21.2</b> Evaluating the model fit</a></li>
<li class="chapter" data-level="21.3" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#interpretting-the-parameter-estimates"><i class="fa fa-check"></i><b>21.3</b> Interpretting the parameter estimates</a></li>
<li class="chapter" data-level="21.4" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#further-inspecting-our-model"><i class="fa fa-check"></i><b>21.4</b> Further inspecting our model</a>
<ul>
<li class="chapter" data-level="21.4.1" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#looking-at-the-models-covariance-matrices"><i class="fa fa-check"></i><b>21.4.1</b> Looking at the model’s covariance matrices</a></li>
</ul></li>
<li class="chapter" data-level="21.5" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#further-inspecting-our-models-parameters"><i class="fa fa-check"></i><b>21.5</b> Further inspecting our model’s parameters</a>
<ul>
<li class="chapter" data-level="21.5.1" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#seeing-which-parameters-were-estimated"><i class="fa fa-check"></i><b>21.5.1</b> Seeing which parameters were estimated</a></li>
<li class="chapter" data-level="21.5.2" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#optional-saving-parameter-estimates-to-a-data-frame"><i class="fa fa-check"></i><b>21.5.2</b> Optional: Saving parameter estimates to a data frame</a></li>
<li class="chapter" data-level="21.5.3" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#generating-path-diagrams"><i class="fa fa-check"></i><b>21.5.3</b> Generating path diagrams</a></li>
<li class="chapter" data-level="21.5.4" data-path="fitting-a-cfa-model.html"><a href="fitting-a-cfa-model.html#examining-modification-indices"><i class="fa fa-check"></i><b>21.5.4</b> Examining modification indices</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="22" data-path="using-alternative-model-specifications.html"><a href="using-alternative-model-specifications.html"><i class="fa fa-check"></i><b>22</b> Using alternative model specifications</a>
<ul>
<li class="chapter" data-level="22.1" data-path="using-alternative-model-specifications.html"><a href="using-alternative-model-specifications.html#rescaling-the-factors-to-be-standardized"><i class="fa fa-check"></i><b>22.1</b> Rescaling the factors to be standardized</a></li>
<li class="chapter" data-level="22.2" data-path="using-alternative-model-specifications.html"><a href="using-alternative-model-specifications.html#specifying-a-competing-nested-model"><i class="fa fa-check"></i><b>22.2</b> Specifying a competing, nested, model</a></li>
<li class="chapter" data-level="22.3" data-path="using-alternative-model-specifications.html"><a href="using-alternative-model-specifications.html#conducting-model-comparisons"><i class="fa fa-check"></i><b>22.3</b> Conducting model comparisons</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="estimating-factor-scores.html"><a href="estimating-factor-scores.html"><i class="fa fa-check"></i><b>23</b> Estimating factor scores</a></li>
<li class="chapter" data-level="24" data-path="cfa-with-categorical-data.html"><a href="cfa-with-categorical-data.html"><i class="fa fa-check"></i><b>24</b> CFA with categorical data</a>
<ul>
<li class="chapter" data-level="24.1" data-path="cfa-with-categorical-data.html"><a href="cfa-with-categorical-data.html#using-data-from-an-r-package"><i class="fa fa-check"></i><b>24.1</b> Using data from an R package</a></li>
<li class="chapter" data-level="24.2" data-path="cfa-with-categorical-data.html"><a href="cfa-with-categorical-data.html#preparing-the-data"><i class="fa fa-check"></i><b>24.2</b> Preparing the data</a></li>
<li class="chapter" data-level="24.3" data-path="cfa-with-categorical-data.html"><a href="cfa-with-categorical-data.html#describing-the-data-1"><i class="fa fa-check"></i><b>24.3</b> Describing the data</a></li>
<li class="chapter" data-level="24.4" data-path="cfa-with-categorical-data.html"><a href="cfa-with-categorical-data.html#fitting-the-cfa-model"><i class="fa fa-check"></i><b>24.4</b> Fitting the CFA model</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="way-tldr-summary.html"><a href="way-tldr-summary.html"><i class="fa fa-check"></i><b>25</b> Way TL;DR Summary</a></li>
<li class="chapter" data-level="26" data-path="references-3.html"><a href="references-3.html"><i class="fa fa-check"></i><b>26</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">EDUC 644 Applied Multivariate Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="example-two" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">8</span> Example Two<a href="example-two.html#example-two" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Everitt and Hothorn use a data set called <code>headsize</code> which I copied and pasted and saved as a csv file. Each case in this data set is a family and the two observed variables being analyzed are <code>head1</code> and <code>head2</code> for the head size of the first and second born male child in the family.</p>
<p>This provides an example of how we can perform PCA on a data set instead of the correlation matrix. It also allows for us to see how we can obtain a component score for each observation. There are several ways to calculate component scores (unfortunately).</p>
<div class="sourceCode" id="cb365"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb365-1"><a href="example-two.html#cb365-1" tabindex="-1"></a>headsize <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;headsize.csv&quot;</span>)</span>
<span id="cb365-2"><a href="example-two.html#cb365-2" tabindex="-1"></a>head_dat <span class="ot">&lt;-</span> headsize <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(head1, head2)</span></code></pre></div>
<p>Let’s try the <code>prcomp()</code> function for the PCA. This is similar to the <code>princomp()</code> function, which they used in the chapter with these data, but it’s easier to use its output.</p>
<div id="pca-on-unstandardized-scores" class="section level2 hasAnchor" number="8.1">
<h2><span class="header-section-number">8.1</span> PCA on Unstandardized Scores<a href="example-two.html#pca-on-unstandardized-scores" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Here’s the PCA Everitt and Hothorn conducted, which was on the raw data and in the original scale. Normally, we do <strong>not</strong> perform PCA on the unstandardized scale of the data because, as we saw above, variables with larger scales are given more weight.<a href="#fn34" class="footnote-ref" id="fnref34"><sup>34</sup></a></p>
<div class="sourceCode" id="cb366"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb366-1"><a href="example-two.html#cb366-1" tabindex="-1"></a>head_pca <span class="ot">&lt;-</span> <span class="fu">prcomp</span>(<span class="sc">~</span> head1 <span class="sc">+</span> head2, </span>
<span id="cb366-2"><a href="example-two.html#cb366-2" tabindex="-1"></a>                 <span class="at">data  =</span> head_dat,</span>
<span id="cb366-3"><a href="example-two.html#cb366-3" tabindex="-1"></a>                 <span class="at">retx  =</span> <span class="cn">FALSE</span>, <span class="co"># Not rotating</span></span>
<span id="cb366-4"><a href="example-two.html#cb366-4" tabindex="-1"></a>                 <span class="at">scale =</span> <span class="cn">FALSE</span>) <span class="co"># Using raw data scores instead of standardized scores.</span></span>
<span id="cb366-5"><a href="example-two.html#cb366-5" tabindex="-1"></a>head_pca</span></code></pre></div>
<pre><code>## Standard deviations (1, .., p=2):
## [1] 12.952459  5.322951
## 
## Rotation (n x k) = (2 x 2):
##              PC1        PC2
## head1 -0.6929858  0.7209512
## head2 -0.7209512 -0.6929858</code></pre>
<div class="sourceCode" id="cb368"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb368-1"><a href="example-two.html#cb368-1" tabindex="-1"></a><span class="fu">summary</span>(head_pca)</span></code></pre></div>
<pre><code>## Importance of components:
##                            PC1    PC2
## Standard deviation     12.9525 5.3230
## Proportion of Variance  0.8555 0.1445
## Cumulative Proportion   0.8555 1.0000</code></pre>
<p>The eigenvalues of the PCA on the non-standardized scores are <span class="math inline">\(12.9525^2\)</span> and <span class="math inline">\(5.3230^2\)</span>, or <span class="math inline">\(167.767\)</span> and <span class="math inline">\(28.334\)</span> respectively.</p>
<div id="hand-calculating-component-scores-from-this-pca" class="section level3 hasAnchor" number="8.1.1">
<h3><span class="header-section-number">8.1.1</span> Hand calculating component scores from this PCA<a href="example-two.html#hand-calculating-component-scores-from-this-pca" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Following the explanation in Everitt and Horthorn, we can calculate each family’s score on each of the two components after centering their observed scores on the variables. For example, each family’s observed center score on <code>head1</code> is their deviation score, <span class="math inline">\(x_{i1} - \bar{x}_1\)</span>; on <code>head1</code>, it is <span class="math inline">\(x_{i2} - \bar{x}_2\)</span>.</p>
<p><span class="math display">\[ C_{i1} = 0.693(x_{i1} - \bar{x}_1) + .721(x_{i2} - \bar{x}_2) \]</span>
<span class="math display">\[ C_{i2} = .721(x_{i1} - \bar{x}_1) - .693(x_{i2} - \bar{x}_2) \]</span></p>
<p>We can do this in tidyverse:</p>
<div class="sourceCode" id="cb370"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb370-1"><a href="example-two.html#cb370-1" tabindex="-1"></a>head_dat <span class="ot">&lt;-</span> head_dat <span class="sc">%&gt;%</span></span>
<span id="cb370-2"><a href="example-two.html#cb370-2" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">C1.cent =</span> <span class="fl">0.693</span> <span class="sc">*</span>(head1 <span class="sc">-</span> <span class="fu">mean</span>(head1)) <span class="sc">+</span> .<span class="dv">721</span><span class="sc">*</span>(head2 <span class="sc">-</span> <span class="fu">mean</span>(head2)),</span>
<span id="cb370-3"><a href="example-two.html#cb370-3" tabindex="-1"></a>         <span class="at">C2.cent =</span> <span class="fl">0.721</span> <span class="sc">*</span>(head1 <span class="sc">-</span> <span class="fu">mean</span>(head1)) <span class="sc">-</span> .<span class="dv">693</span><span class="sc">*</span>(head2 <span class="sc">-</span> <span class="fu">mean</span>(head2)) )</span>
<span id="cb370-4"><a href="example-two.html#cb370-4" tabindex="-1"></a><span class="fu">head</span>(head_dat) <span class="co"># PCA can be very ... heady `groan() = TRUE`.</span></span></code></pre></div>
<pre><code>##   head1 head2  C1.cent C2.cent
## 1   191   179   0.1694   7.161
## 2   195   201  18.8034  -5.201
## 3   181   185  -2.4346  -4.207
## 4   183   188   1.1144  -4.844
## 5   176   171 -15.9936   1.890
## 6   208   192  21.3234  10.409</code></pre>
<p>A more reproducible way to do this same calculation is with the matrix of eigenvectors and the raw scores. Also, whereas above, we calculated the centered scores by hand, we can use the <code>scale()</code> function in Base R to get centered scores, with the arguments <code>center = TRUE</code> and <code>scale = FALSE</code>. (If we set <code>scale = TRUE</code>, we get standardized scores.) We also need to save the eigenvectors as a matrix using <code>A &lt;- cbind(head_pca$rotation)</code>. Then we can matrix multiply the matrix of centered scores by the matrix of eigenvectors, <span class="math inline">\(\mathbf{A}\)</span></p>
<div class="sourceCode" id="cb372"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb372-1"><a href="example-two.html#cb372-1" tabindex="-1"></a>head_centrd <span class="ot">&lt;-</span> <span class="fu">cbind</span>( <span class="fu">scale</span>(head_dat[ , <span class="fu">c</span>(<span class="st">&quot;head1&quot;</span>, <span class="st">&quot;head2&quot;</span>)], </span>
<span id="cb372-2"><a href="example-two.html#cb372-2" tabindex="-1"></a>                            <span class="at">center =</span> <span class="cn">TRUE</span>, </span>
<span id="cb372-3"><a href="example-two.html#cb372-3" tabindex="-1"></a>                            <span class="at">scale  =</span> <span class="cn">FALSE</span>) )</span>
<span id="cb372-4"><a href="example-two.html#cb372-4" tabindex="-1"></a>A <span class="ot">&lt;-</span> <span class="fu">cbind</span>(head_pca<span class="sc">$</span>rotation)</span>
<span id="cb372-5"><a href="example-two.html#cb372-5" tabindex="-1"></a>head_dat[, <span class="fu">c</span>(<span class="st">&quot;C1.cent&quot;</span>, <span class="st">&quot;C2.cent&quot;</span>)] <span class="ot">&lt;-</span> head_centrd <span class="sc">%*%</span> A </span>
<span id="cb372-6"><a href="example-two.html#cb372-6" tabindex="-1"></a><span class="fu">head</span>(head_dat)</span></code></pre></div>
<pre><code>##   head1 head2     C1.cent   C2.cent
## 1   191   179  -0.1695614  7.160674
## 2   195   201 -18.8024312 -5.201210
## 3   181   185   2.4345897 -4.206753
## 4   183   188  -1.1142355 -4.843808
## 5   176   171  15.9928357  1.890292
## 6   208   192 -21.3226862 10.408028</code></pre>
<p>We learned that the eigenvalues are the variances of the composite variables. Let’s look into this.</p>
<div class="sourceCode" id="cb374"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb374-1"><a href="example-two.html#cb374-1" tabindex="-1"></a>head_dat <span class="sc">%&gt;%</span></span>
<span id="cb374-2"><a href="example-two.html#cb374-2" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">varC1 =</span> <span class="fu">var</span>(C1.cent),</span>
<span id="cb374-3"><a href="example-two.html#cb374-3" tabindex="-1"></a>            <span class="at">varC2 =</span> <span class="fu">var</span>(C2.cent))</span></code></pre></div>
<pre><code>##      varC1    varC2
## 1 167.7662 28.33381</code></pre>
<p>These are the same as the square of the standard deviations reported in the output, <span class="math inline">\(12.9525^2\)</span> and <span class="math inline">\(5.3230^2\)</span>, resulting in the two eigenvalues, <span class="math inline">\(167.767\)</span> and <span class="math inline">\(28.334\)</span>.</p>
</div>
</div>
<div id="pca-on-the-standardized-scores" class="section level2 hasAnchor" number="8.2">
<h2><span class="header-section-number">8.2</span> PCA on the Standardized Scores<a href="example-two.html#pca-on-the-standardized-scores" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We almost always conduct a PCA on the standardized observed data rather than on the unstandardized data because it ensures that some variables, with excessive variance, do not take up all of the variance in the PCA solution.</p>
<p>Let’s take a look at the standardized observed scores.</p>
<div class="sourceCode" id="cb376"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb376-1"><a href="example-two.html#cb376-1" tabindex="-1"></a>stdz_scores <span class="ot">&lt;-</span> <span class="fu">scale</span>(head_dat[ ,<span class="fu">c</span>(<span class="st">&quot;head1&quot;</span>, <span class="st">&quot;head2&quot;</span>)], <span class="at">scale =</span> <span class="cn">TRUE</span>)</span>
<span id="cb376-2"><a href="example-two.html#cb376-2" tabindex="-1"></a><span class="fu">head</span>(stdz_scores)</span></code></pre></div>
<pre><code>##           head1      head2
## [1,]  0.5408822 -0.4820596
## [2,]  0.9506414  1.7091204
## [3,] -0.4835159  0.1155349
## [4,] -0.2786363  0.4143322
## [5,] -0.9957149 -1.2788523
## [6,]  2.2823588  0.8127286</code></pre>
<p>These scores, by definition, have a mean of zero and a standard deviation of one.</p>
<p>We can also recognize that (a) the correlation and covariance matrices are the same when we have standardized data, and (b) the <code>eigen()</code> function on this covariance matrix returns the same eigenvalues and eigenvectors as we will observe in our output below. This simply confirms that a PCA on the standardized observed scores will yield the same PCA results as a PCA on the correlation matrix.</p>
<div class="sourceCode" id="cb378"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb378-1"><a href="example-two.html#cb378-1" tabindex="-1"></a><span class="fu">cor</span>(stdz_scores) </span></code></pre></div>
<pre><code>##           head1     head2
## head1 1.0000000 0.7107518
## head2 0.7107518 1.0000000</code></pre>
<div class="sourceCode" id="cb380"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb380-1"><a href="example-two.html#cb380-1" tabindex="-1"></a><span class="fu">cov</span>(stdz_scores)</span></code></pre></div>
<pre><code>##           head1     head2
## head1 1.0000000 0.7107518
## head2 0.7107518 1.0000000</code></pre>
<div class="sourceCode" id="cb382"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb382-1"><a href="example-two.html#cb382-1" tabindex="-1"></a><span class="fu">eigen</span>(<span class="fu">cov</span>(stdz_scores))</span></code></pre></div>
<pre><code>## eigen() decomposition
## $values
## [1] 1.7107518 0.2892482
## 
## $vectors
##           [,1]       [,2]
## [1,] 0.7071068 -0.7071068
## [2,] 0.7071068  0.7071068</code></pre>
<p>Let’s now go back to our <code>prcomp()</code> function and now use <code>scale = TRUE</code> in the function, which does the scaling for us. We can compare this output with the output above with the PCA on the standardized scores.</p>
<div class="sourceCode" id="cb384"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb384-1"><a href="example-two.html#cb384-1" tabindex="-1"></a>pc_out <span class="ot">&lt;-</span> <span class="fu">prcomp</span>(<span class="sc">~</span> head1 <span class="sc">+</span> head2, </span>
<span id="cb384-2"><a href="example-two.html#cb384-2" tabindex="-1"></a>                 <span class="at">data  =</span> head_dat,</span>
<span id="cb384-3"><a href="example-two.html#cb384-3" tabindex="-1"></a>                 <span class="at">retx  =</span> <span class="cn">FALSE</span>, <span class="co"># Not rotating</span></span>
<span id="cb384-4"><a href="example-two.html#cb384-4" tabindex="-1"></a>                 <span class="at">scale =</span> <span class="cn">TRUE</span>)  <span class="co"># Standardize scores, then perform PCA.</span></span>
<span id="cb384-5"><a href="example-two.html#cb384-5" tabindex="-1"></a>pc_out</span></code></pre></div>
<pre><code>## Standard deviations (1, .., p=2):
## [1] 1.307957 0.537818
## 
## Rotation (n x k) = (2 x 2):
##              PC1        PC2
## head1 -0.7071068  0.7071068
## head2 -0.7071068 -0.7071068</code></pre>
<div class="sourceCode" id="cb386"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb386-1"><a href="example-two.html#cb386-1" tabindex="-1"></a><span class="fu">summary</span>(pc_out)</span></code></pre></div>
<pre><code>## Importance of components:
##                           PC1    PC2
## Standard deviation     1.3080 0.5378
## Proportion of Variance 0.8554 0.1446
## Cumulative Proportion  0.8554 1.0000</code></pre>
<p>The proportion of variance of each component is the same as it was with the previous model with unstandardized data. As we expect, however, the standard deviations of the components, which is the square root of the eigenvalues, differ from those of the unstandardized model. The eigenvalues of the PCA on the standardized scores are <span class="math inline">\(1.3080^2\)</span> and <span class="math inline">\(0.5378^2\)</span>, or <span class="math inline">\(1.711\)</span> and <span class="math inline">\(0.289\)</span>. These are the same as those we saw with the <code>eigen()</code> function on the covariance matrix.</p>
<div id="calculating-component-scores" class="section level3 hasAnchor" number="8.2.1">
<h3><span class="header-section-number">8.2.1</span> Calculating component scores<a href="example-two.html#calculating-component-scores" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>First let’s save and look at the unscaled eigenvectors from the standardized data.</p>
<div class="sourceCode" id="cb388"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb388-1"><a href="example-two.html#cb388-1" tabindex="-1"></a>A <span class="ot">&lt;-</span> <span class="fu">cbind</span>(pc_out<span class="sc">$</span>rotation)</span>
<span id="cb388-2"><a href="example-two.html#cb388-2" tabindex="-1"></a>A <span class="co"># The two eigenvectors</span></span></code></pre></div>
<pre><code>##              PC1        PC2
## head1 -0.7071068  0.7071068
## head2 -0.7071068 -0.7071068</code></pre>
<p>Here are the eigenvalues:</p>
<div class="sourceCode" id="cb390"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb390-1"><a href="example-two.html#cb390-1" tabindex="-1"></a>pc_out<span class="sc">$</span>sdev<span class="sc">^</span><span class="dv">2</span></span></code></pre></div>
<pre><code>## [1] 1.7107518 0.2892482</code></pre>
<p>Here are the component scores from this model:</p>
<div class="sourceCode" id="cb392"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb392-1"><a href="example-two.html#cb392-1" tabindex="-1"></a>head_dat[, <span class="fu">c</span>(<span class="st">&quot;C1.stdz&quot;</span>, <span class="st">&quot;C2.stdz&quot;</span>)] <span class="ot">&lt;-</span> stdz_scores <span class="sc">%*%</span> A </span>
<span id="cb392-2"><a href="example-two.html#cb392-2" tabindex="-1"></a><span class="fu">head</span>( head_dat )</span></code></pre></div>
<pre><code>##   head1 head2     C1.cent   C2.cent     C1.stdz    C2.stdz
## 1   191   179  -0.1695614  7.160674 -0.04159384  0.7233291
## 2   195   201 -18.8024312 -5.201210 -1.88073559 -0.5363257
## 3   181   185   2.4345897 -4.206753  0.26020181 -0.4235929
## 4   183   188  -1.1142355 -4.843808 -0.09595153 -0.4900027
## 5   176   171  15.9928357  1.890292  1.60836191  0.2002084
## 6   208   192 -21.3226862 10.408028 -2.18855730  1.0391855</code></pre>
<p>Again, we see that the sample variances of the component scores are the same as the eigenvalues.</p>
<div class="sourceCode" id="cb394"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb394-1"><a href="example-two.html#cb394-1" tabindex="-1"></a>head_dat <span class="sc">%&gt;%</span></span>
<span id="cb394-2"><a href="example-two.html#cb394-2" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">varC1 =</span> <span class="fu">var</span>(C1.stdz),</span>
<span id="cb394-3"><a href="example-two.html#cb394-3" tabindex="-1"></a>            <span class="at">varC2 =</span> <span class="fu">var</span>(C2.stdz))</span></code></pre></div>
<pre><code>##      varC1     varC2
## 1 1.710752 0.2892482</code></pre>
</div>
<div id="using-the-rescaled-eigenvectors-to-interpret-the-components" class="section level3 hasAnchor" number="8.2.2">
<h3><span class="header-section-number">8.2.2</span> Using the rescaled eigenvectors to interpret the components<a href="example-two.html#using-the-rescaled-eigenvectors-to-interpret-the-components" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To get the rescaled eigevectors (or “loadings”), we first get the square root of the eigenvalues. Here are the eigenvalues, again, but this time we’ll place them in a diagonal matrix, <span class="math inline">\(\mathbf{L}\)</span>, which has zeros on the off diagonal because we can then use this for matrix multiplication.</p>
<div class="sourceCode" id="cb396"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb396-1"><a href="example-two.html#cb396-1" tabindex="-1"></a>L <span class="ot">&lt;-</span> <span class="fu">diag</span>(pc_out<span class="sc">$</span>sdev<span class="sc">^</span><span class="dv">2</span>) <span class="co">#Eigenvalues</span></span>
<span id="cb396-2"><a href="example-two.html#cb396-2" tabindex="-1"></a>L <span class="co"># We&#39;ll use &quot;L&quot; for capital Lambda. This is the eigenvalue matrix</span></span></code></pre></div>
<pre><code>##          [,1]      [,2]
## [1,] 1.710752 0.0000000
## [2,] 0.000000 0.2892482</code></pre>
<p>Here are the scaled eigenvectors, with elements interpreted as correlations with component.<a href="#fn35" class="footnote-ref" id="fnref35"><sup>35</sup></a></p>
<div class="sourceCode" id="cb398"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb398-1"><a href="example-two.html#cb398-1" tabindex="-1"></a>A_star <span class="ot">&lt;-</span> A <span class="sc">%*%</span> (<span class="fu">sqrt</span>(L)) </span>
<span id="cb398-2"><a href="example-two.html#cb398-2" tabindex="-1"></a><span class="fu">round</span>(A_star, <span class="dv">3</span>) </span></code></pre></div>
<pre><code>##         [,1]  [,2]
## head1 -0.925  0.38
## head2 -0.925 -0.38</code></pre>
<p>Component 1 has to do with head size. Component 2 is something else, with two opposing forces, maybe something to do with head shape. That’s about as much interpretation we can do with this very simple data set.</p>
</div>
</div>
<div id="let-the-psych-package-do-the-work" class="section level2 hasAnchor" number="8.3">
<h2><span class="header-section-number">8.3</span> Let the Psych Package Do the Work<a href="example-two.html#let-the-psych-package-do-the-work" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Having done all that work, let’s use the psych package and let it report the rescaled eigenvalues (loadings). This, by default, uses the correlation matrix rather than the covariance matrix.</p>
<p>We can also add a <code>scores = TRUE</code> argument to obtain the component scores; these component scores have been rescaled to be standardized. There seems to be a lot of standardization going on here—we’ve standardized the observed variables and now we’re standardizing the component scores, which is really for aiding interpretation because component scores themselves have no intrinsic scale; by standardizing them, we can at least interpret the component scores as standard-deviation units away from the mean.</p>
<div class="sourceCode" id="cb400"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb400-1"><a href="example-two.html#cb400-1" tabindex="-1"></a><span class="fu">library</span>(psych)</span>
<span id="cb400-2"><a href="example-two.html#cb400-2" tabindex="-1"></a>pc_psy <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">pca</span>(head_dat[, <span class="fu">c</span>(<span class="st">&quot;head1&quot;</span>, <span class="st">&quot;head2&quot;</span>)], </span>
<span id="cb400-3"><a href="example-two.html#cb400-3" tabindex="-1"></a>              <span class="at">nfactors =</span> <span class="dv">2</span>, </span>
<span id="cb400-4"><a href="example-two.html#cb400-4" tabindex="-1"></a>              <span class="at">rotate =</span> <span class="st">&#39;none&#39;</span>,</span>
<span id="cb400-5"><a href="example-two.html#cb400-5" tabindex="-1"></a>              <span class="at">scores =</span> <span class="cn">TRUE</span>)</span>
<span id="cb400-6"><a href="example-two.html#cb400-6" tabindex="-1"></a><span class="fu">print</span>(pc_psy, <span class="at">digits =</span> <span class="dv">3</span>)</span></code></pre></div>
<pre><code>## Principal Components Analysis
## Call: principal(r = r, nfactors = nfactors, residuals = residuals, 
##     rotate = rotate, n.obs = n.obs, covar = covar, scores = scores, 
##     missing = missing, impute = impute, oblique.scores = oblique.scores, 
##     method = method, use = use, cor = cor, correct = 0.5, weight = NULL)
## Standardized loadings (pattern matrix) based upon correlation matrix
##         PC1   PC2 h2 u2  com
## head1 0.925 -0.38  1  0 1.33
## head2 0.925  0.38  1  0 1.33
## 
##                         PC1   PC2
## SS loadings           1.711 0.289
## Proportion Var        0.855 0.145
## Cumulative Var        0.855 1.000
## Proportion Explained  0.855 0.145
## Cumulative Proportion 0.855 1.000
## 
## Mean item complexity =  1.3
## Test of the hypothesis that 2 components are sufficient.
## 
## The root mean square of the residuals (RMSR) is  0 
##  with the empirical chi square  0  with prob &lt;  NA 
## 
## Fit based upon off diagonal values = 1</code></pre>
<p>We see the loadings are the rescaled eigenvectors, which are what we want. They can be interpreted as the correlation of the observed variable with the component.</p>
<div id="view-the-component-scores" class="section level3 hasAnchor" number="8.3.1">
<h3><span class="header-section-number">8.3.1</span> View the component scores<a href="example-two.html#view-the-component-scores" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can obtain the component scores for each case from the outputted object. They are a matrix of however many components we have, which we can save to our data:</p>
<div class="sourceCode" id="cb402"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb402-1"><a href="example-two.html#cb402-1" tabindex="-1"></a>head_dat[, <span class="fu">c</span>(<span class="st">&quot;C1.zscore&quot;</span>, <span class="st">&quot;C2.zscore&quot;</span>) ]  <span class="ot">&lt;-</span> pc_psy<span class="sc">$</span>scores</span></code></pre></div>
<p>We can verify that these are indeed standardized component scores.</p>
<div class="sourceCode" id="cb403"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb403-1"><a href="example-two.html#cb403-1" tabindex="-1"></a>head_dat <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(C1.zscore, C2.zscore) <span class="sc">%&gt;%</span> </span>
<span id="cb403-2"><a href="example-two.html#cb403-2" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">MC1 =</span> <span class="fu">round</span>( <span class="fu">mean</span>(C1.zscore), <span class="dv">2</span>),</span>
<span id="cb403-3"><a href="example-two.html#cb403-3" tabindex="-1"></a>            <span class="at">MC2 =</span> <span class="fu">round</span>( <span class="fu">mean</span>(C2.zscore), <span class="dv">2</span>),</span>
<span id="cb403-4"><a href="example-two.html#cb403-4" tabindex="-1"></a>            <span class="at">varC1 =</span> <span class="fu">var</span>(C1.zscore),</span>
<span id="cb403-5"><a href="example-two.html#cb403-5" tabindex="-1"></a>            <span class="at">varC2 =</span> <span class="fu">var</span>(C2.zscore))</span></code></pre></div>
<pre><code>##   MC1 MC2 varC1 varC2
## 1   0   0     1     1</code></pre>
<p>We also see that these scores correlate perfectly with the other component scores we calculated earlier from the coefficients. The difference in sign is because the <code>prcomp()</code> function arbitrarily assigns the sign. We also see that the two component scores, no matter how we calculate them, are orthogonal to each other.</p>
<div class="sourceCode" id="cb405"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb405-1"><a href="example-two.html#cb405-1" tabindex="-1"></a><span class="fu">round</span>( <span class="fu">cor</span>(head_dat[, <span class="fu">c</span>(<span class="st">&quot;C1.cent&quot;</span>, <span class="st">&quot;C2.cent&quot;</span>, <span class="st">&quot;C1.stdz&quot;</span>, <span class="st">&quot;C2.stdz&quot;</span>, </span>
<span id="cb405-2"><a href="example-two.html#cb405-2" tabindex="-1"></a><span class="st">&quot;C1.zscore&quot;</span>, <span class="st">&quot;C2.zscore&quot;</span>) ] ) , <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##           C1.cent C2.cent C1.stdz C2.stdz C1.zscore C2.zscore
## C1.cent      1.00    0.00    1.00    0.01     -1.00     -0.01
## C2.cent      0.00    1.00   -0.01    1.00      0.01     -1.00
## C1.stdz      1.00   -0.01    1.00    0.00     -1.00      0.00
## C2.stdz      0.01    1.00    0.00    1.00      0.00     -1.00
## C1.zscore   -1.00    0.01   -1.00    0.00      1.00      0.00
## C2.zscore   -0.01   -1.00    0.00   -1.00      0.00      1.00</code></pre>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="34">
<li id="fn34"><p>Some functions, such as the psych pacakge’s <code>pca()</code> function will report PCA results based on the standardized scores by default.<a href="example-two.html#fnref34" class="footnote-back">↩︎</a></p></li>
<li id="fn35"><p>We are doing double duty in this demonstration by squaring and then rooting but it is to demonstrate that there is a thing called the eigenvalue matrix, which has eigenvalues along the diagonal.<a href="example-two.html#fnref35" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="example-1-to-see-some-properties-of-pca.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="heptathlon-example.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
